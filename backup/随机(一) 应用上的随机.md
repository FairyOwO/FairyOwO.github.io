> 写在前面: 本文探讨的真随机与伪随机的定义: 只要满足随机性检测的, 即为真随机. 其余皆为伪随机
> 区别于通过物理现象或不可预测的事件产生的真随机数, 与程序生成的伪随机数, 两者将在下一篇介绍
> 常见的伪随机有: 抽卡低保算法等

## 引言

大多数人知道"随机", 但在实际生活中, 缺混淆相关概念, 这里做一个简单的介绍, 本文希望从统计测试和生成机制两个视角厘清二者的界限.

在应用篇视角下，我们关注的是一个数字序列在特定场景中“表现”得如何，而非其“出身”如何。这种视角更侧重于随机数序列的实用性和表观行为。

首先我们需要对本文定义的"真随机"进行一个定义: 任何能够成功通过一套预先设定的、公认的随机性检测标准的数字序列, 无论其生成源头是物理过程还是确定性算法, 均可被视为"应用层面上的真随机". 只要一个序列在统计学上表现出了足够的随机特性, 没有显露出可被识别的模式或规律性, 那么在应用层面就可以信赖其随机.

相应地, "应用层面上的伪随机"则指那些未能通过这些严格统计检验的序列, 或者其设计初衷并非追求统计学上的完美随机性. 一个典型的例子便是游戏中常见的"抽卡保底"算法, 这类算法的设计目标是为了平衡玩家体验或实现特定的商业逻辑, 而非生成在统计学意义上无偏的随机序列. 因此, 此定义下的"伪随机"范畴, 不仅包括了那些因算法缺陷导致统计特性不佳的序列, 也囊括了那些为了特定应用目标而"有意为之"的不完全随机系统.

这一种定义方式, 将能够通过所有相关统计测试的伪随机数生成器 (PRNG) 的输出在应用层赋予"真随机"的地位, 方便我们之后讨论相关内容.

## 随机性检验

为了客观评估一个数字序列是否"足够随机", 学术界和工业界发展出了一系列随机性测试方法和标准. 这些测试的必要性在于, 人眼的直观判断往往不可靠, 需要借助严格的数学工具来甄别序列中可能存在的非随机模式. 

目前国际上公认的随机性测试套件主要包括美国国家标准与技术研究院 (NIST) 发布的SP 800-22测试集和由George Marsaglia教授开发的Diehard测试集。这些测试套件通常包含多种独立的统计检验方法, 例如:

频率测试: 检测序列中的数字的个数是否大致相等
块内频率测试: 分块后, 检测各块内各个数字的比例
游程测试: 检查序列中连续相同比特(游程)的长度分布是否符合随机序列的期望
等, 详情可见[https://en.wikipedia.org/wiki/Statistical_randomness](https://en.wikipedia.org/wiki/Statistical_randomness)

在这些测试中, P值(P-value)是一个核心概念. 它表示在原假设 (即"被测序列是随机的") 成立的前提下. 观测到当前检验统计量或更极端情况的概率 1. 通常, 如果一个P值非常小 (例如小于预设的显著性水平α, 如0.01或0.001), 则认为有足够证据拒绝原假设, 即该序列未能通过此项特定测试, 表现出非随机性 2 .

> 统计学假设检验之 p检验

需要强调的是, "通过测试"并不意味着绝对证明了序列是"真随机"的. 它仅仅表明, 在所实施的统计检验方法下, 该序列没有暴露出明显的非随机模式或统计偏差. 任何测试套件都是有限的, 一个序列即使通过了所有已知的测试, 也无法保证它在未来面对新的、更精密的测试方法时依然表现完美. 统计决策本身也带有概率性, 存在错误地拒绝一个真随机序列 (第一类错误) 或错误地接受一个非随机序列 (第二类错误) 的风险. 此外, 随机性测试标准本身也在不断发展和完善, 对随机数生成器的要求也随之提高.

## "应用伪随机"

TODO