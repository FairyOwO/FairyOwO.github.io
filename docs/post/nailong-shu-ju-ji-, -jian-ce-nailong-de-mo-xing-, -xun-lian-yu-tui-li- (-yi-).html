<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark_colorblind" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="> 回归 老本行

偶然得到 nailong 数据集, 分为两块, 一种是给[分类模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongClassification), 另一种是给[目标检测模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongDetection)

> 后者的数据量不是非常多(6张), 等到有足够多的数据或者我一时兴起手动标注在进行研究

## 初版方案

### 数据集选择

在我刚接触这个数据集的时候, 数据集是只有奶龙的(无其他标签的数据), 这个时候第一个想法就是引入其他分类, 这里采用cifer10数据集的数据, 对数据集进行增广

然而, cifer10 的数据分布毕竟与常见群聊内发送的图片不同, 我觉得会影响最终能力, 应该有选择性而不是随意添加其他类型的图片, 在一番搜索之后, 选中了 [表情包数据集](https://github.com/LLM-Red-Team/emo-visual-data)

虽然这个数据集的原计划是用来检测 VLLM 的能力, 但我认为在我们这个任务中也可以使用

### 模型

在敲定数据集之后, 就开始挑选模型了, 因为是个人小项目, 这里采用我个人喜好的模型选择, 使用了 [convnext 系模型](https://github.com/facebookresearch/ConvNeXt)

这个模型的论文是一篇非常经典的实验文, 里面大量探索了一些技巧对模型能力的影响 (各类消融实验), 虽然他是 2020 年推出, 但他对现在的卷积网络的训练技巧的指引很大

具体细节可以搜索相关的模型解析, 这里不再赘述

<details><summary>model.py</summary>
<p>

```python
# copy from facebook/ConvNeXt
import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.models.layers import trunc_normal_, DropPath
from timm.models.registry import register_model

class Block(nn.Module):
    r''' ConvNeXt Block. There are two equivalent implementations:
    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)
    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back
    We use (2) as we find it slightly faster in PyTorch
    
    Args:
        dim (int): Number of input channels.
        drop_path (float): Stochastic depth rate. Default: 0.0
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
    '''
    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):
        super().__init__()
        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv
        self.norm = LayerNorm(dim, eps=1e-6)
        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers
        self.act = nn.GELU()
        self.pwconv2 = nn.Linear(4 * dim, dim)
        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), 
                                    requires_grad=True) if layer_scale_init_value > 0 else None
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()

    def forward(self, x):
        input = x
        x = self.dwconv(x)
        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)
        x = self.norm(x)
        x = self.pwconv1(x)
        x = self.act(x)
        x = self.pwconv2(x)
        if self.gamma is not None:
            x = self.gamma * x
        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)

        x = input + self.drop_path(x)
        return x

class ConvNeXt(nn.Module):
    r''' ConvNeXt
        A PyTorch impl of : `A ConvNet for the 2020s`  -
          https://arxiv.org/pdf/2201.03545.pdf

    Args:
        in_chans (int): Number of input image channels. Default: 3
        num_classes (int): Number of classes for classification head. Default: 1000
        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]
        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]
        drop_path_rate (float): Stochastic depth rate. Default: 0.
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.
    '''
    def __init__(self, in_chans=3, num_classes=1000, 
                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., 
                 layer_scale_init_value=1e-6, head_init_scale=1.,
                 ):
        super().__init__()

        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers
        stem = nn.Sequential(
            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),
            LayerNorm(dims[0], eps=1e-6, data_format='channels_first')
        )
        self.downsample_layers.append(stem)
        for i in range(3):
            downsample_layer = nn.Sequential(
                    LayerNorm(dims[i], eps=1e-6, data_format='channels_first'),
                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),
            )
            self.downsample_layers.append(downsample_layer)

        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks
        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] 
        cur = 0
        for i in range(4):
            stage = nn.Sequential(
                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], 
                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]
            )
            self.stages.append(stage)
            cur += depths[i]

        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer
        self.head = nn.Linear(dims[-1], num_classes)

        self.apply(self._init_weights)
        self.head.weight.data.mul_(head_init_scale)
        self.head.bias.data.mul_(head_init_scale)

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            trunc_normal_(m.weight, std=.02)
            nn.init.constant_(m.bias, 0)

    def forward_features(self, x):
        for i in range(4):
            x = self.downsample_layers[i](x)
            x = self.stages[i](x)
        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)

    def forward(self, x):
        x = self.forward_features(x)
        x = self.head(x)
        return x

class LayerNorm(nn.Module):
    r''' LayerNorm that supports two data formats: channels_last (default) or channels_first. 
    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with 
    shape (batch_size, height, width, channels) while channels_first corresponds to inputs 
    with shape (batch_size, channels, height, width).
    '''
    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_last'):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.eps = eps
        self.data_format = data_format
        if self.data_format not in ['channels_last', 'channels_first']:
            raise NotImplementedError 
        self.normalized_shape = (normalized_shape, )
    
    def forward(self, x):
        if self.data_format == 'channels_last':
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
        elif self.data_format == 'channels_first':
            u = x.mean(1, keepdim=True)
            s = (x - u).pow(2).mean(1, keepdim=True)
            x = (x - u) / torch.sqrt(s + self.eps)
            x = self.weight[:, None, None] * x + self.bias[:, None, None]
            return x


model_urls = {
    'convnext_tiny_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth',
    'convnext_small_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth',
    'convnext_base_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth',
    'convnext_large_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth',
    'convnext_tiny_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth',
    'convnext_small_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth',
    'convnext_base_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth',
    'convnext_large_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',
    'convnext_xlarge_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth',
}

@register_model
def convnext_tiny(pretrained=False,in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)
    if pretrained:
        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu', check_hash=True)
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_small(pretrained=False,in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)
    if pretrained:
        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_base(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)
    if pretrained:
        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_large(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)
    if pretrained:
        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)
    if pretrained:
        assert in_22k, 'only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True'
        url = model_urls['convnext_xlarge_22k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model
```

</p>
</details> 


### 代码

训练代码大部分都是模板, 不过, 我发现我还没有一个属于自己的 trainer, 趁着这次训练模型的时候补充一个

使用别人的 trainer 难免会遇到 debug, 而代码不熟的情况, 自己写的 trainer 可以掌握各种细节

在整理了一些以前代码后, 总结出了覆盖许多训练模型情况的流程, 趁着这个时候测试一下现在ai编码的能力, 将流程发给 claude-sonnet 后, 输出了一版代码, 在我的一些小修小补(补充日志)后, 就可以跑起来了

<details><summary>trainer.py</summary>
<p>

```python
import gc
import json
import logging
import os
import shutil

import torch
from torch import optim
from torch.amp import GradScaler
from torch.nn.utils import clip_grad_norm_
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

example_config = {
    'model': 'model_name',
    'checkpoint_dir': './checkpoints',
    'tensorboard_dir': './tensorboard',
    'device': 'cuda',
    'enable_cudnn_benchmark': True,
    'enable_amp': False,
    'learning_rate': 1e-4,
    'betas': [0.9, 0.999],
    'eps': 1e-8,
    'enable_compile': False,
    'weight_decay': 0.05,
    'max_steps': 100000,
    'max_grad_norm': 1.0,
    'save_every': 10000,
    'gradient_accumulation_steps': 4
}


class Trainer:
    def __init__(self, config):
        self.config = config
        self.setup_logging()
        self.setup_device()
        self.setup_model()
        self.setup_training()
        
    def setup_logging(self):
        '''设置日志'''
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s %(levelname)s %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        self.writer = SummaryWriter(self.config['tensorboard_dir'])
        
    def setup_device(self):
        '''设置设备'''
        self.device = torch.device(self.config['device'])
        torch.backends.cudnn.benchmark = self.config.get('enable_cudnn_benchmark', True)
        if self.device.type == 'cuda':
            self.logger.info(f'Using device: {self.device} ({torch.cuda.get_device_name()})')
        else:
            self.logger.info(f'Using device: {self.device}')
            
    def setup_model(self):
        '''设置模型、损失函数等'''
        self.model = self.build_model().to(self.device)
        if self.config.get('enable_compile', False):
            self.model.compile()
        self.criterion = self.build_criterion()
        
        # 打印模型信息
        n_parameters = sum(p.numel() for p in self.model.parameters())
        self.logger.info(f'Number of parameters: {n_parameters:,}')
        
    def setup_training(self):
        '''设置训练相关组件'''
        # 优化器
        self.optimizer = self.build_optimizer()
        
        # 学习率调度器
        self.scheduler = self.build_scheduler()
        
        # 梯度缩放器(用于混合精度训练)
        self.scaler = GradScaler(
            enabled=self.config.get('enable_amp', False)
        )
        self.gradient_accumulation_steps = self.config.get('gradient_accumulation_steps', 1)
        
        # 加载检查点
        self.steps = 0
        self.best_metric = {}
        self.load_checkpoint()
        
    def build_model(self):
        '''构建模型(需要子类实现)'''
        raise NotImplementedError
        
    def build_criterion(self):
        '''构建损失函数(需要子类实现)'''
        raise NotImplementedError
        
    def build_optimizer(self):
        '''构建优化器'''
        # 区分需要和不需要weight decay的参数
        decay_params = []
        no_decay_params = []
        for name, param in self.model.named_parameters():
            if 'bias' in name or 'norm' in name:
                no_decay_params.append(param)
            else:
                decay_params.append(param)
                
        opt_params = [
            {'params': decay_params, 'weight_decay': self.config['weight_decay']},
            {'params': no_decay_params, 'weight_decay': 0.0}
        ]
        
        return optim.AdamW(
            opt_params,
            lr=self.config['learning_rate'],
            betas=self.config.get('betas', (0.9, 0.999)),
            eps=self.config.get('eps', 1e-8)
        )
        
    def build_scheduler(self):
        '''构建学习率调度器(需要子类实现)'''
        return NotImplementedError
        
    def build_dataloader(self):
        '''构建数据加载器(需要子类实现)'''
        raise NotImplementedError
        
    def train_step(self, batch):
        '''单步训练(需要子类实现)'''
        raise NotImplementedError
        
    def validate(self):
        '''验证(需要子类实现)'''
        raise NotImplementedError
        
    def save_checkpoint(self, is_best=False):
        '''保存检查点'''
        state = {
            'model': self.model.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict(),
            'scaler': self.scaler.state_dict(),
            'steps': self.steps,
            'best_metric': self.best_metric,
            'config': self.config
        }
        
        # 保存最新检查点
        torch.save(
            state,
            os.path.join(self.config['checkpoint_dir'], 'latest.pt')
        )
        
        # 保存最佳检查点
        if is_best:
            shutil.copy(
                os.path.join(self.config['checkpoint_dir'], 'latest.pt'),
                os.path.join(self.config['checkpoint_dir'], 'best.pt')
            )
            
    def load_checkpoint(self):
        '''加载检查点'''
        checkpoint_path = os.path.join(
            self.config['checkpoint_dir'],
            'latest.pt'
        )
        
        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(
                checkpoint_path,
                map_location=self.device
            )
            
            self.model.load_state_dict(checkpoint['model'])
            self.optimizer.load_state_dict(checkpoint['optimizer'])
            self.scheduler.load_state_dict(checkpoint['scheduler'])
            self.scaler.load_state_dict(checkpoint['scaler'])
            self.steps = checkpoint['steps']
            self.best_metric = checkpoint['best_metric']
            
            self.logger.info(f'Loaded checkpoint from {checkpoint_path}')
            self.logger.info(f'Training will resume from step {self.steps}')
    
    @staticmethod
    def is_better_performance(baseline_dict, compare_dict):
        '''
        判断compare_dict中的指标是否全面超过baseline_dict
        
        Args:
            baseline_dict: 基准字典,格式为 {指标名: 值}
            compare_dict: 比较字典,格式为 {指标名: 值} 
        
        Returns:
            bool: 如果compare_dict中所有指标都严格大于baseline_dict则返回True,否则返回False
        '''
        if not baseline_dict:
            return True
        
        # 检查两个字典的键是否一致
        if set(baseline_dict.keys()) != set(compare_dict.keys()):
            return False
            
        # 检查每个指标是否都有提升
        for metric in baseline_dict:
            if compare_dict[metric] <= baseline_dict[metric]:
                return False
                
        return True
            
    def train(self):
        '''训练流程'''
        train_loader = self.build_dataloader()
        self.model.train()
        
        self.logger.info('Start training...')
        pbar = tqdm(total=self.config['max_steps'], initial=self.steps)
        
        while self.steps < self.config['max_steps']:
            for batch in train_loader:
                # 训练一步
                with torch.autocast(device_type=self.config['device'], enabled=self.config.get('enable_amp', False)):
                    loss = self.train_step(batch)
                self.scaler.scale(loss / self.gradient_accumulation_steps).backward()
                
                if (self.steps + 1) % self.gradient_accumulation_steps == 0:
                    # 梯度裁剪
                    if self.config.get('max_grad_norm', 0) > 0:
                        self.scaler.unscale_(self.optimizer)
                        clip_grad_norm_(
                            self.model.parameters(),
                            self.config['max_grad_norm']
                        )

                    # 优化器步进
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad(set_to_none=True)
                self.scheduler.step()
                
                # 记录
                self.writer.add_scalar('train/loss', loss, self.steps)
                self.writer.add_scalar(
                    'train/lr',
                    self.scheduler.get_last_lr()[0],
                    self.steps
                )
                
                self.steps += 1
                pbar.update(1)
                
                # 验证和保存
                if self.steps % self.config['save_every'] == 0:
                    metric = self.validate()
                    for i in metric:
                        self.logger.info(f'Validation {i}: {metric[i]}')
                        self.writer.add_scalar(f'val/{i}', metric[i], self.steps)
                    
                    is_best = self.is_better_performance(self.best_metric, metric)
                    if is_best:
                        self.best_metric = metric

                    self.model.train()
                    self.save_checkpoint(is_best)
                    
                if self.steps >= self.config['max_steps']:
                    break
                
            gc.collect()
            torch.cuda.empty_cache()
                    
        pbar.close()
        self.logger.info('Training finished!')


def main():
    '''主函数'''
    # 加载配置
    with open('config.json') as f:
        config = json.load(f)
        
    # 创建输出目录
    os.makedirs(config['checkpoint_dir'], exist_ok=True)
    os.makedirs(config['tensorboard_dir'], exist_ok=True)
    
    # 训练
    trainer = Trainer(config)
    trainer.train()
    
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        pass
``` 

</p>
</details> 

<details><summary>train.py(代码未整理完毕)</summary>
<p>

```python

```

</p>
</details> 

> TODO 补充trainer的用例与用法
> TODO 补充超参搜索相关内容, 以及其用例与用法

### 数据增广

原始数据集只有两百多张图片, 这个时候无法避免的要做数据增广, 扩展 nailong 标签的数据, 这里因为是初版方案, 也没有非常精细的增广方案, 这里使用了以下几种方式(代码在如上train.py中):

- 给图片添加颜色遮罩
    让模型不要将遇到黄色的就判定为奶龙
- 在负样本中嵌入正样本
    很经典的增广数据的手法
- 图片轴对称
- 等
。">
<meta property="og:title" content="nailong数据集, 检测nailong的模型, 训练与推理 (一)">
<meta property="og:description" content="> 回归 老本行

偶然得到 nailong 数据集, 分为两块, 一种是给[分类模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongClassification), 另一种是给[目标检测模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongDetection)

> 后者的数据量不是非常多(6张), 等到有足够多的数据或者我一时兴起手动标注在进行研究

## 初版方案

### 数据集选择

在我刚接触这个数据集的时候, 数据集是只有奶龙的(无其他标签的数据), 这个时候第一个想法就是引入其他分类, 这里采用cifer10数据集的数据, 对数据集进行增广

然而, cifer10 的数据分布毕竟与常见群聊内发送的图片不同, 我觉得会影响最终能力, 应该有选择性而不是随意添加其他类型的图片, 在一番搜索之后, 选中了 [表情包数据集](https://github.com/LLM-Red-Team/emo-visual-data)

虽然这个数据集的原计划是用来检测 VLLM 的能力, 但我认为在我们这个任务中也可以使用

### 模型

在敲定数据集之后, 就开始挑选模型了, 因为是个人小项目, 这里采用我个人喜好的模型选择, 使用了 [convnext 系模型](https://github.com/facebookresearch/ConvNeXt)

这个模型的论文是一篇非常经典的实验文, 里面大量探索了一些技巧对模型能力的影响 (各类消融实验), 虽然他是 2020 年推出, 但他对现在的卷积网络的训练技巧的指引很大

具体细节可以搜索相关的模型解析, 这里不再赘述

<details><summary>model.py</summary>
<p>

```python
# copy from facebook/ConvNeXt
import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.models.layers import trunc_normal_, DropPath
from timm.models.registry import register_model

class Block(nn.Module):
    r''' ConvNeXt Block. There are two equivalent implementations:
    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)
    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back
    We use (2) as we find it slightly faster in PyTorch
    
    Args:
        dim (int): Number of input channels.
        drop_path (float): Stochastic depth rate. Default: 0.0
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
    '''
    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):
        super().__init__()
        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv
        self.norm = LayerNorm(dim, eps=1e-6)
        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers
        self.act = nn.GELU()
        self.pwconv2 = nn.Linear(4 * dim, dim)
        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), 
                                    requires_grad=True) if layer_scale_init_value > 0 else None
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()

    def forward(self, x):
        input = x
        x = self.dwconv(x)
        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)
        x = self.norm(x)
        x = self.pwconv1(x)
        x = self.act(x)
        x = self.pwconv2(x)
        if self.gamma is not None:
            x = self.gamma * x
        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)

        x = input + self.drop_path(x)
        return x

class ConvNeXt(nn.Module):
    r''' ConvNeXt
        A PyTorch impl of : `A ConvNet for the 2020s`  -
          https://arxiv.org/pdf/2201.03545.pdf

    Args:
        in_chans (int): Number of input image channels. Default: 3
        num_classes (int): Number of classes for classification head. Default: 1000
        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]
        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]
        drop_path_rate (float): Stochastic depth rate. Default: 0.
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.
    '''
    def __init__(self, in_chans=3, num_classes=1000, 
                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., 
                 layer_scale_init_value=1e-6, head_init_scale=1.,
                 ):
        super().__init__()

        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers
        stem = nn.Sequential(
            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),
            LayerNorm(dims[0], eps=1e-6, data_format='channels_first')
        )
        self.downsample_layers.append(stem)
        for i in range(3):
            downsample_layer = nn.Sequential(
                    LayerNorm(dims[i], eps=1e-6, data_format='channels_first'),
                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),
            )
            self.downsample_layers.append(downsample_layer)

        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks
        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] 
        cur = 0
        for i in range(4):
            stage = nn.Sequential(
                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], 
                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]
            )
            self.stages.append(stage)
            cur += depths[i]

        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer
        self.head = nn.Linear(dims[-1], num_classes)

        self.apply(self._init_weights)
        self.head.weight.data.mul_(head_init_scale)
        self.head.bias.data.mul_(head_init_scale)

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            trunc_normal_(m.weight, std=.02)
            nn.init.constant_(m.bias, 0)

    def forward_features(self, x):
        for i in range(4):
            x = self.downsample_layers[i](x)
            x = self.stages[i](x)
        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)

    def forward(self, x):
        x = self.forward_features(x)
        x = self.head(x)
        return x

class LayerNorm(nn.Module):
    r''' LayerNorm that supports two data formats: channels_last (default) or channels_first. 
    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with 
    shape (batch_size, height, width, channels) while channels_first corresponds to inputs 
    with shape (batch_size, channels, height, width).
    '''
    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_last'):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.eps = eps
        self.data_format = data_format
        if self.data_format not in ['channels_last', 'channels_first']:
            raise NotImplementedError 
        self.normalized_shape = (normalized_shape, )
    
    def forward(self, x):
        if self.data_format == 'channels_last':
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
        elif self.data_format == 'channels_first':
            u = x.mean(1, keepdim=True)
            s = (x - u).pow(2).mean(1, keepdim=True)
            x = (x - u) / torch.sqrt(s + self.eps)
            x = self.weight[:, None, None] * x + self.bias[:, None, None]
            return x


model_urls = {
    'convnext_tiny_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth',
    'convnext_small_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth',
    'convnext_base_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth',
    'convnext_large_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth',
    'convnext_tiny_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth',
    'convnext_small_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth',
    'convnext_base_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth',
    'convnext_large_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',
    'convnext_xlarge_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth',
}

@register_model
def convnext_tiny(pretrained=False,in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)
    if pretrained:
        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu', check_hash=True)
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_small(pretrained=False,in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)
    if pretrained:
        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_base(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)
    if pretrained:
        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_large(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)
    if pretrained:
        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model

@register_model
def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)
    if pretrained:
        assert in_22k, 'only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True'
        url = model_urls['convnext_xlarge_22k']
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
    return model
```

</p>
</details> 


### 代码

训练代码大部分都是模板, 不过, 我发现我还没有一个属于自己的 trainer, 趁着这次训练模型的时候补充一个

使用别人的 trainer 难免会遇到 debug, 而代码不熟的情况, 自己写的 trainer 可以掌握各种细节

在整理了一些以前代码后, 总结出了覆盖许多训练模型情况的流程, 趁着这个时候测试一下现在ai编码的能力, 将流程发给 claude-sonnet 后, 输出了一版代码, 在我的一些小修小补(补充日志)后, 就可以跑起来了

<details><summary>trainer.py</summary>
<p>

```python
import gc
import json
import logging
import os
import shutil

import torch
from torch import optim
from torch.amp import GradScaler
from torch.nn.utils import clip_grad_norm_
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

example_config = {
    'model': 'model_name',
    'checkpoint_dir': './checkpoints',
    'tensorboard_dir': './tensorboard',
    'device': 'cuda',
    'enable_cudnn_benchmark': True,
    'enable_amp': False,
    'learning_rate': 1e-4,
    'betas': [0.9, 0.999],
    'eps': 1e-8,
    'enable_compile': False,
    'weight_decay': 0.05,
    'max_steps': 100000,
    'max_grad_norm': 1.0,
    'save_every': 10000,
    'gradient_accumulation_steps': 4
}


class Trainer:
    def __init__(self, config):
        self.config = config
        self.setup_logging()
        self.setup_device()
        self.setup_model()
        self.setup_training()
        
    def setup_logging(self):
        '''设置日志'''
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s %(levelname)s %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        self.writer = SummaryWriter(self.config['tensorboard_dir'])
        
    def setup_device(self):
        '''设置设备'''
        self.device = torch.device(self.config['device'])
        torch.backends.cudnn.benchmark = self.config.get('enable_cudnn_benchmark', True)
        if self.device.type == 'cuda':
            self.logger.info(f'Using device: {self.device} ({torch.cuda.get_device_name()})')
        else:
            self.logger.info(f'Using device: {self.device}')
            
    def setup_model(self):
        '''设置模型、损失函数等'''
        self.model = self.build_model().to(self.device)
        if self.config.get('enable_compile', False):
            self.model.compile()
        self.criterion = self.build_criterion()
        
        # 打印模型信息
        n_parameters = sum(p.numel() for p in self.model.parameters())
        self.logger.info(f'Number of parameters: {n_parameters:,}')
        
    def setup_training(self):
        '''设置训练相关组件'''
        # 优化器
        self.optimizer = self.build_optimizer()
        
        # 学习率调度器
        self.scheduler = self.build_scheduler()
        
        # 梯度缩放器(用于混合精度训练)
        self.scaler = GradScaler(
            enabled=self.config.get('enable_amp', False)
        )
        self.gradient_accumulation_steps = self.config.get('gradient_accumulation_steps', 1)
        
        # 加载检查点
        self.steps = 0
        self.best_metric = {}
        self.load_checkpoint()
        
    def build_model(self):
        '''构建模型(需要子类实现)'''
        raise NotImplementedError
        
    def build_criterion(self):
        '''构建损失函数(需要子类实现)'''
        raise NotImplementedError
        
    def build_optimizer(self):
        '''构建优化器'''
        # 区分需要和不需要weight decay的参数
        decay_params = []
        no_decay_params = []
        for name, param in self.model.named_parameters():
            if 'bias' in name or 'norm' in name:
                no_decay_params.append(param)
            else:
                decay_params.append(param)
                
        opt_params = [
            {'params': decay_params, 'weight_decay': self.config['weight_decay']},
            {'params': no_decay_params, 'weight_decay': 0.0}
        ]
        
        return optim.AdamW(
            opt_params,
            lr=self.config['learning_rate'],
            betas=self.config.get('betas', (0.9, 0.999)),
            eps=self.config.get('eps', 1e-8)
        )
        
    def build_scheduler(self):
        '''构建学习率调度器(需要子类实现)'''
        return NotImplementedError
        
    def build_dataloader(self):
        '''构建数据加载器(需要子类实现)'''
        raise NotImplementedError
        
    def train_step(self, batch):
        '''单步训练(需要子类实现)'''
        raise NotImplementedError
        
    def validate(self):
        '''验证(需要子类实现)'''
        raise NotImplementedError
        
    def save_checkpoint(self, is_best=False):
        '''保存检查点'''
        state = {
            'model': self.model.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict(),
            'scaler': self.scaler.state_dict(),
            'steps': self.steps,
            'best_metric': self.best_metric,
            'config': self.config
        }
        
        # 保存最新检查点
        torch.save(
            state,
            os.path.join(self.config['checkpoint_dir'], 'latest.pt')
        )
        
        # 保存最佳检查点
        if is_best:
            shutil.copy(
                os.path.join(self.config['checkpoint_dir'], 'latest.pt'),
                os.path.join(self.config['checkpoint_dir'], 'best.pt')
            )
            
    def load_checkpoint(self):
        '''加载检查点'''
        checkpoint_path = os.path.join(
            self.config['checkpoint_dir'],
            'latest.pt'
        )
        
        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(
                checkpoint_path,
                map_location=self.device
            )
            
            self.model.load_state_dict(checkpoint['model'])
            self.optimizer.load_state_dict(checkpoint['optimizer'])
            self.scheduler.load_state_dict(checkpoint['scheduler'])
            self.scaler.load_state_dict(checkpoint['scaler'])
            self.steps = checkpoint['steps']
            self.best_metric = checkpoint['best_metric']
            
            self.logger.info(f'Loaded checkpoint from {checkpoint_path}')
            self.logger.info(f'Training will resume from step {self.steps}')
    
    @staticmethod
    def is_better_performance(baseline_dict, compare_dict):
        '''
        判断compare_dict中的指标是否全面超过baseline_dict
        
        Args:
            baseline_dict: 基准字典,格式为 {指标名: 值}
            compare_dict: 比较字典,格式为 {指标名: 值} 
        
        Returns:
            bool: 如果compare_dict中所有指标都严格大于baseline_dict则返回True,否则返回False
        '''
        if not baseline_dict:
            return True
        
        # 检查两个字典的键是否一致
        if set(baseline_dict.keys()) != set(compare_dict.keys()):
            return False
            
        # 检查每个指标是否都有提升
        for metric in baseline_dict:
            if compare_dict[metric] <= baseline_dict[metric]:
                return False
                
        return True
            
    def train(self):
        '''训练流程'''
        train_loader = self.build_dataloader()
        self.model.train()
        
        self.logger.info('Start training...')
        pbar = tqdm(total=self.config['max_steps'], initial=self.steps)
        
        while self.steps < self.config['max_steps']:
            for batch in train_loader:
                # 训练一步
                with torch.autocast(device_type=self.config['device'], enabled=self.config.get('enable_amp', False)):
                    loss = self.train_step(batch)
                self.scaler.scale(loss / self.gradient_accumulation_steps).backward()
                
                if (self.steps + 1) % self.gradient_accumulation_steps == 0:
                    # 梯度裁剪
                    if self.config.get('max_grad_norm', 0) > 0:
                        self.scaler.unscale_(self.optimizer)
                        clip_grad_norm_(
                            self.model.parameters(),
                            self.config['max_grad_norm']
                        )

                    # 优化器步进
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad(set_to_none=True)
                self.scheduler.step()
                
                # 记录
                self.writer.add_scalar('train/loss', loss, self.steps)
                self.writer.add_scalar(
                    'train/lr',
                    self.scheduler.get_last_lr()[0],
                    self.steps
                )
                
                self.steps += 1
                pbar.update(1)
                
                # 验证和保存
                if self.steps % self.config['save_every'] == 0:
                    metric = self.validate()
                    for i in metric:
                        self.logger.info(f'Validation {i}: {metric[i]}')
                        self.writer.add_scalar(f'val/{i}', metric[i], self.steps)
                    
                    is_best = self.is_better_performance(self.best_metric, metric)
                    if is_best:
                        self.best_metric = metric

                    self.model.train()
                    self.save_checkpoint(is_best)
                    
                if self.steps >= self.config['max_steps']:
                    break
                
            gc.collect()
            torch.cuda.empty_cache()
                    
        pbar.close()
        self.logger.info('Training finished!')


def main():
    '''主函数'''
    # 加载配置
    with open('config.json') as f:
        config = json.load(f)
        
    # 创建输出目录
    os.makedirs(config['checkpoint_dir'], exist_ok=True)
    os.makedirs(config['tensorboard_dir'], exist_ok=True)
    
    # 训练
    trainer = Trainer(config)
    trainer.train()
    
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        pass
``` 

</p>
</details> 

<details><summary>train.py(代码未整理完毕)</summary>
<p>

```python

```

</p>
</details> 

> TODO 补充trainer的用例与用法
> TODO 补充超参搜索相关内容, 以及其用例与用法

### 数据增广

原始数据集只有两百多张图片, 这个时候无法避免的要做数据增广, 扩展 nailong 标签的数据, 这里因为是初版方案, 也没有非常精细的增广方案, 这里使用了以下几种方式(代码在如上train.py中):

- 给图片添加颜色遮罩
    让模型不要将遇到黄色的就判定为奶龙
- 在负样本中嵌入正样本
    很经典的增广数据的手法
- 图片轴对称
- 等
。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://FairyOwO.github.io/post/nailong-shu-ju-ji-%2C%20-jian-ce-nailong-de-mo-xing-%2C%20-xun-lian-yu-tui-li-%20%28-yi-%29.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>nailong数据集, 检测nailong的模型, 训练与推理 (一)</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">nailong数据集, 检测nailong的模型, 训练与推理 (一)</h1>
<div class="title-right">
    <a href="https://FairyOwO.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/FairyOwO/FairyOwO.github.io/issues/4" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><blockquote>
<p>回归 老本行</p>
</blockquote>
<p>偶然得到 nailong 数据集, 分为两块, 一种是给<a href="https://huggingface.co/datasets/refoundd/NailongClassification" rel="nofollow">分类模型使用的数据集</a>, 另一种是给<a href="https://huggingface.co/datasets/refoundd/NailongDetection" rel="nofollow">目标检测模型使用的数据集</a></p>
<blockquote>
<p>后者的数据量不是非常多(6张), 等到有足够多的数据或者我一时兴起手动标注在进行研究</p>
</blockquote>
<h2>初版方案</h2>
<h3>数据集选择</h3>
<p>在我刚接触这个数据集的时候, 数据集是只有奶龙的(无其他标签的数据), 这个时候第一个想法就是引入其他分类, 这里采用cifer10数据集的数据, 对数据集进行增广</p>
<p>然而, cifer10 的数据分布毕竟与常见群聊内发送的图片不同, 我觉得会影响最终能力, 应该有选择性而不是随意添加其他类型的图片, 在一番搜索之后, 选中了 <a href="https://github.com/LLM-Red-Team/emo-visual-data">表情包数据集</a></p>
<p>虽然这个数据集的原计划是用来检测 VLLM 的能力, 但我认为在我们这个任务中也可以使用</p>
<h3>模型</h3>
<p>在敲定数据集之后, 就开始挑选模型了, 因为是个人小项目, 这里采用我个人喜好的模型选择, 使用了 <a href="https://github.com/facebookresearch/ConvNeXt">convnext 系模型</a></p>
<p>这个模型的论文是一篇非常经典的实验文, 里面大量探索了一些技巧对模型能力的影响 (各类消融实验), 虽然他是 2020 年推出, 但他对现在的卷积网络的训练技巧的指引很大</p>
<p>具体细节可以搜索相关的模型解析, 这里不再赘述</p>
<details><summary>model.py</summary>
<p>
</p><div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-c"># copy from facebook/ConvNeXt</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span> <span class="pl-k">as</span> <span class="pl-s1">nn</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span>.<span class="pl-s1">functional</span> <span class="pl-k">as</span> <span class="pl-v">F</span>
<span class="pl-k">from</span> <span class="pl-s1">timm</span>.<span class="pl-s1">models</span>.<span class="pl-s1">layers</span> <span class="pl-k">import</span> <span class="pl-s1">trunc_normal_</span>, <span class="pl-v">DropPath</span>
<span class="pl-k">from</span> <span class="pl-s1">timm</span>.<span class="pl-s1">models</span>.<span class="pl-s1">registry</span> <span class="pl-k">import</span> <span class="pl-s1">register_model</span>

<span class="pl-k">class</span> <span class="pl-v">Block</span>(<span class="pl-s1">nn</span>.<span class="pl-v">Module</span>):
    <span class="pl-s">r""" ConvNeXt Block. There are two equivalent implementations:</span>
<span class="pl-s">    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)</span>
<span class="pl-s">    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back</span>
<span class="pl-s">    We use (2) as we find it slightly faster in PyTorch</span>
<span class="pl-s">    </span>
<span class="pl-s">    Args:</span>
<span class="pl-s">        dim (int): Number of input channels.</span>
<span class="pl-s">        drop_path (float): Stochastic depth rate. Default: 0.0</span>
<span class="pl-s">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span>
<span class="pl-s">    """</span>
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">dim</span>, <span class="pl-s1">drop_path</span><span class="pl-c1">=</span><span class="pl-c1">0.</span>, <span class="pl-s1">layer_scale_init_value</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>):
        <span class="pl-en">super</span>().<span class="pl-en">__init__</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">dwconv</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Conv2d</span>(<span class="pl-s1">dim</span>, <span class="pl-s1">dim</span>, <span class="pl-s1">kernel_size</span><span class="pl-c1">=</span><span class="pl-c1">7</span>, <span class="pl-s1">padding</span><span class="pl-c1">=</span><span class="pl-c1">3</span>, <span class="pl-s1">groups</span><span class="pl-c1">=</span><span class="pl-s1">dim</span>) <span class="pl-c"># depthwise conv</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">norm</span> <span class="pl-c1">=</span> <span class="pl-v">LayerNorm</span>(<span class="pl-s1">dim</span>, <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>)
        <span class="pl-s1">self</span>.<span class="pl-s1">pwconv1</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-s1">dim</span>, <span class="pl-c1">4</span> <span class="pl-c1">*</span> <span class="pl-s1">dim</span>) <span class="pl-c"># pointwise/1x1 convs, implemented with linear layers</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">act</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">GELU</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">pwconv2</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">4</span> <span class="pl-c1">*</span> <span class="pl-s1">dim</span>, <span class="pl-s1">dim</span>)
        <span class="pl-s1">self</span>.<span class="pl-s1">gamma</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Parameter</span>(<span class="pl-s1">layer_scale_init_value</span> <span class="pl-c1">*</span> <span class="pl-s1">torch</span>.<span class="pl-en">ones</span>((<span class="pl-s1">dim</span>)), 
                                    <span class="pl-s1">requires_grad</span><span class="pl-c1">=</span><span class="pl-c1">True</span>) <span class="pl-k">if</span> <span class="pl-s1">layer_scale_init_value</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">0</span> <span class="pl-k">else</span> <span class="pl-c1">None</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">drop_path</span> <span class="pl-c1">=</span> <span class="pl-v">DropPath</span>(<span class="pl-s1">drop_path</span>) <span class="pl-k">if</span> <span class="pl-s1">drop_path</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">0.</span> <span class="pl-k">else</span> <span class="pl-s1">nn</span>.<span class="pl-v">Identity</span>()

    <span class="pl-k">def</span> <span class="pl-en">forward</span>(<span class="pl-s1">self</span>, <span class="pl-s1">x</span>):
        <span class="pl-s1">input</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">dwconv</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>.<span class="pl-en">permute</span>(<span class="pl-c1">0</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">1</span>) <span class="pl-c"># (N, C, H, W) -&gt; (N, H, W, C)</span>
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">norm</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">pwconv1</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">act</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">pwconv2</span>(<span class="pl-s1">x</span>)
        <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">gamma</span> <span class="pl-c1">is</span> <span class="pl-c1">not</span> <span class="pl-c1">None</span>:
            <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">gamma</span> <span class="pl-c1">*</span> <span class="pl-s1">x</span>
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>.<span class="pl-en">permute</span>(<span class="pl-c1">0</span>, <span class="pl-c1">3</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>) <span class="pl-c"># (N, H, W, C) -&gt; (N, C, H, W)</span>

        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">input</span> <span class="pl-c1">+</span> <span class="pl-s1">self</span>.<span class="pl-en">drop_path</span>(<span class="pl-s1">x</span>)
        <span class="pl-k">return</span> <span class="pl-s1">x</span>

<span class="pl-k">class</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">nn</span>.<span class="pl-v">Module</span>):
    <span class="pl-s">r""" ConvNeXt</span>
<span class="pl-s">        A PyTorch impl of : `A ConvNet for the 2020s`  -</span>
<span class="pl-s">          https://arxiv.org/pdf/2201.03545.pdf</span>
<span class="pl-s"></span>
<span class="pl-s">    Args:</span>
<span class="pl-s">        in_chans (int): Number of input image channels. Default: 3</span>
<span class="pl-s">        num_classes (int): Number of classes for classification head. Default: 1000</span>
<span class="pl-s">        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]</span>
<span class="pl-s">        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]</span>
<span class="pl-s">        drop_path_rate (float): Stochastic depth rate. Default: 0.</span>
<span class="pl-s">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span>
<span class="pl-s">        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.</span>
<span class="pl-s">    """</span>
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">in_chans</span><span class="pl-c1">=</span><span class="pl-c1">3</span>, <span class="pl-s1">num_classes</span><span class="pl-c1">=</span><span class="pl-c1">1000</span>, 
                 <span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">96</span>, <span class="pl-c1">192</span>, <span class="pl-c1">384</span>, <span class="pl-c1">768</span>], <span class="pl-s1">drop_path_rate</span><span class="pl-c1">=</span><span class="pl-c1">0.</span>, 
                 <span class="pl-s1">layer_scale_init_value</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>, <span class="pl-s1">head_init_scale</span><span class="pl-c1">=</span><span class="pl-c1">1.</span>,
                 ):
        <span class="pl-en">super</span>().<span class="pl-en">__init__</span>()

        <span class="pl-s1">self</span>.<span class="pl-s1">downsample_layers</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">ModuleList</span>() <span class="pl-c"># stem and 3 intermediate downsampling conv layers</span>
        <span class="pl-s1">stem</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
            <span class="pl-s1">nn</span>.<span class="pl-v">Conv2d</span>(<span class="pl-s1">in_chans</span>, <span class="pl-s1">dims</span>[<span class="pl-c1">0</span>], <span class="pl-s1">kernel_size</span><span class="pl-c1">=</span><span class="pl-c1">4</span>, <span class="pl-s1">stride</span><span class="pl-c1">=</span><span class="pl-c1">4</span>),
            <span class="pl-v">LayerNorm</span>(<span class="pl-s1">dims</span>[<span class="pl-c1">0</span>], <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>, <span class="pl-s1">data_format</span><span class="pl-c1">=</span><span class="pl-s">"channels_first"</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">downsample_layers</span>.<span class="pl-en">append</span>(<span class="pl-s1">stem</span>)
        <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-c1">3</span>):
            <span class="pl-s1">downsample_layer</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
                    <span class="pl-v">LayerNorm</span>(<span class="pl-s1">dims</span>[<span class="pl-s1">i</span>], <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>, <span class="pl-s1">data_format</span><span class="pl-c1">=</span><span class="pl-s">"channels_first"</span>),
                    <span class="pl-s1">nn</span>.<span class="pl-v">Conv2d</span>(<span class="pl-s1">dims</span>[<span class="pl-s1">i</span>], <span class="pl-s1">dims</span>[<span class="pl-s1">i</span><span class="pl-c1">+</span><span class="pl-c1">1</span>], <span class="pl-s1">kernel_size</span><span class="pl-c1">=</span><span class="pl-c1">2</span>, <span class="pl-s1">stride</span><span class="pl-c1">=</span><span class="pl-c1">2</span>),
            )
            <span class="pl-s1">self</span>.<span class="pl-s1">downsample_layers</span>.<span class="pl-en">append</span>(<span class="pl-s1">downsample_layer</span>)

        <span class="pl-s1">self</span>.<span class="pl-s1">stages</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">ModuleList</span>() <span class="pl-c"># 4 feature resolution stages, each consisting of multiple residual blocks</span>
        <span class="pl-s1">dp_rates</span><span class="pl-c1">=</span>[<span class="pl-s1">x</span>.<span class="pl-en">item</span>() <span class="pl-k">for</span> <span class="pl-s1">x</span> <span class="pl-c1">in</span> <span class="pl-s1">torch</span>.<span class="pl-en">linspace</span>(<span class="pl-c1">0</span>, <span class="pl-s1">drop_path_rate</span>, <span class="pl-en">sum</span>(<span class="pl-s1">depths</span>))] 
        <span class="pl-s1">cur</span> <span class="pl-c1">=</span> <span class="pl-c1">0</span>
        <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-c1">4</span>):
            <span class="pl-s1">stage</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
                <span class="pl-c1">*</span>[<span class="pl-v">Block</span>(<span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-s1">dims</span>[<span class="pl-s1">i</span>], <span class="pl-s1">drop_path</span><span class="pl-c1">=</span><span class="pl-s1">dp_rates</span>[<span class="pl-s1">cur</span> <span class="pl-c1">+</span> <span class="pl-s1">j</span>], 
                <span class="pl-s1">layer_scale_init_value</span><span class="pl-c1">=</span><span class="pl-s1">layer_scale_init_value</span>) <span class="pl-k">for</span> <span class="pl-s1">j</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">depths</span>[<span class="pl-s1">i</span>])]
            )
            <span class="pl-s1">self</span>.<span class="pl-s1">stages</span>.<span class="pl-en">append</span>(<span class="pl-s1">stage</span>)
            <span class="pl-s1">cur</span> <span class="pl-c1">+=</span> <span class="pl-s1">depths</span>[<span class="pl-s1">i</span>]

        <span class="pl-s1">self</span>.<span class="pl-s1">norm</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">LayerNorm</span>(<span class="pl-s1">dims</span>[<span class="pl-c1">-</span><span class="pl-c1">1</span>], <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>) <span class="pl-c"># final norm layer</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">head</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-s1">dims</span>[<span class="pl-c1">-</span><span class="pl-c1">1</span>], <span class="pl-s1">num_classes</span>)

        <span class="pl-s1">self</span>.<span class="pl-en">apply</span>(<span class="pl-s1">self</span>.<span class="pl-s1">_init_weights</span>)
        <span class="pl-s1">self</span>.<span class="pl-s1">head</span>.<span class="pl-s1">weight</span>.<span class="pl-s1">data</span>.<span class="pl-en">mul_</span>(<span class="pl-s1">head_init_scale</span>)
        <span class="pl-s1">self</span>.<span class="pl-s1">head</span>.<span class="pl-s1">bias</span>.<span class="pl-s1">data</span>.<span class="pl-en">mul_</span>(<span class="pl-s1">head_init_scale</span>)

    <span class="pl-k">def</span> <span class="pl-en">_init_weights</span>(<span class="pl-s1">self</span>, <span class="pl-s1">m</span>):
        <span class="pl-k">if</span> <span class="pl-en">isinstance</span>(<span class="pl-s1">m</span>, (<span class="pl-s1">nn</span>.<span class="pl-v">Conv2d</span>, <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>)):
            <span class="pl-en">trunc_normal_</span>(<span class="pl-s1">m</span>.<span class="pl-s1">weight</span>, <span class="pl-s1">std</span><span class="pl-c1">=</span><span class="pl-c1">.02</span>)
            <span class="pl-s1">nn</span>.<span class="pl-s1">init</span>.<span class="pl-en">constant_</span>(<span class="pl-s1">m</span>.<span class="pl-s1">bias</span>, <span class="pl-c1">0</span>)

    <span class="pl-k">def</span> <span class="pl-en">forward_features</span>(<span class="pl-s1">self</span>, <span class="pl-s1">x</span>):
        <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-c1">4</span>):
            <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">downsample_layers</span>[<span class="pl-s1">i</span>](<span class="pl-s1">x</span>)
            <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">stages</span>[<span class="pl-s1">i</span>](<span class="pl-s1">x</span>)
        <span class="pl-k">return</span> <span class="pl-s1">self</span>.<span class="pl-en">norm</span>(<span class="pl-s1">x</span>.<span class="pl-en">mean</span>([<span class="pl-c1">-</span><span class="pl-c1">2</span>, <span class="pl-c1">-</span><span class="pl-c1">1</span>])) <span class="pl-c"># global average pooling, (N, C, H, W) -&gt; (N, C)</span>

    <span class="pl-k">def</span> <span class="pl-en">forward</span>(<span class="pl-s1">self</span>, <span class="pl-s1">x</span>):
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">forward_features</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">head</span>(<span class="pl-s1">x</span>)
        <span class="pl-k">return</span> <span class="pl-s1">x</span>

<span class="pl-k">class</span> <span class="pl-v">LayerNorm</span>(<span class="pl-s1">nn</span>.<span class="pl-v">Module</span>):
    <span class="pl-s">r""" LayerNorm that supports two data formats: channels_last (default) or channels_first. </span>
<span class="pl-s">    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with </span>
<span class="pl-s">    shape (batch_size, height, width, channels) while channels_first corresponds to inputs </span>
<span class="pl-s">    with shape (batch_size, channels, height, width).</span>
<span class="pl-s">    """</span>
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">normalized_shape</span>, <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-c1">1e-6</span>, <span class="pl-s1">data_format</span><span class="pl-c1">=</span><span class="pl-s">"channels_last"</span>):
        <span class="pl-en">super</span>().<span class="pl-en">__init__</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">weight</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Parameter</span>(<span class="pl-s1">torch</span>.<span class="pl-en">ones</span>(<span class="pl-s1">normalized_shape</span>))
        <span class="pl-s1">self</span>.<span class="pl-s1">bias</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Parameter</span>(<span class="pl-s1">torch</span>.<span class="pl-en">zeros</span>(<span class="pl-s1">normalized_shape</span>))
        <span class="pl-s1">self</span>.<span class="pl-s1">eps</span> <span class="pl-c1">=</span> <span class="pl-s1">eps</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">data_format</span> <span class="pl-c1">=</span> <span class="pl-s1">data_format</span>
        <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">data_format</span> <span class="pl-c1">not</span> <span class="pl-c1">in</span> [<span class="pl-s">"channels_last"</span>, <span class="pl-s">"channels_first"</span>]:
            <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span> 
        <span class="pl-s1">self</span>.<span class="pl-s1">normalized_shape</span> <span class="pl-c1">=</span> (<span class="pl-s1">normalized_shape</span>, )
    
    <span class="pl-k">def</span> <span class="pl-en">forward</span>(<span class="pl-s1">self</span>, <span class="pl-s1">x</span>):
        <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">data_format</span> <span class="pl-c1">==</span> <span class="pl-s">"channels_last"</span>:
            <span class="pl-k">return</span> <span class="pl-v">F</span>.<span class="pl-en">layer_norm</span>(<span class="pl-s1">x</span>, <span class="pl-s1">self</span>.<span class="pl-s1">normalized_shape</span>, <span class="pl-s1">self</span>.<span class="pl-s1">weight</span>, <span class="pl-s1">self</span>.<span class="pl-s1">bias</span>, <span class="pl-s1">self</span>.<span class="pl-s1">eps</span>)
        <span class="pl-k">elif</span> <span class="pl-s1">self</span>.<span class="pl-s1">data_format</span> <span class="pl-c1">==</span> <span class="pl-s">"channels_first"</span>:
            <span class="pl-s1">u</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>.<span class="pl-en">mean</span>(<span class="pl-c1">1</span>, <span class="pl-s1">keepdim</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
            <span class="pl-s1">s</span> <span class="pl-c1">=</span> (<span class="pl-s1">x</span> <span class="pl-c1">-</span> <span class="pl-s1">u</span>).<span class="pl-en">pow</span>(<span class="pl-c1">2</span>).<span class="pl-en">mean</span>(<span class="pl-c1">1</span>, <span class="pl-s1">keepdim</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
            <span class="pl-s1">x</span> <span class="pl-c1">=</span> (<span class="pl-s1">x</span> <span class="pl-c1">-</span> <span class="pl-s1">u</span>) <span class="pl-c1">/</span> <span class="pl-s1">torch</span>.<span class="pl-en">sqrt</span>(<span class="pl-s1">s</span> <span class="pl-c1">+</span> <span class="pl-s1">self</span>.<span class="pl-s1">eps</span>)
            <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">weight</span>[:, <span class="pl-c1">None</span>, <span class="pl-c1">None</span>] <span class="pl-c1">*</span> <span class="pl-s1">x</span> <span class="pl-c1">+</span> <span class="pl-s1">self</span>.<span class="pl-s1">bias</span>[:, <span class="pl-c1">None</span>, <span class="pl-c1">None</span>]
            <span class="pl-k">return</span> <span class="pl-s1">x</span>


<span class="pl-s1">model_urls</span> <span class="pl-c1">=</span> {
    <span class="pl-s">"convnext_tiny_1k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth"</span>,
    <span class="pl-s">"convnext_small_1k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth"</span>,
    <span class="pl-s">"convnext_base_1k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth"</span>,
    <span class="pl-s">"convnext_large_1k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth"</span>,
    <span class="pl-s">"convnext_tiny_22k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth"</span>,
    <span class="pl-s">"convnext_small_22k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth"</span>,
    <span class="pl-s">"convnext_base_22k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth"</span>,
    <span class="pl-s">"convnext_large_22k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth"</span>,
    <span class="pl-s">"convnext_xlarge_22k"</span>: <span class="pl-s">"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth"</span>,
}

<span class="pl-en">@<span class="pl-s1">register_model</span></span>
<span class="pl-k">def</span> <span class="pl-en">convnext_tiny</span>(<span class="pl-s1">pretrained</span><span class="pl-c1">=</span><span class="pl-c1">False</span>,<span class="pl-s1">in_22k</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>):
    <span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">96</span>, <span class="pl-c1">192</span>, <span class="pl-c1">384</span>, <span class="pl-c1">768</span>], <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>)
    <span class="pl-k">if</span> <span class="pl-s1">pretrained</span>:
        <span class="pl-s1">url</span> <span class="pl-c1">=</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_tiny_22k'</span>] <span class="pl-k">if</span> <span class="pl-s1">in_22k</span> <span class="pl-k">else</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_tiny_1k'</span>]
        <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-s1">hub</span>.<span class="pl-en">load_state_dict_from_url</span>(<span class="pl-s1">url</span><span class="pl-c1">=</span><span class="pl-s1">url</span>, <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s">"cpu"</span>, <span class="pl-s1">check_hash</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
        <span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">"model"</span>])
    <span class="pl-k">return</span> <span class="pl-s1">model</span>

<span class="pl-en">@<span class="pl-s1">register_model</span></span>
<span class="pl-k">def</span> <span class="pl-en">convnext_small</span>(<span class="pl-s1">pretrained</span><span class="pl-c1">=</span><span class="pl-c1">False</span>,<span class="pl-s1">in_22k</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>):
    <span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">27</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">96</span>, <span class="pl-c1">192</span>, <span class="pl-c1">384</span>, <span class="pl-c1">768</span>], <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>)
    <span class="pl-k">if</span> <span class="pl-s1">pretrained</span>:
        <span class="pl-s1">url</span> <span class="pl-c1">=</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_small_22k'</span>] <span class="pl-k">if</span> <span class="pl-s1">in_22k</span> <span class="pl-k">else</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_small_1k'</span>]
        <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-s1">hub</span>.<span class="pl-en">load_state_dict_from_url</span>(<span class="pl-s1">url</span><span class="pl-c1">=</span><span class="pl-s1">url</span>, <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s">"cpu"</span>)
        <span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">"model"</span>])
    <span class="pl-k">return</span> <span class="pl-s1">model</span>

<span class="pl-en">@<span class="pl-s1">register_model</span></span>
<span class="pl-k">def</span> <span class="pl-en">convnext_base</span>(<span class="pl-s1">pretrained</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-s1">in_22k</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>):
    <span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">27</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">128</span>, <span class="pl-c1">256</span>, <span class="pl-c1">512</span>, <span class="pl-c1">1024</span>], <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>)
    <span class="pl-k">if</span> <span class="pl-s1">pretrained</span>:
        <span class="pl-s1">url</span> <span class="pl-c1">=</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_base_22k'</span>] <span class="pl-k">if</span> <span class="pl-s1">in_22k</span> <span class="pl-k">else</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_base_1k'</span>]
        <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-s1">hub</span>.<span class="pl-en">load_state_dict_from_url</span>(<span class="pl-s1">url</span><span class="pl-c1">=</span><span class="pl-s1">url</span>, <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s">"cpu"</span>)
        <span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">"model"</span>])
    <span class="pl-k">return</span> <span class="pl-s1">model</span>

<span class="pl-en">@<span class="pl-s1">register_model</span></span>
<span class="pl-k">def</span> <span class="pl-en">convnext_large</span>(<span class="pl-s1">pretrained</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-s1">in_22k</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>):
    <span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">27</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">192</span>, <span class="pl-c1">384</span>, <span class="pl-c1">768</span>, <span class="pl-c1">1536</span>], <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>)
    <span class="pl-k">if</span> <span class="pl-s1">pretrained</span>:
        <span class="pl-s1">url</span> <span class="pl-c1">=</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_large_22k'</span>] <span class="pl-k">if</span> <span class="pl-s1">in_22k</span> <span class="pl-k">else</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_large_1k'</span>]
        <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-s1">hub</span>.<span class="pl-en">load_state_dict_from_url</span>(<span class="pl-s1">url</span><span class="pl-c1">=</span><span class="pl-s1">url</span>, <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s">"cpu"</span>)
        <span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">"model"</span>])
    <span class="pl-k">return</span> <span class="pl-s1">model</span>

<span class="pl-en">@<span class="pl-s1">register_model</span></span>
<span class="pl-k">def</span> <span class="pl-en">convnext_xlarge</span>(<span class="pl-s1">pretrained</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-s1">in_22k</span><span class="pl-c1">=</span><span class="pl-c1">False</span>, <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>):
    <span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">ConvNeXt</span>(<span class="pl-s1">depths</span><span class="pl-c1">=</span>[<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, <span class="pl-c1">27</span>, <span class="pl-c1">3</span>], <span class="pl-s1">dims</span><span class="pl-c1">=</span>[<span class="pl-c1">256</span>, <span class="pl-c1">512</span>, <span class="pl-c1">1024</span>, <span class="pl-c1">2048</span>], <span class="pl-c1">**</span><span class="pl-s1">kwargs</span>)
    <span class="pl-k">if</span> <span class="pl-s1">pretrained</span>:
        <span class="pl-k">assert</span> <span class="pl-s1">in_22k</span>, <span class="pl-s">"only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True"</span>
        <span class="pl-s1">url</span> <span class="pl-c1">=</span> <span class="pl-s1">model_urls</span>[<span class="pl-s">'convnext_xlarge_22k'</span>]
        <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-s1">hub</span>.<span class="pl-en">load_state_dict_from_url</span>(<span class="pl-s1">url</span><span class="pl-c1">=</span><span class="pl-s1">url</span>, <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s">"cpu"</span>)
        <span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">"model"</span>])
    <span class="pl-k">return</span> <span class="pl-s1">model</span></pre></div>
<p></p>
</details> 
<h3>代码</h3>
<p>训练代码大部分都是模板, 不过, 我发现我还没有一个属于自己的 trainer, 趁着这次训练模型的时候补充一个</p>
<p>使用别人的 trainer 难免会遇到 debug, 而代码不熟的情况, 自己写的 trainer 可以掌握各种细节</p>
<p>在整理了一些以前代码后, 总结出了覆盖许多训练模型情况的流程, 趁着这个时候测试一下现在ai编码的能力, 将流程发给 claude-sonnet 后, 输出了一版代码, 在我的一些小修小补(补充日志)后, 就可以跑起来了</p>
<details><summary>trainer.py</summary>
<p>
</p><div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">import</span> <span class="pl-s1">gc</span>
<span class="pl-k">import</span> <span class="pl-s1">json</span>
<span class="pl-k">import</span> <span class="pl-s1">logging</span>
<span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">import</span> <span class="pl-s1">shutil</span>

<span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span> <span class="pl-k">import</span> <span class="pl-s1">optim</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">amp</span> <span class="pl-k">import</span> <span class="pl-v">GradScaler</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span>.<span class="pl-s1">utils</span> <span class="pl-k">import</span> <span class="pl-s1">clip_grad_norm_</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">utils</span>.<span class="pl-s1">tensorboard</span> <span class="pl-k">import</span> <span class="pl-v">SummaryWriter</span>
<span class="pl-k">from</span> <span class="pl-s1">tqdm</span> <span class="pl-k">import</span> <span class="pl-s1">tqdm</span>

<span class="pl-s1">example_config</span> <span class="pl-c1">=</span> {
    <span class="pl-s">"model"</span>: <span class="pl-s">"model_name"</span>,
    <span class="pl-s">"checkpoint_dir"</span>: <span class="pl-s">"./checkpoints"</span>,
    <span class="pl-s">"tensorboard_dir"</span>: <span class="pl-s">"./tensorboard"</span>,
    <span class="pl-s">"device"</span>: <span class="pl-s">"cuda"</span>,
    <span class="pl-s">"enable_cudnn_benchmark"</span>: <span class="pl-c1">True</span>,
    <span class="pl-s">"enable_amp"</span>: <span class="pl-c1">False</span>,
    <span class="pl-s">"learning_rate"</span>: <span class="pl-c1">1e-4</span>,
    <span class="pl-s">"betas"</span>: [<span class="pl-c1">0.9</span>, <span class="pl-c1">0.999</span>],
    <span class="pl-s">"eps"</span>: <span class="pl-c1">1e-8</span>,
    <span class="pl-s">"enable_compile"</span>: <span class="pl-c1">False</span>,
    <span class="pl-s">"weight_decay"</span>: <span class="pl-c1">0.05</span>,
    <span class="pl-s">"max_steps"</span>: <span class="pl-c1">100000</span>,
    <span class="pl-s">"max_grad_norm"</span>: <span class="pl-c1">1.0</span>,
    <span class="pl-s">"save_every"</span>: <span class="pl-c1">10000</span>,
    <span class="pl-s">"gradient_accumulation_steps"</span>: <span class="pl-c1">4</span>
}


<span class="pl-k">class</span> <span class="pl-v">Trainer</span>:
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">config</span>):
        <span class="pl-s1">self</span>.<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">config</span>
        <span class="pl-s1">self</span>.<span class="pl-en">setup_logging</span>()
        <span class="pl-s1">self</span>.<span class="pl-en">setup_device</span>()
        <span class="pl-s1">self</span>.<span class="pl-en">setup_model</span>()
        <span class="pl-s1">self</span>.<span class="pl-en">setup_training</span>()
        
    <span class="pl-k">def</span> <span class="pl-en">setup_logging</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""设置日志"""</span>
        <span class="pl-s1">logging</span>.<span class="pl-en">basicConfig</span>(
            <span class="pl-s1">level</span><span class="pl-c1">=</span><span class="pl-s1">logging</span>.<span class="pl-v">INFO</span>,
            <span class="pl-s1">format</span><span class="pl-c1">=</span><span class="pl-s">'%(asctime)s %(levelname)s %(message)s'</span>
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">logger</span> <span class="pl-c1">=</span> <span class="pl-s1">logging</span>.<span class="pl-en">getLogger</span>(<span class="pl-s1">__name__</span>)
        <span class="pl-s1">self</span>.<span class="pl-s1">writer</span> <span class="pl-c1">=</span> <span class="pl-v">SummaryWriter</span>(<span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'tensorboard_dir'</span>])
        
    <span class="pl-k">def</span> <span class="pl-en">setup_device</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""设置设备"""</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">device</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-en">device</span>(<span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'device'</span>])
        <span class="pl-s1">torch</span>.<span class="pl-s1">backends</span>.<span class="pl-s1">cudnn</span>.<span class="pl-s1">benchmark</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'enable_cudnn_benchmark'</span>, <span class="pl-c1">True</span>)
        <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">device</span>.<span class="pl-s1">type</span> <span class="pl-c1">==</span> <span class="pl-s">'cuda'</span>:
            <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Using device: <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">self</span>.<span class="pl-s1">device</span><span class="pl-kos">}</span></span> (<span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">torch</span>.<span class="pl-s1">cuda</span>.<span class="pl-en">get_device_name</span>()<span class="pl-kos">}</span></span>)'</span>)
        <span class="pl-k">else</span>:
            <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Using device: <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">self</span>.<span class="pl-s1">device</span><span class="pl-kos">}</span></span>'</span>)
            
    <span class="pl-k">def</span> <span class="pl-en">setup_model</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""设置模型、损失函数等"""</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">build_model</span>().<span class="pl-en">to</span>(<span class="pl-s1">self</span>.<span class="pl-s1">device</span>)
        <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'enable_compile'</span>, <span class="pl-c1">False</span>):
            <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">compile</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">criterion</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">build_criterion</span>()
        
        <span class="pl-c"># 打印模型信息</span>
        <span class="pl-s1">n_parameters</span> <span class="pl-c1">=</span> <span class="pl-en">sum</span>(<span class="pl-s1">p</span>.<span class="pl-en">numel</span>() <span class="pl-k">for</span> <span class="pl-s1">p</span> <span class="pl-c1">in</span> <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">parameters</span>())
        <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Number of parameters: <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">n_parameters</span>:,<span class="pl-kos">}</span></span>'</span>)
        
    <span class="pl-k">def</span> <span class="pl-en">setup_training</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""设置训练相关组件"""</span>
        <span class="pl-c"># 优化器</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">build_optimizer</span>()
        
        <span class="pl-c"># 学习率调度器</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">scheduler</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">build_scheduler</span>()
        
        <span class="pl-c"># 梯度缩放器(用于混合精度训练)</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span> <span class="pl-c1">=</span> <span class="pl-v">GradScaler</span>(
            <span class="pl-s1">enabled</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'enable_amp'</span>, <span class="pl-c1">False</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">gradient_accumulation_steps</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'gradient_accumulation_steps'</span>, <span class="pl-c1">1</span>)
        
        <span class="pl-c"># 加载检查点</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">=</span> <span class="pl-c1">0</span>
        <span class="pl-s1">self</span>.<span class="pl-s1">best_metric</span> <span class="pl-c1">=</span> {}
        <span class="pl-s1">self</span>.<span class="pl-en">load_checkpoint</span>()
        
    <span class="pl-k">def</span> <span class="pl-en">build_model</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""构建模型(需要子类实现)"""</span>
        <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">build_criterion</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""构建损失函数(需要子类实现)"""</span>
        <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">build_optimizer</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""构建优化器"""</span>
        <span class="pl-c"># 区分需要和不需要weight decay的参数</span>
        <span class="pl-s1">decay_params</span> <span class="pl-c1">=</span> []
        <span class="pl-s1">no_decay_params</span> <span class="pl-c1">=</span> []
        <span class="pl-k">for</span> <span class="pl-s1">name</span>, <span class="pl-s1">param</span> <span class="pl-c1">in</span> <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">named_parameters</span>():
            <span class="pl-k">if</span> <span class="pl-s">'bias'</span> <span class="pl-c1">in</span> <span class="pl-s1">name</span> <span class="pl-c1">or</span> <span class="pl-s">'norm'</span> <span class="pl-c1">in</span> <span class="pl-s1">name</span>:
                <span class="pl-s1">no_decay_params</span>.<span class="pl-en">append</span>(<span class="pl-s1">param</span>)
            <span class="pl-k">else</span>:
                <span class="pl-s1">decay_params</span>.<span class="pl-en">append</span>(<span class="pl-s1">param</span>)
                
        <span class="pl-s1">opt_params</span> <span class="pl-c1">=</span> [
            {<span class="pl-s">'params'</span>: <span class="pl-s1">decay_params</span>, <span class="pl-s">'weight_decay'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'weight_decay'</span>]},
            {<span class="pl-s">'params'</span>: <span class="pl-s1">no_decay_params</span>, <span class="pl-s">'weight_decay'</span>: <span class="pl-c1">0.0</span>}
        ]
        
        <span class="pl-k">return</span> <span class="pl-s1">optim</span>.<span class="pl-v">AdamW</span>(
            <span class="pl-s1">opt_params</span>,
            <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'learning_rate'</span>],
            <span class="pl-s1">betas</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'betas'</span>, (<span class="pl-c1">0.9</span>, <span class="pl-c1">0.999</span>)),
            <span class="pl-s1">eps</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'eps'</span>, <span class="pl-c1">1e-8</span>)
        )
        
    <span class="pl-k">def</span> <span class="pl-en">build_scheduler</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""构建学习率调度器(需要子类实现)"""</span>
        <span class="pl-k">return</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">build_dataloader</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""构建数据加载器(需要子类实现)"""</span>
        <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">train_step</span>(<span class="pl-s1">self</span>, <span class="pl-s1">batch</span>):
        <span class="pl-s">"""单步训练(需要子类实现)"""</span>
        <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">validate</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""验证(需要子类实现)"""</span>
        <span class="pl-k">raise</span> <span class="pl-v">NotImplementedError</span>
        
    <span class="pl-k">def</span> <span class="pl-en">save_checkpoint</span>(<span class="pl-s1">self</span>, <span class="pl-s1">is_best</span><span class="pl-c1">=</span><span class="pl-c1">False</span>):
        <span class="pl-s">"""保存检查点"""</span>
        <span class="pl-s1">state</span> <span class="pl-c1">=</span> {
            <span class="pl-s">'model'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">state_dict</span>(),
            <span class="pl-s">'optimizer'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span>.<span class="pl-en">state_dict</span>(),
            <span class="pl-s">'scheduler'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">scheduler</span>.<span class="pl-en">state_dict</span>(),
            <span class="pl-s">'scaler'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">state_dict</span>(),
            <span class="pl-s">'steps'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">steps</span>,
            <span class="pl-s">'best_metric'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">best_metric</span>,
            <span class="pl-s">'config'</span>: <span class="pl-s1">self</span>.<span class="pl-s1">config</span>
        }
        
        <span class="pl-c"># 保存最新检查点</span>
        <span class="pl-s1">torch</span>.<span class="pl-en">save</span>(
            <span class="pl-s1">state</span>,
            <span class="pl-s1">os</span>.<span class="pl-s1">path</span>.<span class="pl-en">join</span>(<span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'checkpoint_dir'</span>], <span class="pl-s">'latest.pt'</span>)
        )
        
        <span class="pl-c"># 保存最佳检查点</span>
        <span class="pl-k">if</span> <span class="pl-s1">is_best</span>:
            <span class="pl-s1">shutil</span>.<span class="pl-en">copy</span>(
                <span class="pl-s1">os</span>.<span class="pl-s1">path</span>.<span class="pl-en">join</span>(<span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'checkpoint_dir'</span>], <span class="pl-s">'latest.pt'</span>),
                <span class="pl-s1">os</span>.<span class="pl-s1">path</span>.<span class="pl-en">join</span>(<span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'checkpoint_dir'</span>], <span class="pl-s">'best.pt'</span>)
            )
            
    <span class="pl-k">def</span> <span class="pl-en">load_checkpoint</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""加载检查点"""</span>
        <span class="pl-s1">checkpoint_path</span> <span class="pl-c1">=</span> <span class="pl-s1">os</span>.<span class="pl-s1">path</span>.<span class="pl-en">join</span>(
            <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'checkpoint_dir'</span>],
            <span class="pl-s">'latest.pt'</span>
        )
        
        <span class="pl-k">if</span> <span class="pl-s1">os</span>.<span class="pl-s1">path</span>.<span class="pl-en">exists</span>(<span class="pl-s1">checkpoint_path</span>):
            <span class="pl-s1">checkpoint</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-en">load</span>(
                <span class="pl-s1">checkpoint_path</span>,
                <span class="pl-s1">map_location</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">device</span>
            )
            
            <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">'model'</span>])
            <span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">'optimizer'</span>])
            <span class="pl-s1">self</span>.<span class="pl-s1">scheduler</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">'scheduler'</span>])
            <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">load_state_dict</span>(<span class="pl-s1">checkpoint</span>[<span class="pl-s">'scaler'</span>])
            <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint</span>[<span class="pl-s">'steps'</span>]
            <span class="pl-s1">self</span>.<span class="pl-s1">best_metric</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint</span>[<span class="pl-s">'best_metric'</span>]
            
            <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Loaded checkpoint from <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">checkpoint_path</span><span class="pl-kos">}</span></span>'</span>)
            <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Training will resume from step <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">self</span>.<span class="pl-s1">steps</span><span class="pl-kos">}</span></span>'</span>)
    
    <span class="pl-en">@<span class="pl-s1">staticmethod</span></span>
    <span class="pl-k">def</span> <span class="pl-en">is_better_performance</span>(<span class="pl-s1">baseline_dict</span>, <span class="pl-s1">compare_dict</span>):
        <span class="pl-s">"""</span>
<span class="pl-s">        判断compare_dict中的指标是否全面超过baseline_dict</span>
<span class="pl-s">        </span>
<span class="pl-s">        Args:</span>
<span class="pl-s">            baseline_dict: 基准字典,格式为 {指标名: 值}</span>
<span class="pl-s">            compare_dict: 比较字典,格式为 {指标名: 值} </span>
<span class="pl-s">        </span>
<span class="pl-s">        Returns:</span>
<span class="pl-s">            bool: 如果compare_dict中所有指标都严格大于baseline_dict则返回True,否则返回False</span>
<span class="pl-s">        """</span>
        <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">baseline_dict</span>:
            <span class="pl-k">return</span> <span class="pl-c1">True</span>
        
        <span class="pl-c"># 检查两个字典的键是否一致</span>
        <span class="pl-k">if</span> <span class="pl-en">set</span>(<span class="pl-s1">baseline_dict</span>.<span class="pl-en">keys</span>()) <span class="pl-c1">!=</span> <span class="pl-en">set</span>(<span class="pl-s1">compare_dict</span>.<span class="pl-en">keys</span>()):
            <span class="pl-k">return</span> <span class="pl-c1">False</span>
            
        <span class="pl-c"># 检查每个指标是否都有提升</span>
        <span class="pl-k">for</span> <span class="pl-s1">metric</span> <span class="pl-c1">in</span> <span class="pl-s1">baseline_dict</span>:
            <span class="pl-k">if</span> <span class="pl-s1">compare_dict</span>[<span class="pl-s1">metric</span>] <span class="pl-c1">&lt;=</span> <span class="pl-s1">baseline_dict</span>[<span class="pl-s1">metric</span>]:
                <span class="pl-k">return</span> <span class="pl-c1">False</span>
                
        <span class="pl-k">return</span> <span class="pl-c1">True</span>
            
    <span class="pl-k">def</span> <span class="pl-en">train</span>(<span class="pl-s1">self</span>):
        <span class="pl-s">"""训练流程"""</span>
        <span class="pl-s1">train_loader</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">build_dataloader</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">train</span>()
        
        <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">'Start training...'</span>)
        <span class="pl-s1">pbar</span> <span class="pl-c1">=</span> <span class="pl-en">tqdm</span>(<span class="pl-s1">total</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'max_steps'</span>], <span class="pl-s1">initial</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">steps</span>)
        
        <span class="pl-k">while</span> <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">&lt;</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'max_steps'</span>]:
            <span class="pl-k">for</span> <span class="pl-s1">batch</span> <span class="pl-c1">in</span> <span class="pl-s1">train_loader</span>:
                <span class="pl-c"># 训练一步</span>
                <span class="pl-k">with</span> <span class="pl-s1">torch</span>.<span class="pl-en">autocast</span>(<span class="pl-s1">device_type</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'device'</span>], <span class="pl-s1">enabled</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'enable_amp'</span>, <span class="pl-c1">False</span>)):
                    <span class="pl-s1">loss</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">train_step</span>(<span class="pl-s1">batch</span>)
                <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">scale</span>(<span class="pl-s1">loss</span> <span class="pl-c1">/</span> <span class="pl-s1">self</span>.<span class="pl-s1">gradient_accumulation_steps</span>).<span class="pl-en">backward</span>()
                
                <span class="pl-k">if</span> (<span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>) <span class="pl-c1">%</span> <span class="pl-s1">self</span>.<span class="pl-s1">gradient_accumulation_steps</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
                    <span class="pl-c"># 梯度裁剪</span>
                    <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>.<span class="pl-en">get</span>(<span class="pl-s">'max_grad_norm'</span>, <span class="pl-c1">0</span>) <span class="pl-c1">&gt;</span> <span class="pl-c1">0</span>:
                        <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">unscale_</span>(<span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span>)
                        <span class="pl-en">clip_grad_norm_</span>(
                            <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">parameters</span>(),
                            <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'max_grad_norm'</span>]
                        )

                    <span class="pl-c"># 优化器步进</span>
                    <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">step</span>(<span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span>)
                    <span class="pl-s1">self</span>.<span class="pl-s1">scaler</span>.<span class="pl-en">update</span>()
                    <span class="pl-s1">self</span>.<span class="pl-s1">optimizer</span>.<span class="pl-en">zero_grad</span>(<span class="pl-s1">set_to_none</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
                <span class="pl-s1">self</span>.<span class="pl-s1">scheduler</span>.<span class="pl-en">step</span>()
                
                <span class="pl-c"># 记录</span>
                <span class="pl-s1">self</span>.<span class="pl-s1">writer</span>.<span class="pl-en">add_scalar</span>(<span class="pl-s">'train/loss'</span>, <span class="pl-s1">loss</span>, <span class="pl-s1">self</span>.<span class="pl-s1">steps</span>)
                <span class="pl-s1">self</span>.<span class="pl-s1">writer</span>.<span class="pl-en">add_scalar</span>(
                    <span class="pl-s">'train/lr'</span>,
                    <span class="pl-s1">self</span>.<span class="pl-s1">scheduler</span>.<span class="pl-en">get_last_lr</span>()[<span class="pl-c1">0</span>],
                    <span class="pl-s1">self</span>.<span class="pl-s1">steps</span>
                )
                
                <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">+=</span> <span class="pl-c1">1</span>
                <span class="pl-s1">pbar</span>.<span class="pl-en">update</span>(<span class="pl-c1">1</span>)
                
                <span class="pl-c"># 验证和保存</span>
                <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">%</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'save_every'</span>] <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
                    <span class="pl-s1">metric</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">validate</span>()
                    <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-s1">metric</span>:
                        <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">f'Validation <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">i</span><span class="pl-kos">}</span></span>: <span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">metric</span>[<span class="pl-s1">i</span>]<span class="pl-kos">}</span></span>'</span>)
                        <span class="pl-s1">self</span>.<span class="pl-s1">writer</span>.<span class="pl-en">add_scalar</span>(<span class="pl-s">f'val/<span class="pl-s1"><span class="pl-kos">{</span><span class="pl-s1">i</span><span class="pl-kos">}</span></span>'</span>, <span class="pl-s1">metric</span>[<span class="pl-s1">i</span>], <span class="pl-s1">self</span>.<span class="pl-s1">steps</span>)
                    
                    <span class="pl-s1">is_best</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">is_better_performance</span>(<span class="pl-s1">self</span>.<span class="pl-s1">best_metric</span>, <span class="pl-s1">metric</span>)
                    <span class="pl-k">if</span> <span class="pl-s1">is_best</span>:
                        <span class="pl-s1">self</span>.<span class="pl-s1">best_metric</span> <span class="pl-c1">=</span> <span class="pl-s1">metric</span>

                    <span class="pl-s1">self</span>.<span class="pl-s1">model</span>.<span class="pl-en">train</span>()
                    <span class="pl-s1">self</span>.<span class="pl-en">save_checkpoint</span>(<span class="pl-s1">is_best</span>)
                    
                <span class="pl-k">if</span> <span class="pl-s1">self</span>.<span class="pl-s1">steps</span> <span class="pl-c1">&gt;=</span> <span class="pl-s1">self</span>.<span class="pl-s1">config</span>[<span class="pl-s">'max_steps'</span>]:
                    <span class="pl-k">break</span>
                
            <span class="pl-s1">gc</span>.<span class="pl-en">collect</span>()
            <span class="pl-s1">torch</span>.<span class="pl-s1">cuda</span>.<span class="pl-en">empty_cache</span>()
                    
        <span class="pl-s1">pbar</span>.<span class="pl-en">close</span>()
        <span class="pl-s1">self</span>.<span class="pl-s1">logger</span>.<span class="pl-en">info</span>(<span class="pl-s">'Training finished!'</span>)


<span class="pl-k">def</span> <span class="pl-en">main</span>():
    <span class="pl-s">"""主函数"""</span>
    <span class="pl-c"># 加载配置</span>
    <span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s">'config.json'</span>) <span class="pl-k">as</span> <span class="pl-s1">f</span>:
        <span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">json</span>.<span class="pl-en">load</span>(<span class="pl-s1">f</span>)
        
    <span class="pl-c"># 创建输出目录</span>
    <span class="pl-s1">os</span>.<span class="pl-en">makedirs</span>(<span class="pl-s1">config</span>[<span class="pl-s">'checkpoint_dir'</span>], <span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
    <span class="pl-s1">os</span>.<span class="pl-en">makedirs</span>(<span class="pl-s1">config</span>[<span class="pl-s">'tensorboard_dir'</span>], <span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
    
    <span class="pl-c"># 训练</span>
    <span class="pl-s1">trainer</span> <span class="pl-c1">=</span> <span class="pl-v">Trainer</span>(<span class="pl-s1">config</span>)
    <span class="pl-s1">trainer</span>.<span class="pl-en">train</span>()
    
<span class="pl-k">if</span> <span class="pl-s1">__name__</span> <span class="pl-c1">==</span> <span class="pl-s">'__main__'</span>:
    <span class="pl-k">try</span>:
        <span class="pl-en">main</span>()
    <span class="pl-k">except</span> <span class="pl-v">KeyboardInterrupt</span>:
        <span class="pl-k">pass</span></pre></div>
<p></p>
</details> 
<details><summary>train.py(代码未整理完毕)</summary>
<p>
</p><div class="highlight highlight-source-python"><pre class="notranslate"></pre></div>
<p></p>
</details> 
<blockquote>
<p>TODO 补充trainer的用例与用法<br>
TODO 补充超参搜索相关内容, 以及其用例与用法</p>
</blockquote>
<h3>数据增广</h3>
<p>原始数据集只有两百多张图片, 这个时候无法避免的要做数据增广, 扩展 nailong 标签的数据, 这里因为是初版方案, 也没有非常精细的增广方案, 这里使用了以下几种方式(代码在如上train.py中):</p>
<ul>
<li>给图片添加颜色遮罩<br>
让模型不要将遇到黄色的就判定为奶龙</li>
<li>在负样本中嵌入正样本<br>
很经典的增广数据的手法</li>
<li>图片轴对称</li>
<li>等</li>
</ul></div>
<div style="font-size:small;margin-top:8px;float:right;">转载无需注明出处</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://FairyOwO.github.io">FairyOwO 的 Blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("11/22/2024"!=""){
    var startSite=new Date("11/22/2024");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","FairyOwO/FairyOwO.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>


</html>
