<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>FairyOwO 的 Blog</title><link>https://FairyOwO.github.io</link><description>记录一些琐事</description><copyright>FairyOwO 的 Blog</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://FairyOwO.github.io</link></image><lastBuildDate>Wed, 27 Nov 2024 10:05:23 +0000</lastBuildDate><managingEditor>FairyOwO 的 Blog</managingEditor><ttl>60</ttl><webMaster>FairyOwO 的 Blog</webMaster><item><title>nailong数据集, 检测nailong的模型, 训练与推理 (一)</title><link>https://FairyOwO.github.io/post/nailong-shu-ju-ji-%2C%20-jian-ce-nailong-de-mo-xing-%2C%20-xun-lian-yu-tui-li-%20%28-yi-%29.html</link><description>&gt; 回归 老本行&#13;
&#13;
偶然得到 nailong 数据集, 分为两块, 一种是给[分类模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongClassification), 另一种是给[目标检测模型使用的数据集](https://huggingface.co/datasets/refoundd/NailongDetection)&#13;
&#13;
&gt; 后者的数据量不是非常多(6张), 等到有足够多的数据或者我一时兴起手动标注在进行研究&#13;
&#13;
## 初版方案&#13;
&#13;
### 数据集选择&#13;
&#13;
在我刚接触这个数据集的时候, 数据集是只有奶龙的(无其他标签的数据), 这个时候第一个想法就是引入其他分类, 这里采用cifer10数据集的数据, 对数据集进行增广&#13;
&#13;
然而, cifer10 的数据分布毕竟与常见群聊内发送的图片不同, 我觉得会影响最终能力, 应该有选择性而不是随意添加其他类型的图片, 在一番搜索之后, 选中了 [表情包数据集](https://github.com/LLM-Red-Team/emo-visual-data)&#13;
&#13;
虽然这个数据集的原计划是用来检测 VLLM 的能力, 但我认为在我们这个任务中也可以使用&#13;
&#13;
### 模型&#13;
&#13;
在敲定数据集之后, 就开始挑选模型了, 因为是个人小项目, 这里采用我个人喜好的模型选择, 使用了 [convnext 系模型](https://github.com/facebookresearch/ConvNeXt)&#13;
&#13;
这个模型的论文是一篇非常经典的实验文, 里面大量探索了一些技巧对模型能力的影响 (各类消融实验), 虽然他是 2020 年推出, 但他对现在的卷积网络的训练技巧的指引很大&#13;
&#13;
具体细节可以搜索相关的模型解析, 这里不再赘述&#13;
&#13;
&lt;details&gt;&lt;summary&gt;model.py&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```python&#13;
# copy from facebook/ConvNeXt&#13;
import torch&#13;
import torch.nn as nn&#13;
import torch.nn.functional as F&#13;
from timm.models.layers import trunc_normal_, DropPath&#13;
from timm.models.registry import register_model&#13;
&#13;
class Block(nn.Module):&#13;
    r''' ConvNeXt Block. There are two equivalent implementations:&#13;
    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)&#13;
    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back&#13;
    We use (2) as we find it slightly faster in PyTorch&#13;
    &#13;
    Args:&#13;
        dim (int): Number of input channels.&#13;
        drop_path (float): Stochastic depth rate. Default: 0.0&#13;
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.&#13;
    '''&#13;
    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):&#13;
        super().__init__()&#13;
        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv&#13;
        self.norm = LayerNorm(dim, eps=1e-6)&#13;
        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers&#13;
        self.act = nn.GELU()&#13;
        self.pwconv2 = nn.Linear(4 * dim, dim)&#13;
        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), &#13;
                                    requires_grad=True) if layer_scale_init_value &gt; 0 else None&#13;
        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()&#13;
&#13;
    def forward(self, x):&#13;
        input = x&#13;
        x = self.dwconv(x)&#13;
        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -&gt; (N, H, W, C)&#13;
        x = self.norm(x)&#13;
        x = self.pwconv1(x)&#13;
        x = self.act(x)&#13;
        x = self.pwconv2(x)&#13;
        if self.gamma is not None:&#13;
            x = self.gamma * x&#13;
        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -&gt; (N, C, H, W)&#13;
&#13;
        x = input + self.drop_path(x)&#13;
        return x&#13;
&#13;
class ConvNeXt(nn.Module):&#13;
    r''' ConvNeXt&#13;
        A PyTorch impl of : `A ConvNet for the 2020s`  -&#13;
          https://arxiv.org/pdf/2201.03545.pdf&#13;
&#13;
    Args:&#13;
        in_chans (int): Number of input image channels. Default: 3&#13;
        num_classes (int): Number of classes for classification head. Default: 1000&#13;
        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]&#13;
        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]&#13;
        drop_path_rate (float): Stochastic depth rate. Default: 0.&#13;
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.&#13;
        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.&#13;
    '''&#13;
    def __init__(self, in_chans=3, num_classes=1000, &#13;
                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., &#13;
                 layer_scale_init_value=1e-6, head_init_scale=1.,&#13;
                 ):&#13;
        super().__init__()&#13;
&#13;
        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers&#13;
        stem = nn.Sequential(&#13;
            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),&#13;
            LayerNorm(dims[0], eps=1e-6, data_format='channels_first')&#13;
        )&#13;
        self.downsample_layers.append(stem)&#13;
        for i in range(3):&#13;
            downsample_layer = nn.Sequential(&#13;
                    LayerNorm(dims[i], eps=1e-6, data_format='channels_first'),&#13;
                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),&#13;
            )&#13;
            self.downsample_layers.append(downsample_layer)&#13;
&#13;
        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks&#13;
        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] &#13;
        cur = 0&#13;
        for i in range(4):&#13;
            stage = nn.Sequential(&#13;
                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], &#13;
                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]&#13;
            )&#13;
            self.stages.append(stage)&#13;
            cur += depths[i]&#13;
&#13;
        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer&#13;
        self.head = nn.Linear(dims[-1], num_classes)&#13;
&#13;
        self.apply(self._init_weights)&#13;
        self.head.weight.data.mul_(head_init_scale)&#13;
        self.head.bias.data.mul_(head_init_scale)&#13;
&#13;
    def _init_weights(self, m):&#13;
        if isinstance(m, (nn.Conv2d, nn.Linear)):&#13;
            trunc_normal_(m.weight, std=.02)&#13;
            nn.init.constant_(m.bias, 0)&#13;
&#13;
    def forward_features(self, x):&#13;
        for i in range(4):&#13;
            x = self.downsample_layers[i](x)&#13;
            x = self.stages[i](x)&#13;
        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -&gt; (N, C)&#13;
&#13;
    def forward(self, x):&#13;
        x = self.forward_features(x)&#13;
        x = self.head(x)&#13;
        return x&#13;
&#13;
class LayerNorm(nn.Module):&#13;
    r''' LayerNorm that supports two data formats: channels_last (default) or channels_first. &#13;
    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with &#13;
    shape (batch_size, height, width, channels) while channels_first corresponds to inputs &#13;
    with shape (batch_size, channels, height, width).&#13;
    '''&#13;
    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_last'):&#13;
        super().__init__()&#13;
        self.weight = nn.Parameter(torch.ones(normalized_shape))&#13;
        self.bias = nn.Parameter(torch.zeros(normalized_shape))&#13;
        self.eps = eps&#13;
        self.data_format = data_format&#13;
        if self.data_format not in ['channels_last', 'channels_first']:&#13;
            raise NotImplementedError &#13;
        self.normalized_shape = (normalized_shape, )&#13;
    &#13;
    def forward(self, x):&#13;
        if self.data_format == 'channels_last':&#13;
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)&#13;
        elif self.data_format == 'channels_first':&#13;
            u = x.mean(1, keepdim=True)&#13;
            s = (x - u).pow(2).mean(1, keepdim=True)&#13;
            x = (x - u) / torch.sqrt(s + self.eps)&#13;
            x = self.weight[:, None, None] * x + self.bias[:, None, None]&#13;
            return x&#13;
&#13;
&#13;
model_urls = {&#13;
    'convnext_tiny_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth',&#13;
    'convnext_small_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth',&#13;
    'convnext_base_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth',&#13;
    'convnext_large_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth',&#13;
    'convnext_tiny_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth',&#13;
    'convnext_small_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth',&#13;
    'convnext_base_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth',&#13;
    'convnext_large_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',&#13;
    'convnext_xlarge_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth',&#13;
}&#13;
&#13;
@register_model&#13;
def convnext_tiny(pretrained=False,in_22k=False, **kwargs):&#13;
    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)&#13;
    if pretrained:&#13;
        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']&#13;
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu', check_hash=True)&#13;
        model.load_state_dict(checkpoint['model'])&#13;
    return model&#13;
&#13;
@register_model&#13;
def convnext_small(pretrained=False,in_22k=False, **kwargs):&#13;
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)&#13;
    if pretrained:&#13;
        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']&#13;
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')&#13;
        model.load_state_dict(checkpoint['model'])&#13;
    return model&#13;
&#13;
@register_model&#13;
def convnext_base(pretrained=False, in_22k=False, **kwargs):&#13;
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)&#13;
    if pretrained:&#13;
        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']&#13;
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')&#13;
        model.load_state_dict(checkpoint['model'])&#13;
    return model&#13;
&#13;
@register_model&#13;
def convnext_large(pretrained=False, in_22k=False, **kwargs):&#13;
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)&#13;
    if pretrained:&#13;
        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']&#13;
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')&#13;
        model.load_state_dict(checkpoint['model'])&#13;
    return model&#13;
&#13;
@register_model&#13;
def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):&#13;
    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)&#13;
    if pretrained:&#13;
        assert in_22k, 'only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True'&#13;
        url = model_urls['convnext_xlarge_22k']&#13;
        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')&#13;
        model.load_state_dict(checkpoint['model'])&#13;
    return model&#13;
```&#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
&#13;
### 代码&#13;
&#13;
训练代码大部分都是模板, 不过, 我发现我还没有一个属于自己的 trainer, 趁着这次训练模型的时候补充一个&#13;
&#13;
使用别人的 trainer 难免会遇到 debug, 而代码不熟的情况, 自己写的 trainer 可以掌握各种细节&#13;
&#13;
在整理了一些以前代码后, 总结出了覆盖许多训练模型情况的流程, 趁着这个时候测试一下现在ai编码的能力, 将流程发给 claude-sonnet 后, 输出了一版代码, 在我的一些小修小补(补充日志)后, 就可以跑起来了&#13;
&#13;
&lt;details&gt;&lt;summary&gt;trainer.py&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```python&#13;
import gc&#13;
import json&#13;
import logging&#13;
import os&#13;
import shutil&#13;
&#13;
import torch&#13;
from torch import optim&#13;
from torch.amp import GradScaler&#13;
from torch.nn.utils import clip_grad_norm_&#13;
from torch.utils.tensorboard import SummaryWriter&#13;
from tqdm import tqdm&#13;
&#13;
example_config = {&#13;
    'model': 'model_name',&#13;
    'checkpoint_dir': './checkpoints',&#13;
    'tensorboard_dir': './tensorboard',&#13;
    'device': 'cuda',&#13;
    'enable_cudnn_benchmark': True,&#13;
    'enable_amp': False,&#13;
    'learning_rate': 1e-4,&#13;
    'betas': [0.9, 0.999],&#13;
    'eps': 1e-8,&#13;
    'enable_compile': False,&#13;
    'weight_decay': 0.05,&#13;
    'max_steps': 100000,&#13;
    'max_grad_norm': 1.0,&#13;
    'save_every': 10000,&#13;
    'gradient_accumulation_steps': 4&#13;
}&#13;
&#13;
&#13;
class Trainer:&#13;
    def __init__(self, config):&#13;
        self.config = config&#13;
        self.setup_logging()&#13;
        self.setup_device()&#13;
        self.setup_model()&#13;
        self.setup_training()&#13;
        &#13;
    def setup_logging(self):&#13;
        '''设置日志'''&#13;
        logging.basicConfig(&#13;
            level=logging.INFO,&#13;
            format='%(asctime)s %(levelname)s %(message)s'&#13;
        )&#13;
        self.logger = logging.getLogger(__name__)&#13;
        self.writer = SummaryWriter(self.config['tensorboard_dir'])&#13;
        &#13;
    def setup_device(self):&#13;
        '''设置设备'''&#13;
        self.device = torch.device(self.config['device'])&#13;
        torch.backends.cudnn.benchmark = self.config.get('enable_cudnn_benchmark', True)&#13;
        if self.device.type == 'cuda':&#13;
            self.logger.info(f'Using device: {self.device} ({torch.cuda.get_device_name()})')&#13;
        else:&#13;
            self.logger.info(f'Using device: {self.device}')&#13;
            &#13;
    def setup_model(self):&#13;
        '''设置模型、损失函数等'''&#13;
        self.model = self.build_model().to(self.device)&#13;
        if self.config.get('enable_compile', False):&#13;
            self.model.compile()&#13;
        self.criterion = self.build_criterion()&#13;
        &#13;
        # 打印模型信息&#13;
        n_parameters = sum(p.numel() for p in self.model.parameters())&#13;
        self.logger.info(f'Number of parameters: {n_parameters:,}')&#13;
        &#13;
    def setup_training(self):&#13;
        '''设置训练相关组件'''&#13;
        # 优化器&#13;
        self.optimizer = self.build_optimizer()&#13;
        &#13;
        # 学习率调度器&#13;
        self.scheduler = self.build_scheduler()&#13;
        &#13;
        # 梯度缩放器(用于混合精度训练)&#13;
        self.scaler = GradScaler(&#13;
            enabled=self.config.get('enable_amp', False)&#13;
        )&#13;
        self.gradient_accumulation_steps = self.config.get('gradient_accumulation_steps', 1)&#13;
        &#13;
        # 加载检查点&#13;
        self.steps = 0&#13;
        self.best_metric = {}&#13;
        self.load_checkpoint()&#13;
        &#13;
    def build_model(self):&#13;
        '''构建模型(需要子类实现)'''&#13;
        raise NotImplementedError&#13;
        &#13;
    def build_criterion(self):&#13;
        '''构建损失函数(需要子类实现)'''&#13;
        raise NotImplementedError&#13;
        &#13;
    def build_optimizer(self):&#13;
        '''构建优化器'''&#13;
        # 区分需要和不需要weight decay的参数&#13;
        decay_params = []&#13;
        no_decay_params = []&#13;
        for name, param in self.model.named_parameters():&#13;
            if 'bias' in name or 'norm' in name:&#13;
                no_decay_params.append(param)&#13;
            else:&#13;
                decay_params.append(param)&#13;
                &#13;
        opt_params = [&#13;
            {'params': decay_params, 'weight_decay': self.config['weight_decay']},&#13;
            {'params': no_decay_params, 'weight_decay': 0.0}&#13;
        ]&#13;
        &#13;
        return optim.AdamW(&#13;
            opt_params,&#13;
            lr=self.config['learning_rate'],&#13;
            betas=self.config.get('betas', (0.9, 0.999)),&#13;
            eps=self.config.get('eps', 1e-8)&#13;
        )&#13;
        &#13;
    def build_scheduler(self):&#13;
        '''构建学习率调度器(需要子类实现)'''&#13;
        return NotImplementedError&#13;
        &#13;
    def build_dataloader(self):&#13;
        '''构建数据加载器(需要子类实现)'''&#13;
        raise NotImplementedError&#13;
        &#13;
    def train_step(self, batch):&#13;
        '''单步训练(需要子类实现)'''&#13;
        raise NotImplementedError&#13;
        &#13;
    def validate(self):&#13;
        '''验证(需要子类实现)'''&#13;
        raise NotImplementedError&#13;
        &#13;
    def save_checkpoint(self, is_best=False):&#13;
        '''保存检查点'''&#13;
        state = {&#13;
            'model': self.model.state_dict(),&#13;
            'optimizer': self.optimizer.state_dict(),&#13;
            'scheduler': self.scheduler.state_dict(),&#13;
            'scaler': self.scaler.state_dict(),&#13;
            'steps': self.steps,&#13;
            'best_metric': self.best_metric,&#13;
            'config': self.config&#13;
        }&#13;
        &#13;
        # 保存最新检查点&#13;
        torch.save(&#13;
            state,&#13;
            os.path.join(self.config['checkpoint_dir'], 'latest.pt')&#13;
        )&#13;
        &#13;
        # 保存最佳检查点&#13;
        if is_best:&#13;
            shutil.copy(&#13;
                os.path.join(self.config['checkpoint_dir'], 'latest.pt'),&#13;
                os.path.join(self.config['checkpoint_dir'], 'best.pt')&#13;
            )&#13;
            &#13;
    def load_checkpoint(self):&#13;
        '''加载检查点'''&#13;
        checkpoint_path = os.path.join(&#13;
            self.config['checkpoint_dir'],&#13;
            'latest.pt'&#13;
        )&#13;
        &#13;
        if os.path.exists(checkpoint_path):&#13;
            checkpoint = torch.load(&#13;
                checkpoint_path,&#13;
                map_location=self.device&#13;
            )&#13;
            &#13;
            self.model.load_state_dict(checkpoint['model'])&#13;
            self.optimizer.load_state_dict(checkpoint['optimizer'])&#13;
            self.scheduler.load_state_dict(checkpoint['scheduler'])&#13;
            self.scaler.load_state_dict(checkpoint['scaler'])&#13;
            self.steps = checkpoint['steps']&#13;
            self.best_metric = checkpoint['best_metric']&#13;
            &#13;
            self.logger.info(f'Loaded checkpoint from {checkpoint_path}')&#13;
            self.logger.info(f'Training will resume from step {self.steps}')&#13;
    &#13;
    @staticmethod&#13;
    def is_better_performance(baseline_dict, compare_dict):&#13;
        '''&#13;
        判断compare_dict中的指标是否全面超过baseline_dict&#13;
        &#13;
        Args:&#13;
            baseline_dict: 基准字典,格式为 {指标名: 值}&#13;
            compare_dict: 比较字典,格式为 {指标名: 值} &#13;
        &#13;
        Returns:&#13;
            bool: 如果compare_dict中所有指标都严格大于baseline_dict则返回True,否则返回False&#13;
        '''&#13;
        if not baseline_dict:&#13;
            return True&#13;
        &#13;
        # 检查两个字典的键是否一致&#13;
        if set(baseline_dict.keys()) != set(compare_dict.keys()):&#13;
            return False&#13;
            &#13;
        # 检查每个指标是否都有提升&#13;
        for metric in baseline_dict:&#13;
            if compare_dict[metric] &lt;= baseline_dict[metric]:&#13;
                return False&#13;
                &#13;
        return True&#13;
            &#13;
    def train(self):&#13;
        '''训练流程'''&#13;
        train_loader = self.build_dataloader()&#13;
        self.model.train()&#13;
        &#13;
        self.logger.info('Start training...')&#13;
        pbar = tqdm(total=self.config['max_steps'], initial=self.steps)&#13;
        &#13;
        while self.steps &lt; self.config['max_steps']:&#13;
            for batch in train_loader:&#13;
                # 训练一步&#13;
                with torch.autocast(device_type=self.config['device'], enabled=self.config.get('enable_amp', False)):&#13;
                    loss = self.train_step(batch)&#13;
                self.scaler.scale(loss / self.gradient_accumulation_steps).backward()&#13;
                &#13;
                if (self.steps + 1) % self.gradient_accumulation_steps == 0:&#13;
                    # 梯度裁剪&#13;
                    if self.config.get('max_grad_norm', 0) &gt; 0:&#13;
                        self.scaler.unscale_(self.optimizer)&#13;
                        clip_grad_norm_(&#13;
                            self.model.parameters(),&#13;
                            self.config['max_grad_norm']&#13;
                        )&#13;
&#13;
                    # 优化器步进&#13;
                    self.scaler.step(self.optimizer)&#13;
                    self.scaler.update()&#13;
                    self.optimizer.zero_grad(set_to_none=True)&#13;
                self.scheduler.step()&#13;
                &#13;
                # 记录&#13;
                self.writer.add_scalar('train/loss', loss, self.steps)&#13;
                self.writer.add_scalar(&#13;
                    'train/lr',&#13;
                    self.scheduler.get_last_lr()[0],&#13;
                    self.steps&#13;
                )&#13;
                &#13;
                self.steps += 1&#13;
                pbar.update(1)&#13;
                &#13;
                # 验证和保存&#13;
                if self.steps % self.config['save_every'] == 0:&#13;
                    metric = self.validate()&#13;
                    for i in metric:&#13;
                        self.logger.info(f'Validation {i}: {metric[i]}')&#13;
                        self.writer.add_scalar(f'val/{i}', metric[i], self.steps)&#13;
                    &#13;
                    is_best = self.is_better_performance(self.best_metric, metric)&#13;
                    if is_best:&#13;
                        self.best_metric = metric&#13;
&#13;
                    self.model.train()&#13;
                    self.save_checkpoint(is_best)&#13;
                    &#13;
                if self.steps &gt;= self.config['max_steps']:&#13;
                    break&#13;
                &#13;
            gc.collect()&#13;
            torch.cuda.empty_cache()&#13;
                    &#13;
        pbar.close()&#13;
        self.logger.info('Training finished!')&#13;
&#13;
&#13;
def main():&#13;
    '''主函数'''&#13;
    # 加载配置&#13;
    with open('config.json') as f:&#13;
        config = json.load(f)&#13;
        &#13;
    # 创建输出目录&#13;
    os.makedirs(config['checkpoint_dir'], exist_ok=True)&#13;
    os.makedirs(config['tensorboard_dir'], exist_ok=True)&#13;
    &#13;
    # 训练&#13;
    trainer = Trainer(config)&#13;
    trainer.train()&#13;
    &#13;
if __name__ == '__main__':&#13;
    try:&#13;
        main()&#13;
    except KeyboardInterrupt:&#13;
        pass&#13;
``` &#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
&lt;details&gt;&lt;summary&gt;train.py(代码未整理完毕)&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```python&#13;
&#13;
```&#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
&gt; TODO 补充trainer的用例与用法&#13;
&gt; TODO 补充超参搜索相关内容, 以及其用例与用法&#13;
&#13;
### 数据增广&#13;
&#13;
原始数据集只有两百多张图片, 这个时候无法避免的要做数据增广, 扩展 nailong 标签的数据, 这里因为是初版方案, 也没有非常精细的增广方案, 这里使用了以下几种方式(代码在如上train.py中):&#13;
&#13;
- 给图片添加颜色遮罩&#13;
    让模型不要将遇到黄色的就判定为奶龙&#13;
- 在负样本中嵌入正样本&#13;
    很经典的增广数据的手法&#13;
- 图片轴对称&#13;
- 等&#13;
。</description><guid isPermaLink="true">https://FairyOwO.github.io/post/nailong-shu-ju-ji-%2C%20-jian-ce-nailong-de-mo-xing-%2C%20-xun-lian-yu-tui-li-%20%28-yi-%29.html</guid><pubDate>Tue, 26 Nov 2024 12:53:02 +0000</pubDate></item><item><title>使用 k3s 搭建 k8s 集群(使用国内镜像)</title><link>https://FairyOwO.github.io/post/shi-yong-%20k3s%20-da-jian-%20k8s%20-ji-qun-%28-shi-yong-guo-nei-jing-xiang-%29.html</link><description>&gt; 历史文章搬运&#13;
&#13;
&gt; 注: 此处k3s为具体的 Kubernetes 发行版, 后面的k8s为 Kubernetes 的缩写, Kubernetes 是开源容器编排平台&#13;
&#13;
需求之初是想对年抛机, 月抛机进行统一的管理, 方便部署相关镜像, 类似于史莱姆的结构(拿到新的机器, 加入集群, 机器时间过期, 自动离线, 伸缩重启分配全由集群本身管理)&#13;
&#13;
使用系统为 Debian&#13;
&#13;
## 服务器搭建&#13;
&#13;
### 搭建集群&#13;
&#13;
主 server sh脚本&#13;
&lt;details&gt;&lt;summary&gt;Details&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```sh&#13;
echo 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
&#13;
# 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换&#13;
deb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware&#13;
deb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' &gt; /etc/apt/sources.list&#13;
&#13;
apt update&#13;
&#13;
curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \&#13;
  INSTALL_K3S_MIRROR=cn \&#13;
  sh -s - server \&#13;
  --cluster-init \&#13;
  --system-default-registry=registry.cn-hangzhou.aliyuncs.com&#13;
&#13;
cat /var/lib/rancher/k3s/server/token&#13;
&#13;
cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt; EOF&#13;
mirrors:&#13;
  docker.io:&#13;
    endpoint:&#13;
      - 'https://dockerproxy.net'&#13;
      - 'https://registry.cn-hangzhou.aliyuncs.com/'&#13;
      - 'https://mirror.ccs.tencentyun.com'&#13;
  k8s.gcr.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/google_containers'&#13;
  ghcr.io:&#13;
    endpoint:&#13;
      - 'https://ghcr.dockerproxy.net'&#13;
      - 'https://ghcr.m.daocloud.io/'&#13;
  gcr.io:&#13;
    endpoint:&#13;
      - 'https://gcr.dockerproxy.net'&#13;
      - 'https://gcr.m.daocloud.io/'&#13;
  quay.io:&#13;
    endpoint:&#13;
      - 'https://quay.dockerproxy.net'&#13;
      - 'https://quay.tencentcloudcr.com/'&#13;
  registry.k8s.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/v2/google_containers'&#13;
EOF&#13;
systemctl restart k3s&#13;
```&#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
副 server sh脚本&#13;
&#13;
&lt;details&gt;&lt;summary&gt;Details&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```sh&#13;
echo 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
&#13;
# 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换&#13;
deb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware&#13;
deb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' &gt; /etc/apt/sources.list&#13;
&#13;
apt update&#13;
&#13;
curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \&#13;
  INSTALL_K3S_MIRROR=cn \&#13;
  sh -s - server \&#13;
  --cluster-init \&#13;
  --system-default-registry=registry.cn-hangzhou.aliyuncs.com&#13;
&#13;
cat /var/lib/rancher/k3s/server/token&#13;
&#13;
cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt; EOF&#13;
mirrors:&#13;
  docker.io:&#13;
    endpoint:&#13;
      - 'https://dockerproxy.net'&#13;
      - 'https://registry.cn-hangzhou.aliyuncs.com/'&#13;
      - 'https://mirror.ccs.tencentyun.com'&#13;
  k8s.gcr.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/google_containers'&#13;
  ghcr.io:&#13;
    endpoint:&#13;
      - 'https://ghcr.dockerproxy.net'&#13;
      - 'https://ghcr.m.daocloud.io/'&#13;
  gcr.io:&#13;
    endpoint:&#13;
      - 'https://gcr.dockerproxy.net'&#13;
      - 'https://gcr.m.daocloud.io/'&#13;
  quay.io:&#13;
    endpoint:&#13;
      - 'https://quay.dockerproxy.net'&#13;
      - 'https://quay.tencentcloudcr.com/'&#13;
  registry.k8s.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/v2/google_containers'&#13;
EOF&#13;
systemctl restart k3s&#13;
```&#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
client sh脚本&#13;
&#13;
&lt;details&gt;&lt;summary&gt;Details&lt;/summary&gt;&#13;
&lt;p&gt;&#13;
&#13;
```sh&#13;
echo 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware&#13;
&#13;
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware&#13;
&#13;
# 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换&#13;
deb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware&#13;
deb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' &gt; /etc/apt/sources.list&#13;
&#13;
apt update&#13;
&#13;
curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \&#13;
  INSTALL_K3S_MIRROR=cn \&#13;
  K3S_URL=https://ip:6443 \&#13;
  K3S_TOKEN=your_token \&#13;
  sh -&#13;
&#13;
mkdir -p /etc/rancher/k3s&#13;
cat &gt;&gt; /etc/rancher/k3s/registries.yaml &lt;&lt; EOF&#13;
mirrors:&#13;
  docker.io:&#13;
    endpoint:&#13;
      - 'https://dockerproxy.net'&#13;
      - 'https://registry.cn-hangzhou.aliyuncs.com/'&#13;
      - 'https://mirror.ccs.tencentyun.com'&#13;
  k8s.gcr.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/google_containers'&#13;
  ghcr.io:&#13;
    endpoint:&#13;
      - 'https://ghcr.dockerproxy.net'&#13;
      - 'https://ghcr.m.daocloud.io/'&#13;
  gcr.io:&#13;
    endpoint:&#13;
      - 'https://gcr.dockerproxy.net'&#13;
      - 'https://gcr.m.daocloud.io/'&#13;
  quay.io:&#13;
    endpoint:&#13;
      - 'https://quay.dockerproxy.net'&#13;
      - 'https://quay.tencentcloudcr.com/'&#13;
  registry.k8s.io:&#13;
    endpoint:&#13;
      - 'https://k8s.dockerproxy.net'&#13;
      - 'https://registry.aliyuncs.com/v2/google_containers'&#13;
EOF&#13;
systemctl restart k3s-agent&#13;
```&#13;
&#13;
&lt;/p&gt;&#13;
&lt;/details&gt; &#13;
&#13;
&gt; 注: k3s 搭建集群的方案需要保证主服务器不离线, 否则整个集群会离线, 考虑到k3s占用低, 机器一般是性能不高的类型, 我也有长期续费的服务器, 故使用这个方案&#13;
&#13;
在主server服务器使用&#13;
&#13;
```sh&#13;
kubectl get nodes -A&#13;
```&#13;
出现每台机子的信息, 代表集群内部网络通信没问题&#13;
&#13;
在主server服务器使用&#13;
```sh&#13;
kubectl get pods --all-namespaces&#13;
```&#13;
在所有服务在 `RUNNING` 状态时, 为安装成功 (这些服务都是内部通信与均衡负载的镜像), 如果是卡在 `container creating`, 则安装失败, 原因是镜像没正确配置&#13;
&#13;
### 安装helm (虽然不知道干什么用, 集群内也自带一个helm)&#13;
&#13;
1. 手动安装&#13;
    1. 下载需要的版本 [下载地址](https://github.com/helm/helm/releases)&#13;
    2. 解压, 上传到服务器, chmod给执行权限&#13;
    3. 移动到环境变量的目录中&#13;
        ```sh&#13;
        mv helm /usr/local/bin/helm&#13;
        ```&#13;
2. 使用脚本安装&#13;
    ```sh&#13;
    https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash&#13;
    ```&#13;
&#13;
## 面板安装&#13;
&#13;
为了简单, 面板选择的是 kubepi&#13;
&#13;
[文档](https://github.com/1Panel-dev/KubePi/wiki/2%E3%80%81%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2#kubernetes)&#13;
&#13;
这里选择的是非持久化部署, 在直接部署在刚刚建好的集群之中&#13;
&#13;
&gt; 持久化部署会有莫名其妙的分配问题, 应该是跟分配本地空间有关系, 我也不需要持久化集群信息(因为只有一个集群), 所以没什么关系&#13;
&#13;
```sh&#13;
# 安装&#13;
sudo kubectl apply -f https://raw.githubusercontent.com/1Panel-dev/KubePi/master/docs/deploy/kubectl/kubepi.yaml&#13;
```&#13;
&#13;
安装完成后, 根据安装教程, 获取访问地址&#13;
&#13;
```sh&#13;
# 获取 NodeIp&#13;
export NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')&#13;
# 获取 NodePort&#13;
export NODE_PORT=$(kubectl -n kube-system get services kubepi -o jsonpath='{.spec.ports[0].nodePort}')&#13;
# 获取 Address&#13;
echo http://$NODE_IP:$NODE_PORT&#13;
```&#13;
&#13;
&gt; 注: 内网组机子的时候这里会是内网地址, 需要使用端口转发转发到 `0.0.0.0` 之后才能外网访问&#13;
&gt; ```sh&#13;
&gt; kubectl port-forward --address 0.0.0.0 kubepi-d8477f9d8-drthz -n kube-system 2999:80&#13;
&gt; ```&#13;
&gt; 此命令不会中断, 会持续运行, 需要把这条命令中的 `kubepi-d8477f9d8-drthz` 换成实际名字&#13;
&#13;
登陆系统&#13;
&#13;
```text&#13;
地址: http://$NODE_IP:$NODE_PORT&#13;
用户名: admin&#13;
密码: kubepi&#13;
```&#13;
&#13;
登陆后记得修改密码&#13;
&#13;
导入集群&#13;
&#13;
在主服务器, 获取&#13;
&#13;
```sh&#13;
cd /etc/rancher/k3s&#13;
cat k3s.yaml&#13;
```&#13;
在 kubepi 导入集群, 认证模式选择 kubeconfig文件, 把这个文件复制进去&#13;
&#13;
在集群配置中, 配置一下网络, 使之可以直接通过外网端口访问&#13;
&#13;
具体配置流程忘了, 此方法由同事指点&#13;
&#13;
## 部署项目&#13;
&#13;
在 kubepi 中 选择集群, 应用市场, chart 仓库, 填入相关信息, 这里我使用的是:&#13;
```text&#13;
开源社: http://mirror.kaiyuanshe.cn/kubernetes/charts/&#13;
开源应用市场: https://charts.grapps.cn&#13;
```&#13;
&#13;
点开应用就有很多项目跳出来可以部署。</description><guid isPermaLink="true">https://FairyOwO.github.io/post/shi-yong-%20k3s%20-da-jian-%20k8s%20-ji-qun-%28-shi-yong-guo-nei-jing-xiang-%29.html</guid><pubDate>Fri, 22 Nov 2024 09:34:51 +0000</pubDate></item><item><title>待阅读</title><link>https://FairyOwO.github.io/post/dai-yue-du.html</link><description>## 对强化学习进行系统性的学习&#13;
&gt; 此前因为对一些强化学习项目感兴趣, 而草草学习了一部分(感谢 ai, 解释了大部分内容), 这里准备系统性学习一份&#13;
1. [Reinforcement Learning: An Introduction](https://rl.qiwihui.com/zh-cn/latest/) 强化学习导论&#13;
2. [Openai Spinning Up](https://spinningup.qiwihui.com/zh-cn/latest/) OpenAI 深度强化学习&#13;
&#13;
## 知乎 大模型相关&#13;
&#13;
## 苏剑林博客&#13;
&#13;
## 图像生成, llm对prompt优化&#13;
&gt; demo需要。</description><guid isPermaLink="true">https://FairyOwO.github.io/post/dai-yue-du.html</guid><pubDate>Fri, 22 Nov 2024 08:44:27 +0000</pubDate></item><item><title>Test</title><link>https://FairyOwO.github.io/post/Test.html</link><description>这是一个测试!&#13;
This is a test!。</description><guid isPermaLink="true">https://FairyOwO.github.io/post/Test.html</guid><pubDate>Fri, 22 Nov 2024 03:26:34 +0000</pubDate></item></channel></rss>