{"singlePage": [], "startSite": "11/22/2024", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark_colorblind", "urlMode": "pinyin", "script": "", "style": "", "head": "", "indexScript": "", "indexStyle": "", "bottomText": "\u8f6c\u8f7d\u65e0\u9700\u6ce8\u660e\u51fa\u5904", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 1, "allHead": "", "title": "FairyOwO \u7684 Blog", "subTitle": "\u8bb0\u5f55\u4e00\u4e9b\u7410\u4e8b", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "email": "740614599@qq.com", "postListJson": {"P1": {"htmlDir": "docs/post/Test.html", "labels": ["blog"], "postTitle": "Test", "postUrl": "post/Test.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/1", "commentNum": 2, "wordCount": 24, "description": "\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5!\r\nThis is a test!\u3002", "top": 0, "createdAt": 1732245994, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P2": {"htmlDir": "docs/post/dai-yue-du.html", "labels": ["idea"], "postTitle": "\u5f85\u9605\u8bfb", "postUrl": "post/dai-yue-du.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/2", "commentNum": 0, "wordCount": 339, "description": "## \u5bf9\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u5b66\u4e60\r\n> \u6b64\u524d\u56e0\u4e3a\u5bf9\u4e00\u4e9b\u5f3a\u5316\u5b66\u4e60\u9879\u76ee\u611f\u5174\u8da3, \u800c\u8349\u8349\u5b66\u4e60\u4e86\u4e00\u90e8\u5206(\u611f\u8c22 ai, \u89e3\u91ca\u4e86\u5927\u90e8\u5206\u5185\u5bb9), \u8fd9\u91cc\u51c6\u5907\u7cfb\u7edf\u6027\u5b66\u4e60\u4e00\u4efd\r\n1. [Reinforcement Learning: An Introduction](https://rl.qiwihui.com/zh-cn/latest/) \u5f3a\u5316\u5b66\u4e60\u5bfc\u8bba\r\n2. [Openai Spinning Up](https://spinningup.qiwihui.com/zh-cn/latest/) OpenAI \u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\r\n\r\n## \u77e5\u4e4e \u5927\u6a21\u578b\u76f8\u5173\r\n\r\n## \u82cf\u5251\u6797\u535a\u5ba2\r\n\r\n## \u56fe\u50cf\u751f\u6210, llm\u5bf9prompt\u4f18\u5316\r\n> demo\u9700\u8981\r\n\r\n## \u56fe\u50cf\u751f\u6210\u6a21\u578b 2024\u5e74 \u8bad\u7ec3\u65b9\u6cd5\u3002", "top": 0, "createdAt": 1732265067, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P3": {"htmlDir": "docs/post/shi-yong- k3s -da-jian- k8s -ji-qun-(-shi-yong-guo-nei-jing-xiang-).html", "labels": ["blog"], "postTitle": "\u4f7f\u7528 k3s \u642d\u5efa k8s \u96c6\u7fa4(\u4f7f\u7528\u56fd\u5185\u955c\u50cf)", "postUrl": "post/shi-yong-%20k3s%20-da-jian-%20k8s%20-ji-qun-%28-shi-yong-guo-nei-jing-xiang-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/3", "commentNum": 0, "wordCount": 8564, "description": "> \u5386\u53f2\u6587\u7ae0\u642c\u8fd0\r\n\r\n> \u6ce8: \u6b64\u5904k3s\u4e3a\u5177\u4f53\u7684 Kubernetes \u53d1\u884c\u7248, \u540e\u9762\u7684k8s\u4e3a Kubernetes \u7684\u7f29\u5199, Kubernetes \u662f\u5f00\u6e90\u5bb9\u5668\u7f16\u6392\u5e73\u53f0\r\n\r\n\u9700\u6c42\u4e4b\u521d\u662f\u60f3\u5bf9\u5e74\u629b\u673a, \u6708\u629b\u673a\u8fdb\u884c\u7edf\u4e00\u7684\u7ba1\u7406, \u65b9\u4fbf\u90e8\u7f72\u76f8\u5173\u955c\u50cf, \u7c7b\u4f3c\u4e8e\u53f2\u83b1\u59c6\u7684\u7ed3\u6784(\u62ff\u5230\u65b0\u7684\u673a\u5668, \u52a0\u5165\u96c6\u7fa4, \u673a\u5668\u65f6\u95f4\u8fc7\u671f, \u81ea\u52a8\u79bb\u7ebf, \u4f38\u7f29\u91cd\u542f\u5206\u914d\u5168\u7531\u96c6\u7fa4\u672c\u8eab\u7ba1\u7406)\r\n\r\n\u4f7f\u7528\u7cfb\u7edf\u4e3a Debian\r\n\r\n## \u670d\u52a1\u5668\u642d\u5efa\r\n\r\n### \u642d\u5efa\u96c6\u7fa4\r\n\r\n\u4e3b server sh\u811a\u672c\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  sh -s - server \\\r\n  --cluster-init \\\r\n  --system-default-registry=registry.cn-hangzhou.aliyuncs.com\r\n\r\ncat /var/lib/rancher/k3s/server/token\r\n\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\u526f server sh\u811a\u672c\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  sh -s - server \\\r\n  --cluster-init \\\r\n  --system-default-registry=registry.cn-hangzhou.aliyuncs.com\r\n\r\ncat /var/lib/rancher/k3s/server/token\r\n\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\nclient sh\u811a\u672c\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  K3S_URL=https://ip:6443 \\\r\n  K3S_TOKEN=your_token \\\r\n  sh -\r\n\r\nmkdir -p /etc/rancher/k3s\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s-agent\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n> \u6ce8: k3s \u642d\u5efa\u96c6\u7fa4\u7684\u65b9\u6848\u9700\u8981\u4fdd\u8bc1\u4e3b\u670d\u52a1\u5668\u4e0d\u79bb\u7ebf, \u5426\u5219\u6574\u4e2a\u96c6\u7fa4\u4f1a\u79bb\u7ebf, \u8003\u8651\u5230k3s\u5360\u7528\u4f4e, \u673a\u5668\u4e00\u822c\u662f\u6027\u80fd\u4e0d\u9ad8\u7684\u7c7b\u578b, \u6211\u4e5f\u6709\u957f\u671f\u7eed\u8d39\u7684\u670d\u52a1\u5668, \u6545\u4f7f\u7528\u8fd9\u4e2a\u65b9\u6848\r\n\r\n\u5728\u4e3bserver\u670d\u52a1\u5668\u4f7f\u7528\r\n\r\n```sh\r\nkubectl get nodes -A\r\n```\r\n\u51fa\u73b0\u6bcf\u53f0\u673a\u5b50\u7684\u4fe1\u606f, \u4ee3\u8868\u96c6\u7fa4\u5185\u90e8\u7f51\u7edc\u901a\u4fe1\u6ca1\u95ee\u9898\r\n\r\n\u5728\u4e3bserver\u670d\u52a1\u5668\u4f7f\u7528\r\n```sh\r\nkubectl get pods --all-namespaces\r\n```\r\n\u5728\u6240\u6709\u670d\u52a1\u5728 `RUNNING` \u72b6\u6001\u65f6, \u4e3a\u5b89\u88c5\u6210\u529f (\u8fd9\u4e9b\u670d\u52a1\u90fd\u662f\u5185\u90e8\u901a\u4fe1\u4e0e\u5747\u8861\u8d1f\u8f7d\u7684\u955c\u50cf), \u5982\u679c\u662f\u5361\u5728 `container creating`, \u5219\u5b89\u88c5\u5931\u8d25, \u539f\u56e0\u662f\u955c\u50cf\u6ca1\u6b63\u786e\u914d\u7f6e\r\n\r\n### \u5b89\u88c5helm (\u867d\u7136\u4e0d\u77e5\u9053\u5e72\u4ec0\u4e48\u7528, \u96c6\u7fa4\u5185\u4e5f\u81ea\u5e26\u4e00\u4e2ahelm)\r\n\r\n1. \u624b\u52a8\u5b89\u88c5\r\n    1. \u4e0b\u8f7d\u9700\u8981\u7684\u7248\u672c [\u4e0b\u8f7d\u5730\u5740](https://github.com/helm/helm/releases)\r\n    2. \u89e3\u538b, \u4e0a\u4f20\u5230\u670d\u52a1\u5668, chmod\u7ed9\u6267\u884c\u6743\u9650\r\n    3. \u79fb\u52a8\u5230\u73af\u5883\u53d8\u91cf\u7684\u76ee\u5f55\u4e2d\r\n        ```sh\r\n        mv helm /usr/local/bin/helm\r\n        ```\r\n2. \u4f7f\u7528\u811a\u672c\u5b89\u88c5\r\n    ```sh\r\n    https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\r\n    ```\r\n\r\n## \u9762\u677f\u5b89\u88c5\r\n\r\n\u4e3a\u4e86\u7b80\u5355, \u9762\u677f\u9009\u62e9\u7684\u662f kubepi\r\n\r\n[\u6587\u6863](https://github.com/1Panel-dev/KubePi/wiki/2%E3%80%81%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2#kubernetes)\r\n\r\n\u8fd9\u91cc\u9009\u62e9\u7684\u662f\u975e\u6301\u4e45\u5316\u90e8\u7f72, \u5728\u76f4\u63a5\u90e8\u7f72\u5728\u521a\u521a\u5efa\u597d\u7684\u96c6\u7fa4\u4e4b\u4e2d\r\n\r\n> \u6301\u4e45\u5316\u90e8\u7f72\u4f1a\u6709\u83ab\u540d\u5176\u5999\u7684\u5206\u914d\u95ee\u9898, \u5e94\u8be5\u662f\u8ddf\u5206\u914d\u672c\u5730\u7a7a\u95f4\u6709\u5173\u7cfb, \u6211\u4e5f\u4e0d\u9700\u8981\u6301\u4e45\u5316\u96c6\u7fa4\u4fe1\u606f(\u56e0\u4e3a\u53ea\u6709\u4e00\u4e2a\u96c6\u7fa4), \u6240\u4ee5\u6ca1\u4ec0\u4e48\u5173\u7cfb\r\n\r\n```sh\r\n# \u5b89\u88c5\r\nsudo kubectl apply -f https://raw.githubusercontent.com/1Panel-dev/KubePi/master/docs/deploy/kubectl/kubepi.yaml\r\n```\r\n\r\n\u5b89\u88c5\u5b8c\u6210\u540e, \u6839\u636e\u5b89\u88c5\u6559\u7a0b, \u83b7\u53d6\u8bbf\u95ee\u5730\u5740\r\n\r\n```sh\r\n# \u83b7\u53d6 NodeIp\r\nexport NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')\r\n# \u83b7\u53d6 NodePort\r\nexport NODE_PORT=$(kubectl -n kube-system get services kubepi -o jsonpath='{.spec.ports[0].nodePort}')\r\n# \u83b7\u53d6 Address\r\necho http://$NODE_IP:$NODE_PORT\r\n```\r\n\r\n> \u6ce8: \u5185\u7f51\u7ec4\u673a\u5b50\u7684\u65f6\u5019\u8fd9\u91cc\u4f1a\u662f\u5185\u7f51\u5730\u5740, \u9700\u8981\u4f7f\u7528\u7aef\u53e3\u8f6c\u53d1\u8f6c\u53d1\u5230 `0.0.0.0` \u4e4b\u540e\u624d\u80fd\u5916\u7f51\u8bbf\u95ee\r\n> ```sh\r\n> kubectl port-forward --address 0.0.0.0 kubepi-d8477f9d8-drthz -n kube-system 2999:80\r\n> ```\r\n> \u6b64\u547d\u4ee4\u4e0d\u4f1a\u4e2d\u65ad, \u4f1a\u6301\u7eed\u8fd0\u884c, \u9700\u8981\u628a\u8fd9\u6761\u547d\u4ee4\u4e2d\u7684 `kubepi-d8477f9d8-drthz` \u6362\u6210\u5b9e\u9645\u540d\u5b57\r\n\r\n\u767b\u9646\u7cfb\u7edf\r\n\r\n```text\r\n\u5730\u5740: http://$NODE_IP:$NODE_PORT\r\n\u7528\u6237\u540d: admin\r\n\u5bc6\u7801: kubepi\r\n```\r\n\r\n\u767b\u9646\u540e\u8bb0\u5f97\u4fee\u6539\u5bc6\u7801\r\n\r\n\u5bfc\u5165\u96c6\u7fa4\r\n\r\n\u5728\u4e3b\u670d\u52a1\u5668, \u83b7\u53d6\r\n\r\n```sh\r\ncd /etc/rancher/k3s\r\ncat k3s.yaml\r\n```\r\n\u5728 kubepi \u5bfc\u5165\u96c6\u7fa4, \u8ba4\u8bc1\u6a21\u5f0f\u9009\u62e9 kubeconfig\u6587\u4ef6, \u628a\u8fd9\u4e2a\u6587\u4ef6\u590d\u5236\u8fdb\u53bb\r\n\r\n\u5728\u96c6\u7fa4\u914d\u7f6e\u4e2d, \u914d\u7f6e\u4e00\u4e0b\u7f51\u7edc, \u4f7f\u4e4b\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u5916\u7f51\u7aef\u53e3\u8bbf\u95ee\r\n\r\n\u5177\u4f53\u914d\u7f6e\u6d41\u7a0b\u5fd8\u4e86, \u6b64\u65b9\u6cd5\u7531\u540c\u4e8b\u6307\u70b9\r\n\r\n## \u90e8\u7f72\u9879\u76ee\r\n\r\n\u5728 kubepi \u4e2d \u9009\u62e9\u96c6\u7fa4, \u5e94\u7528\u5e02\u573a, chart \u4ed3\u5e93, \u586b\u5165\u76f8\u5173\u4fe1\u606f, \u8fd9\u91cc\u6211\u4f7f\u7528\u7684\u662f:\r\n```text\r\n\u5f00\u6e90\u793e: http://mirror.kaiyuanshe.cn/kubernetes/charts/\r\n\u5f00\u6e90\u5e94\u7528\u5e02\u573a: https://charts.grapps.cn\r\n```\r\n\r\n\u70b9\u5f00\u5e94\u7528\u5c31\u6709\u5f88\u591a\u9879\u76ee\u8df3\u51fa\u6765\u53ef\u4ee5\u90e8\u7f72\u3002", "top": 0, "createdAt": 1732268091, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P4": {"htmlDir": "docs/post/nailong-shu-ju-ji-, -jian-ce-nailong-de-mo-xing-, -xun-lian-yu-tui-li- (-yi-).html", "labels": ["blog"], "postTitle": "nailong\u6570\u636e\u96c6, \u68c0\u6d4bnailong\u7684\u6a21\u578b, \u8bad\u7ec3\u4e0e\u63a8\u7406 (\u4e00)", "postUrl": "post/nailong-shu-ju-ji-%2C%20-jian-ce-nailong-de-mo-xing-%2C%20-xun-lian-yu-tui-li-%20%28-yi-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/4", "commentNum": 0, "wordCount": 48329, "description": "> \u56de\u5f52 \u8001\u672c\u884c\r\n\r\n\u5076\u7136\u5f97\u5230 nailong \u6570\u636e\u96c6, \u5206\u4e3a\u4e24\u5757, \u4e00\u79cd\u662f\u7ed9[\u5206\u7c7b\u6a21\u578b\u4f7f\u7528\u7684\u6570\u636e\u96c6](https://huggingface.co/datasets/refoundd/NailongClassification), \u53e6\u4e00\u79cd\u662f\u7ed9[\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u4f7f\u7528\u7684\u6570\u636e\u96c6](https://huggingface.co/datasets/refoundd/NailongDetection)\r\n\r\n> \u540e\u8005\u7684\u6570\u636e\u91cf\u4e0d\u662f\u975e\u5e38\u591a(6\u5f20), \u7b49\u5230\u6709\u8db3\u591f\u591a\u7684\u6570\u636e\u6216\u8005\u6211\u4e00\u65f6\u5174\u8d77\u624b\u52a8\u6807\u6ce8\u5728\u8fdb\u884c\u7814\u7a76\r\n\r\n## \u521d\u7248\u65b9\u6848\r\n\r\n### \u6570\u636e\u96c6\u9009\u62e9\r\n\r\n\u5728\u6211\u521a\u63a5\u89e6\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u65f6\u5019, \u6570\u636e\u96c6\u662f\u53ea\u6709\u5976\u9f99\u7684(\u65e0\u5176\u4ed6\u6807\u7b7e\u7684\u6570\u636e), \u8fd9\u4e2a\u65f6\u5019\u7b2c\u4e00\u4e2a\u60f3\u6cd5\u5c31\u662f\u5f15\u5165\u5176\u4ed6\u5206\u7c7b, \u8fd9\u91cc\u91c7\u7528cifer10\u6570\u636e\u96c6\u7684\u6570\u636e, \u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u589e\u5e7f\r\n\r\n\u7136\u800c, cifer10 \u7684\u6570\u636e\u5206\u5e03\u6bd5\u7adf\u4e0e\u5e38\u89c1\u7fa4\u804a\u5185\u53d1\u9001\u7684\u56fe\u7247\u4e0d\u540c, \u6211\u89c9\u5f97\u4f1a\u5f71\u54cd\u6700\u7ec8\u80fd\u529b, \u5e94\u8be5\u6709\u9009\u62e9\u6027\u800c\u4e0d\u662f\u968f\u610f\u6dfb\u52a0\u5176\u4ed6\u7c7b\u578b\u7684\u56fe\u7247, \u5728\u4e00\u756a\u641c\u7d22\u4e4b\u540e, \u9009\u4e2d\u4e86 [\u8868\u60c5\u5305\u6570\u636e\u96c6](https://github.com/LLM-Red-Team/emo-visual-data)\r\n\r\n\u867d\u7136\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u539f\u8ba1\u5212\u662f\u7528\u6765\u68c0\u6d4b VLLM \u7684\u80fd\u529b, \u4f46\u6211\u8ba4\u4e3a\u5728\u6211\u4eec\u8fd9\u4e2a\u4efb\u52a1\u4e2d\u4e5f\u53ef\u4ee5\u4f7f\u7528\r\n\r\n### \u6a21\u578b\r\n\r\n\u5728\u6572\u5b9a\u6570\u636e\u96c6\u4e4b\u540e, \u5c31\u5f00\u59cb\u6311\u9009\u6a21\u578b\u4e86, \u56e0\u4e3a\u662f\u4e2a\u4eba\u5c0f\u9879\u76ee, \u8fd9\u91cc\u91c7\u7528\u6211\u4e2a\u4eba\u559c\u597d\u7684\u6a21\u578b\u9009\u62e9, \u4f7f\u7528\u4e86 [convnext \u7cfb\u6a21\u578b](https://github.com/facebookresearch/ConvNeXt)\r\n\r\n\u8fd9\u4e2a\u6a21\u578b\u7684\u8bba\u6587\u662f\u4e00\u7bc7\u975e\u5e38\u7ecf\u5178\u7684\u5b9e\u9a8c\u6587, \u91cc\u9762\u5927\u91cf\u63a2\u7d22\u4e86\u4e00\u4e9b\u6280\u5de7\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd (\u5404\u7c7b\u6d88\u878d\u5b9e\u9a8c), \u867d\u7136\u4ed6\u662f 2020 \u5e74\u63a8\u51fa, \u4f46\u4ed6\u5bf9\u73b0\u5728\u7684\u5377\u79ef\u7f51\u7edc\u7684\u8bad\u7ec3\u6280\u5de7\u7684\u6307\u5f15\u5f88\u5927\r\n\r\n\u5177\u4f53\u7ec6\u8282\u53ef\u4ee5\u641c\u7d22\u76f8\u5173\u7684\u6a21\u578b\u89e3\u6790, \u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\r\n\r\n<details><summary>model.py</summary>\r\n<p>\r\n\r\n```python\r\n# copy from facebook/ConvNeXt\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom timm.models.layers import trunc_normal_, DropPath\r\nfrom timm.models.registry import register_model\r\n\r\nclass Block(nn.Module):\r\n    r''' ConvNeXt Block. There are two equivalent implementations:\r\n    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\r\n    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\r\n    We use (2) as we find it slightly faster in PyTorch\r\n    \r\n    Args:\r\n        dim (int): Number of input channels.\r\n        drop_path (float): Stochastic depth rate. Default: 0.0\r\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\r\n    '''\r\n    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\r\n        super().__init__()\r\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\r\n        self.norm = LayerNorm(dim, eps=1e-6)\r\n        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\r\n        self.act = nn.GELU()\r\n        self.pwconv2 = nn.Linear(4 * dim, dim)\r\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \r\n                                    requires_grad=True) if layer_scale_init_value > 0 else None\r\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\r\n\r\n    def forward(self, x):\r\n        input = x\r\n        x = self.dwconv(x)\r\n        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\r\n        x = self.norm(x)\r\n        x = self.pwconv1(x)\r\n        x = self.act(x)\r\n        x = self.pwconv2(x)\r\n        if self.gamma is not None:\r\n            x = self.gamma * x\r\n        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\r\n\r\n        x = input + self.drop_path(x)\r\n        return x\r\n\r\nclass ConvNeXt(nn.Module):\r\n    r''' ConvNeXt\r\n        A PyTorch impl of : `A ConvNet for the 2020s`  -\r\n          https://arxiv.org/pdf/2201.03545.pdf\r\n\r\n    Args:\r\n        in_chans (int): Number of input image channels. Default: 3\r\n        num_classes (int): Number of classes for classification head. Default: 1000\r\n        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\r\n        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\r\n        drop_path_rate (float): Stochastic depth rate. Default: 0.\r\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\r\n        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\r\n    '''\r\n    def __init__(self, in_chans=3, num_classes=1000, \r\n                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \r\n                 layer_scale_init_value=1e-6, head_init_scale=1.,\r\n                 ):\r\n        super().__init__()\r\n\r\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\r\n        stem = nn.Sequential(\r\n            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\r\n            LayerNorm(dims[0], eps=1e-6, data_format='channels_first')\r\n        )\r\n        self.downsample_layers.append(stem)\r\n        for i in range(3):\r\n            downsample_layer = nn.Sequential(\r\n                    LayerNorm(dims[i], eps=1e-6, data_format='channels_first'),\r\n                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\r\n            )\r\n            self.downsample_layers.append(downsample_layer)\r\n\r\n        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\r\n        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \r\n        cur = 0\r\n        for i in range(4):\r\n            stage = nn.Sequential(\r\n                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \r\n                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\r\n            )\r\n            self.stages.append(stage)\r\n            cur += depths[i]\r\n\r\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\r\n        self.head = nn.Linear(dims[-1], num_classes)\r\n\r\n        self.apply(self._init_weights)\r\n        self.head.weight.data.mul_(head_init_scale)\r\n        self.head.bias.data.mul_(head_init_scale)\r\n\r\n    def _init_weights(self, m):\r\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\r\n            trunc_normal_(m.weight, std=.02)\r\n            nn.init.constant_(m.bias, 0)\r\n\r\n    def forward_features(self, x):\r\n        for i in range(4):\r\n            x = self.downsample_layers[i](x)\r\n            x = self.stages[i](x)\r\n        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\r\n\r\n    def forward(self, x):\r\n        x = self.forward_features(x)\r\n        x = self.head(x)\r\n        return x\r\n\r\nclass LayerNorm(nn.Module):\r\n    r''' LayerNorm that supports two data formats: channels_last (default) or channels_first. \r\n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \r\n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \r\n    with shape (batch_size, channels, height, width).\r\n    '''\r\n    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_last'):\r\n        super().__init__()\r\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\r\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\r\n        self.eps = eps\r\n        self.data_format = data_format\r\n        if self.data_format not in ['channels_last', 'channels_first']:\r\n            raise NotImplementedError \r\n        self.normalized_shape = (normalized_shape, )\r\n    \r\n    def forward(self, x):\r\n        if self.data_format == 'channels_last':\r\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\r\n        elif self.data_format == 'channels_first':\r\n            u = x.mean(1, keepdim=True)\r\n            s = (x - u).pow(2).mean(1, keepdim=True)\r\n            x = (x - u) / torch.sqrt(s + self.eps)\r\n            x = self.weight[:, None, None] * x + self.bias[:, None, None]\r\n            return x\r\n\r\n\r\nmodel_urls = {\r\n    'convnext_tiny_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth',\r\n    'convnext_small_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth',\r\n    'convnext_base_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth',\r\n    'convnext_large_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth',\r\n    'convnext_tiny_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth',\r\n    'convnext_small_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth',\r\n    'convnext_base_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth',\r\n    'convnext_large_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',\r\n    'convnext_xlarge_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth',\r\n}\r\n\r\n@register_model\r\ndef convnext_tiny(pretrained=False,in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu', check_hash=True)\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_small(pretrained=False,in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_base(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_large(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\r\n    if pretrained:\r\n        assert in_22k, 'only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True'\r\n        url = model_urls['convnext_xlarge_22k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\r\n### \u4ee3\u7801\r\n\r\n\u8bad\u7ec3\u4ee3\u7801\u5927\u90e8\u5206\u90fd\u662f\u6a21\u677f, \u4e0d\u8fc7, \u6211\u53d1\u73b0\u6211\u8fd8\u6ca1\u6709\u4e00\u4e2a\u5c5e\u4e8e\u81ea\u5df1\u7684 trainer, \u8d81\u7740\u8fd9\u6b21\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u8865\u5145\u4e00\u4e2a\r\n\r\n\u4f7f\u7528\u522b\u4eba\u7684 trainer \u96be\u514d\u4f1a\u9047\u5230 debug, \u800c\u4ee3\u7801\u4e0d\u719f\u7684\u60c5\u51b5, \u81ea\u5df1\u5199\u7684 trainer \u53ef\u4ee5\u638c\u63e1\u5404\u79cd\u7ec6\u8282\r\n\r\n\u5728\u6574\u7406\u4e86\u4e00\u4e9b\u4ee5\u524d\u4ee3\u7801\u540e, \u603b\u7ed3\u51fa\u4e86\u8986\u76d6\u8bb8\u591a\u8bad\u7ec3\u6a21\u578b\u60c5\u51b5\u7684\u6d41\u7a0b, \u8d81\u7740\u8fd9\u4e2a\u65f6\u5019\u6d4b\u8bd5\u4e00\u4e0b\u73b0\u5728ai\u7f16\u7801\u7684\u80fd\u529b, \u5c06\u6d41\u7a0b\u53d1\u7ed9 claude-sonnet \u540e, \u8f93\u51fa\u4e86\u4e00\u7248\u4ee3\u7801, \u5728\u6211\u7684\u4e00\u4e9b\u5c0f\u4fee\u5c0f\u8865(\u8865\u5145\u65e5\u5fd7)\u540e, \u5c31\u53ef\u4ee5\u8dd1\u8d77\u6765\u4e86\r\n\r\n<details><summary>trainer.py</summary>\r\n<p>\r\n\r\n```python\r\nimport gc\r\nimport json\r\nimport logging\r\nimport os\r\nimport shutil\r\n\r\nimport torch\r\nfrom torch import optim\r\nfrom torch.amp import GradScaler\r\nfrom torch.nn.utils import clip_grad_norm_\r\nfrom torch.utils.tensorboard import SummaryWriter\r\nfrom tqdm import tqdm\r\n\r\nexample_config = {\r\n    'model': 'model_name',\r\n    'checkpoint_dir': './checkpoints',\r\n    'tensorboard_dir': './tensorboard',\r\n    'device': 'cuda',\r\n    'enable_cudnn_benchmark': True,\r\n    'enable_amp': False,\r\n    'learning_rate': 1e-4,\r\n    'betas': [0.9, 0.999],\r\n    'eps': 1e-8,\r\n    'enable_compile': False,\r\n    'weight_decay': 0.05,\r\n    'max_steps': 100000,\r\n    'max_grad_norm': 1.0,\r\n    'save_every': 10000,\r\n    'gradient_accumulation_steps': 4\r\n}\r\n\r\n\r\nclass Trainer:\r\n    def __init__(self, config):\r\n        self.config = config\r\n        self.setup_logging()\r\n        self.setup_device()\r\n        self.setup_model()\r\n        self.setup_training()\r\n        \r\n    def setup_logging(self):\r\n        '''\u8bbe\u7f6e\u65e5\u5fd7'''\r\n        logging.basicConfig(\r\n            level=logging.INFO,\r\n            format='%(asctime)s %(levelname)s %(message)s'\r\n        )\r\n        self.logger = logging.getLogger(__name__)\r\n        self.writer = SummaryWriter(self.config['tensorboard_dir'])\r\n        \r\n    def setup_device(self):\r\n        '''\u8bbe\u7f6e\u8bbe\u5907'''\r\n        self.device = torch.device(self.config['device'])\r\n        torch.backends.cudnn.benchmark = self.config.get('enable_cudnn_benchmark', True)\r\n        if self.device.type == 'cuda':\r\n            self.logger.info(f'Using device: {self.device} ({torch.cuda.get_device_name()})')\r\n        else:\r\n            self.logger.info(f'Using device: {self.device}')\r\n            \r\n    def setup_model(self):\r\n        '''\u8bbe\u7f6e\u6a21\u578b\u3001\u635f\u5931\u51fd\u6570\u7b49'''\r\n        self.model = self.build_model().to(self.device)\r\n        if self.config.get('enable_compile', False):\r\n            self.model.compile()\r\n        self.criterion = self.build_criterion()\r\n        \r\n        # \u6253\u5370\u6a21\u578b\u4fe1\u606f\r\n        n_parameters = sum(p.numel() for p in self.model.parameters())\r\n        self.logger.info(f'Number of parameters: {n_parameters:,}')\r\n        \r\n    def setup_training(self):\r\n        '''\u8bbe\u7f6e\u8bad\u7ec3\u76f8\u5173\u7ec4\u4ef6'''\r\n        # \u4f18\u5316\u5668\r\n        self.optimizer = self.build_optimizer()\r\n        \r\n        # \u5b66\u4e60\u7387\u8c03\u5ea6\u5668\r\n        self.scheduler = self.build_scheduler()\r\n        \r\n        # \u68af\u5ea6\u7f29\u653e\u5668(\u7528\u4e8e\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3)\r\n        self.scaler = GradScaler(\r\n            enabled=self.config.get('enable_amp', False)\r\n        )\r\n        self.gradient_accumulation_steps = self.config.get('gradient_accumulation_steps', 1)\r\n        \r\n        # \u52a0\u8f7d\u68c0\u67e5\u70b9\r\n        self.steps = 0\r\n        self.best_metric = {}\r\n        self.load_checkpoint()\r\n        \r\n    def build_model(self):\r\n        '''\u6784\u5efa\u6a21\u578b(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def build_criterion(self):\r\n        '''\u6784\u5efa\u635f\u5931\u51fd\u6570(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def build_optimizer(self):\r\n        '''\u6784\u5efa\u4f18\u5316\u5668'''\r\n        # \u533a\u5206\u9700\u8981\u548c\u4e0d\u9700\u8981weight decay\u7684\u53c2\u6570\r\n        decay_params = []\r\n        no_decay_params = []\r\n        for name, param in self.model.named_parameters():\r\n            if 'bias' in name or 'norm' in name:\r\n                no_decay_params.append(param)\r\n            else:\r\n                decay_params.append(param)\r\n                \r\n        opt_params = [\r\n            {'params': decay_params, 'weight_decay': self.config['weight_decay']},\r\n            {'params': no_decay_params, 'weight_decay': 0.0}\r\n        ]\r\n        \r\n        return optim.AdamW(\r\n            opt_params,\r\n            lr=self.config['learning_rate'],\r\n            betas=self.config.get('betas', (0.9, 0.999)),\r\n            eps=self.config.get('eps', 1e-8)\r\n        )\r\n        \r\n    def build_scheduler(self):\r\n        '''\u6784\u5efa\u5b66\u4e60\u7387\u8c03\u5ea6\u5668(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        return NotImplementedError\r\n        \r\n    def build_dataloader(self):\r\n        '''\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def train_step(self, batch):\r\n        '''\u5355\u6b65\u8bad\u7ec3(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def validate(self):\r\n        '''\u9a8c\u8bc1(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def save_checkpoint(self, is_best=False):\r\n        '''\u4fdd\u5b58\u68c0\u67e5\u70b9'''\r\n        state = {\r\n            'model': self.model.state_dict(),\r\n            'optimizer': self.optimizer.state_dict(),\r\n            'scheduler': self.scheduler.state_dict(),\r\n            'scaler': self.scaler.state_dict(),\r\n            'steps': self.steps,\r\n            'best_metric': self.best_metric,\r\n            'config': self.config\r\n        }\r\n        \r\n        # \u4fdd\u5b58\u6700\u65b0\u68c0\u67e5\u70b9\r\n        torch.save(\r\n            state,\r\n            os.path.join(self.config['checkpoint_dir'], 'latest.pt')\r\n        )\r\n        \r\n        # \u4fdd\u5b58\u6700\u4f73\u68c0\u67e5\u70b9\r\n        if is_best:\r\n            shutil.copy(\r\n                os.path.join(self.config['checkpoint_dir'], 'latest.pt'),\r\n                os.path.join(self.config['checkpoint_dir'], 'best.pt')\r\n            )\r\n            \r\n    def load_checkpoint(self):\r\n        '''\u52a0\u8f7d\u68c0\u67e5\u70b9'''\r\n        checkpoint_path = os.path.join(\r\n            self.config['checkpoint_dir'],\r\n            'latest.pt'\r\n        )\r\n        \r\n        if os.path.exists(checkpoint_path):\r\n            checkpoint = torch.load(\r\n                checkpoint_path,\r\n                map_location=self.device\r\n            )\r\n            \r\n            self.model.load_state_dict(checkpoint['model'])\r\n            self.optimizer.load_state_dict(checkpoint['optimizer'])\r\n            self.scheduler.load_state_dict(checkpoint['scheduler'])\r\n            self.scaler.load_state_dict(checkpoint['scaler'])\r\n            self.steps = checkpoint['steps']\r\n            self.best_metric = checkpoint['best_metric']\r\n            \r\n            self.logger.info(f'Loaded checkpoint from {checkpoint_path}')\r\n            self.logger.info(f'Training will resume from step {self.steps}')\r\n    \r\n    @staticmethod\r\n    def is_better_performance(baseline_dict, compare_dict):\r\n        '''\r\n        \u5224\u65adcompare_dict\u4e2d\u7684\u6307\u6807\u662f\u5426\u5168\u9762\u8d85\u8fc7baseline_dict\r\n        \r\n        Args:\r\n            baseline_dict: \u57fa\u51c6\u5b57\u5178,\u683c\u5f0f\u4e3a {\u6307\u6807\u540d: \u503c}\r\n            compare_dict: \u6bd4\u8f83\u5b57\u5178,\u683c\u5f0f\u4e3a {\u6307\u6807\u540d: \u503c} \r\n        \r\n        Returns:\r\n            bool: \u5982\u679ccompare_dict\u4e2d\u6240\u6709\u6307\u6807\u90fd\u4e25\u683c\u5927\u4e8ebaseline_dict\u5219\u8fd4\u56deTrue,\u5426\u5219\u8fd4\u56deFalse\r\n        '''\r\n        if not baseline_dict:\r\n            return True\r\n        \r\n        # \u68c0\u67e5\u4e24\u4e2a\u5b57\u5178\u7684\u952e\u662f\u5426\u4e00\u81f4\r\n        if set(baseline_dict.keys()) != set(compare_dict.keys()):\r\n            return False\r\n            \r\n        # \u68c0\u67e5\u6bcf\u4e2a\u6307\u6807\u662f\u5426\u90fd\u6709\u63d0\u5347\r\n        for metric in baseline_dict:\r\n            if compare_dict[metric] <= baseline_dict[metric]:\r\n                return False\r\n                \r\n        return True\r\n            \r\n    def train(self):\r\n        '''\u8bad\u7ec3\u6d41\u7a0b'''\r\n        train_loader = self.build_dataloader()\r\n        self.model.train()\r\n        \r\n        self.logger.info('Start training...')\r\n        pbar = tqdm(total=self.config['max_steps'], initial=self.steps)\r\n        \r\n        while self.steps < self.config['max_steps']:\r\n            for batch in train_loader:\r\n                # \u8bad\u7ec3\u4e00\u6b65\r\n                with torch.autocast(device_type=self.config['device'], enabled=self.config.get('enable_amp', False)):\r\n                    loss = self.train_step(batch)\r\n                self.scaler.scale(loss / self.gradient_accumulation_steps).backward()\r\n                \r\n                if (self.steps + 1) % self.gradient_accumulation_steps == 0:\r\n                    # \u68af\u5ea6\u88c1\u526a\r\n                    if self.config.get('max_grad_norm', 0) > 0:\r\n                        self.scaler.unscale_(self.optimizer)\r\n                        clip_grad_norm_(\r\n                            self.model.parameters(),\r\n                            self.config['max_grad_norm']\r\n                        )\r\n\r\n                    # \u4f18\u5316\u5668\u6b65\u8fdb\r\n                    self.scaler.step(self.optimizer)\r\n                    self.scaler.update()\r\n                    self.optimizer.zero_grad(set_to_none=True)\r\n                self.scheduler.step()\r\n                \r\n                # \u8bb0\u5f55\r\n                self.writer.add_scalar('train/loss', loss, self.steps)\r\n                self.writer.add_scalar(\r\n                    'train/lr',\r\n                    self.scheduler.get_last_lr()[0],\r\n                    self.steps\r\n                )\r\n                \r\n                self.steps += 1\r\n                pbar.update(1)\r\n                \r\n                # \u9a8c\u8bc1\u548c\u4fdd\u5b58\r\n                if self.steps % self.config['save_every'] == 0:\r\n                    metric = self.validate()\r\n                    for i in metric:\r\n                        self.logger.info(f'Validation {i}: {metric[i]}')\r\n                        self.writer.add_scalar(f'val/{i}', metric[i], self.steps)\r\n                    \r\n                    is_best = self.is_better_performance(self.best_metric, metric)\r\n                    if is_best:\r\n                        self.best_metric = metric\r\n\r\n                    self.model.train()\r\n                    self.save_checkpoint(is_best)\r\n                    \r\n                if self.steps >= self.config['max_steps']:\r\n                    break\r\n                \r\n            gc.collect()\r\n            torch.cuda.empty_cache()\r\n                    \r\n        pbar.close()\r\n        self.logger.info('Training finished!')\r\n\r\n\r\ndef main():\r\n    '''\u4e3b\u51fd\u6570'''\r\n    # \u52a0\u8f7d\u914d\u7f6e\r\n    with open('config.json') as f:\r\n        config = json.load(f)\r\n        \r\n    # \u521b\u5efa\u8f93\u51fa\u76ee\u5f55\r\n    os.makedirs(config['checkpoint_dir'], exist_ok=True)\r\n    os.makedirs(config['tensorboard_dir'], exist_ok=True)\r\n    \r\n    # \u8bad\u7ec3\r\n    trainer = Trainer(config)\r\n    trainer.train()\r\n    \r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except KeyboardInterrupt:\r\n        pass\r\n``` \r\n\r\n</p>\r\n</details> \r\n\r\n`trainer.py` \u7b80\u5355\u6574\u5408\u4e86\u51e0\u4e2a\u5e38\u7528\u7684\u8bad\u7ec3\u624b\u6bb5, \u6bd4\u5982\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3, \u68af\u5ea6\u88c1\u526a, \u68af\u5ea6\u7d2f\u8ba1, weight_decay(\u5199\u6b7b\u4e86), tensorboard\u7684\u8bb0\u5f55, \u65ad\u70b9\u7eed\u8bad\u7b49\u64cd\u4f5c, \u9700\u8981\u6ce8\u610f\u7684\u662f, `trainer.py` \u6ca1\u6709\u4f7f\u7528 epoch \u4f5c\u4e3a\u8bad\u7ec3\u8fdb\u5ea6, \u800c\u662f\u7528\u4e86\u66f4\u7cbe\u7ec6\u7684 step (\u6bcf\u6b21\u8fed\u4ee3\u53c2\u6570\u5373\u4e3a\u4e00\u4e2astep), \u4f7f\u7528\u7684\u65f6\u5019\u9700\u8981\u81ea\u884c\u5b9e\u73b0\u6a21\u578b\u6784\u5efa, \u635f\u5931\u51fd\u6570\u6784\u5efa \u5b66\u4e60\u7387\u8c03\u5ea6\u5668 \u6570\u636e\u96c6\u52a0\u8f7d\u5668, \u5355\u6b65\u8bad\u7ec3, \u9a8c\u8bc1\u7684\u6d41\u7a0b\u7684\u5b50\u7c7b\u5b9e\u73b0\r\n\r\n\u7136\u540e\u5c06\u4e00\u4e9b\u914d\u7f6e\u653e\u5230config\u4e2d\u4fbf\u4e8e\u8bfb\u53d6, \u5176\u4e2d\u6709\u4e00\u4e9b\u914d\u7f6e\u662f\u5fc5\u987b\u7684, \u5176\u4ed6\u5219\u662f\u5b50\u7c7b\u5b9e\u73b0\u7684\u65f6\u5019\u9700\u8981\u7684\r\n\r\n\u542c\u8d77\u6765\u53ef\u80fd\u6709\u70b9\u62bd\u8c61, \u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684trainer\u4f7f\u7528\u6848\u4f8b\r\n\r\n<details><summary>trainer\u4f7f\u7528\u6848\u4f8b</summary>\r\n<p>\r\n\r\nimport torchvision\r\nimport torch\r\nfrom trainer import Trainer\r\nfrom torchvision.models import resnet18\r\nfrom torch.optim.lr_scheduler import LambdaLR\r\n\r\n\r\n\r\ntransform = torchvision.transforms.Compose([\r\n    torchvision.transforms.ToTensor(),\r\n    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n])\r\n\r\nclass ConstantLambdaLR(LambdaLR):\r\n    def __init__(self, optimizer, **kwargs):\r\n        kwargs['optimizer'] = optimizer\r\n        kwargs['lr_lambda'] = self._step_inner\r\n        super().__init__(**kwargs)\r\n\r\n    def _step_inner(self, steps):\r\n        return 1\r\n\r\n\r\nclass Cifer10Trainer(Trainer):\r\n    def __init__(self, config):\r\n        super().__init__(config)\r\n\r\n    def build_model(self):\r\n        model = resnet18()\r\n        model.fc = torch.nn.Linear(model.fc.in_features, 10)\r\n        return model\r\n    \r\n    def build_criterion(self):\r\n        return torch.nn.CrossEntropyLoss()\r\n    \r\n    def build_scheduler(self):\r\n        return ConstantLambdaLR(self.optimizer)\r\n    \r\n    def build_dataloader(self):\r\n        train_dataset = torchvision.datasets.CIFAR10(root='./temp', train=True, download=True, transform=transform)\r\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.config['batch_size'], shuffle=True, num_workers=1)\r\n        return train_loader\r\n    \r\n    def train_step(self, batch):\r\n        inputs, labels = batch\r\n        inputs, labels = inputs.to(self.device), labels.to(self.device)\r\n        outputs = self.model(inputs)\r\n        loss = self.criterion(outputs, labels)\r\n        return loss\r\n    \r\n    def validate(self):\r\n        self.model.eval()\r\n        test_dataset = torchvision.datasets.CIFAR10(root='./temp', train=False, download=True, transform=transform)\r\n        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=1)\r\n        acc = []\r\n        with torch.inference_mode():\r\n            for batch in test_loader:\r\n                inputs, labels = batch\r\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\r\n                y_hat = self.model(inputs)\r\n                acc.append((y_hat.argmax(dim=1) == labels).sum().item() / labels.size(0))\r\n                \r\n        return {'acc': sum(acc) / len(acc)}\r\n                \r\n\r\ndef main():\r\n    config = {\r\n        'model': 'resnet18',\r\n        'checkpoint_dir': './checkpoints',\r\n        'tensorboard_dir': './tensorboard',\r\n        'device': 'cuda',\r\n        'enable_cudnn_benchmark': True,\r\n        'enable_amp': False,\r\n        'learning_rate': 1e-3,\r\n        'betas': [0.9, 0.999],\r\n        'eps': 1e-8,\r\n        'enable_compile': False,\r\n        'weight_decay': 0.05,\r\n        'max_steps': 500,\r\n        'max_grad_norm': 1.0,\r\n        'save_every': 100,\r\n        'gradient_accumulation_steps': 1,\r\n        'batch_size': 32\r\n    }\r\n    trainer = Cifer10Trainer(config)\r\n    trainer.train()\r\n    \r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except KeyboardInterrupt:\r\n        pass\r\n\r\n</p>\r\n</details> \r\n\r\n> \u4ee3\u7801\u4f7f\u7528cifer10\u6570\u636e\u96c6, resnet18\u4f5c\u4e3a\u6a21\u578b\u8bad\u7ec3\u7684\u7b80\u5355\u7684\u6d41\u7a0b\r\n\r\n\u6709\u4e86\u6d41\u7a0b\u63a5\u4e0b\u6765\u7f16\u5199\u6211\u4eec\u7684\u8bad\u7ec3\u4ee3\u7801\r\n\r\n<details><summary>train.py(\u4ee3\u7801\u672a\u6574\u7406\u5b8c\u6bd5, \u975e\u521d\u7248\u4ee3\u7801, \u4ec5\u4f9b\u53c2\u8003)</summary>\r\n<p>\r\n\r\n```python\r\nimport os\r\nimport random\r\n\r\nimport cv2\r\nimport numpy as np\r\nfrom sklearn.metrics import f1_score\r\nimport torch\r\nfrom PIL import Image\r\nfrom torch.optim.lr_scheduler import LambdaLR\r\nfrom torch.utils.data import DataLoader, Dataset\r\nfrom datasets import load_dataset\r\nfrom torchvision import transforms\r\n\r\n# from torchvision.models import resnet18\r\nfrom model import convnext_base\r\nfrom trainer import Trainer\r\n\r\nimage_size = 224\r\nbatch_size = 32\r\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n\r\n\r\n# def get_color_from_image(image_path):\r\n#     '''\r\n#     \u4ece\u7eaf\u8272\u56fe\u7247\u4e2d\u83b7\u53d6RGB\u989c\u8272\u503c\r\n#     \u8fd4\u56de: (R, G, B)\u5143\u7ec4\r\n#     '''\r\n#     # \u8bfb\u53d6\u56fe\u7247\r\n#     image = Image.open(image_path).convert('RGB')\r\n#     # \u8f6c\u6362\u4e3anumpy\u6570\u7ec4\r\n#     img_array = np.array(image)\r\n    \r\n#     # \u83b7\u53d6\u56fe\u7247\u4e2d\u5fc3\u70b9\u7684\u989c\u8272\u503c\r\n#     h, w = img_array.shape[:2]\r\n#     center_color = img_array[h//2, w//2]\r\n    \r\n#     # \u6216\u8005\u8ba1\u7b97\u6574\u4e2a\u56fe\u7247\u7684\u5e73\u5747\u989c\u8272\r\n#     average_color = img_array.mean(axis=(0,1)).astype(int)\r\n    \r\n#     return tuple(average_color)  # \u6216\u8005 tuple(average_color)\r\n\r\n\r\n# class AugmentationUtils:\r\n#     @staticmethod\r\n#     def add_color_mask(image, is_positive):\r\n#         '''\u7ed9\u56fe\u7247\u6dfb\u52a0\u989c\u8272\u906e\u7f69'''\r\n#         # \u8f6c\u6362\u4e3anumpy\u6570\u7ec4\u5e76\u786e\u4fdd\u7c7b\u578b\u4e3auint8\r\n#         image = np.array(image, dtype=np.uint8)\r\n        \r\n#         # \u521b\u5efa\u4e0e\u56fe\u50cf\u76f8\u540c\u5927\u5c0f\u7684\u906e\u7f69\r\n#         mask = np.ones_like(image, dtype=np.uint8)\r\n        \r\n#         # \u968f\u673a\u751f\u6210\u989c\u8272\r\n#         if is_positive:\r\n#             color = [random.randint(0, 255) for _ in range(3)]\r\n#         else:\r\n#             color = get_color_from_image('22.png')\r\n        \r\n#         # \u4e3a\u906e\u7f69\u8d4b\u4e88\u989c\u8272    \r\n#         for i in range(3):\r\n#             mask[:, :, i] = color[i]\r\n        \r\n#         # \u786e\u4fddmask\u4e5f\u662fuint8\u7c7b\u578b\r\n#         mask = mask.astype(np.uint8)\r\n        \r\n#         # \u6dfb\u52a0\u906e\u7f69\r\n#         alpha = 0.5  # \u900f\u660e\u5ea6\r\n#         image = cv2.addWeighted(image, 1-alpha, mask, alpha, 0)\r\n        \r\n#         return Image.fromarray(image)\r\n\r\n#     @staticmethod\r\n#     def embed_positive_in_negative(positive_img, negative_img):\r\n#         '''\u5728\u8d1f\u6837\u672c\u4e2d\u5d4c\u5165\u6b63\u6837\u672c'''\r\n#         # \u8f6c\u6362\u4e3anumpy\u6570\u7ec4\r\n#         pos_img = np.array(positive_img)\r\n#         neg_img = np.array(negative_img)\r\n        \r\n#         # \u786e\u4fdd\u56fe\u50cf\u662f3\u901a\u9053\u7684\r\n#         if len(pos_img.shape) == 2:\r\n#             pos_img = cv2.cvtColor(pos_img, cv2.COLOR_GRAY2BGR)\r\n#         if len(neg_img.shape) == 2:\r\n#             neg_img = cv2.cvtColor(neg_img, cv2.COLOR_GRAY2BGR)\r\n        \r\n#         # \u83b7\u53d6\u8d1f\u6837\u672c\u5c3a\u5bf8\r\n#         h, w = neg_img.shape[:2]\r\n#         pos_h, pos_w = pos_img.shape[:2]\r\n        \r\n#         # \u8ba1\u7b97\u5408\u9002\u7684\u7f29\u653e\u6bd4\u4f8b\r\n#         scale = min(\r\n#             random.uniform(0.5, 0.8),\r\n#             (w * 0.8) / pos_w,\r\n#             (h * 0.8) / pos_h\r\n#         )\r\n        \r\n#         # \u7f29\u653e\u6b63\u6837\u672c\r\n#         new_size = (int(pos_w * scale), int(pos_h * scale))\r\n#         pos_img_resized = cv2.resize(pos_img, new_size)\r\n        \r\n#         # \u786e\u4fdd\u6709\u6548\u7684\u968f\u673a\u4f4d\u7f6e\u8303\u56f4\r\n#         max_x = max(0, w - new_size[0])\r\n#         max_y = max(0, h - new_size[1])\r\n        \r\n#         # \u968f\u673a\u9009\u62e9\u63d2\u5165\u4f4d\u7f6e\r\n#         x = random.randint(0, max_x) if max_x > 0 else 0\r\n#         y = random.randint(0, max_y) if max_y > 0 else 0\r\n        \r\n#         # \u83b7\u53d6ROI\u533a\u57df\u5e76\u786e\u4fdd\u4e0e\u7f29\u653e\u540e\u7684\u6b63\u6837\u672c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\r\n#         roi = neg_img[y:y+new_size[1], x:x+new_size[0]]\r\n        \r\n#         # \u786e\u4fddROI\u548cpos_img_resized\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u901a\u9053\u6570\r\n#         if roi.shape == pos_img_resized.shape:\r\n#             # \u6df7\u5408\u56fe\u50cf\r\n#             blended = cv2.addWeighted(roi, 0.3, pos_img_resized, 0.7, 0)\r\n#             neg_img[y:y+new_size[1], x:x+new_size[0]] = blended\r\n        \r\n#         return Image.fromarray(neg_img)\r\n    \r\n#     @staticmethod\r\n#     def embed_same(positive_img, negative_img):\r\n#         '''\u5728\u8d1f\u6837\u672c\u4e2d\u5d4c\u5165\u6b63\u6837\u672c'''\r\n#         # \u8f6c\u6362\u4e3anumpy\u6570\u7ec4\r\n#         pos_img = np.array(positive_img)\r\n#         neg_img = np.array(negative_img)\r\n        \r\n#         # \u786e\u4fdd\u56fe\u50cf\u662f3\u901a\u9053\u7684\r\n#         if len(pos_img.shape) == 2:\r\n#             pos_img = cv2.cvtColor(pos_img, cv2.COLOR_GRAY2BGR)\r\n#         if len(neg_img.shape) == 2:\r\n#             neg_img = cv2.cvtColor(neg_img, cv2.COLOR_GRAY2BGR)\r\n        \r\n#         # \u83b7\u53d6\u8d1f\u6837\u672c\u5c3a\u5bf8\r\n#         h, w = neg_img.shape[:2]\r\n#         pos_h, pos_w = pos_img.shape[:2]\r\n        \r\n#         # \u8ba1\u7b97\u5408\u9002\u7684\u7f29\u653e\u6bd4\u4f8b\r\n#         scale = min(\r\n#             random.uniform(0.5, 0.8),\r\n#             (w * 0.8) / pos_w,\r\n#             (h * 0.8) / pos_h\r\n#         )\r\n        \r\n#         # \u7f29\u653e\u6b63\u6837\u672c\r\n#         new_size = (int(pos_w * scale), int(pos_h * scale))\r\n#         pos_img_resized = cv2.resize(pos_img, new_size)\r\n        \r\n#         # \u786e\u4fdd\u6709\u6548\u7684\u968f\u673a\u4f4d\u7f6e\u8303\u56f4\r\n#         max_x = max(0, w - new_size[0])\r\n#         max_y = max(0, h - new_size[1])\r\n        \r\n#         # \u968f\u673a\u9009\u62e9\u63d2\u5165\u4f4d\u7f6e\r\n#         x = random.randint(0, max_x) if max_x > 0 else 0\r\n#         y = random.randint(0, max_y) if max_y > 0 else 0\r\n        \r\n#         # \u83b7\u53d6ROI\u533a\u57df\u5e76\u786e\u4fdd\u4e0e\u7f29\u653e\u540e\u7684\u6b63\u6837\u672c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\r\n#         roi = neg_img[y:y+new_size[1], x:x+new_size[0]]\r\n        \r\n#         # \u786e\u4fddROI\u548cpos_img_resized\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u901a\u9053\u6570\r\n#         if roi.shape == pos_img_resized.shape:\r\n#             # \u6df7\u5408\u56fe\u50cf\r\n#             blended = cv2.addWeighted(roi, 0.3, pos_img_resized, 0.7, 0)\r\n#             neg_img[y:y+new_size[1], x:x+new_size[0]] = blended\r\n        \r\n#         return Image.fromarray(neg_img)\r\n\r\n#     @staticmethod\r\n#     def flip_image(image):\r\n#         '''\u56fe\u7247\u8f74\u5bf9\u79f0'''\r\n#         return Image.fromarray(np.array(image)[:, ::-1])\r\n    \r\n#     @staticmethod\r\n#     def mirror_half_image(image):\r\n#         img_array = np.array(image)\r\n    \r\n#         # \u83b7\u53d6\u56fe\u7247\u5c3a\u5bf8\r\n#         h, w = img_array.shape[:2]\r\n        \r\n#         # \u53d6\u5de6\u534a\u8fb9\r\n#         half_w = w // 2\r\n#         left_half = img_array[:, :half_w]\r\n        \r\n#         # \u6c34\u5e73\u7ffb\u8f6c\u5de6\u534a\u8fb9\u5f97\u5230\u53f3\u534a\u8fb9\r\n#         right_half = left_half[:, ::-1]\r\n        \r\n#         # \u62fc\u63a5\u4e24\u4e2a\u534a\u8fb9\r\n#         mirrored = np.concatenate([left_half, right_half], axis=1)\r\n        \r\n#         return Image.fromarray(mirrored)\r\n    \r\n\r\n# def augment_dataset(positive_images, negative_images):\r\n#     aug_utils = AugmentationUtils()\r\n#     augmented_data = []\r\n    \r\n#     # \u589e\u5f3a\u6b63\u6837\u672c\r\n#     for pos_img in positive_images:\r\n#         img = Image.open(pos_img).convert('RGB')\r\n#         # \u539f\u56fe\r\n#         augmented_data.append((img, 1))\r\n#         # \u989c\u8272\u906e\u7f69\r\n#         augmented_data.append((aug_utils.add_color_mask(img, True), 1))\r\n#         # \u8f74\u5bf9\u79f0\r\n#         augmented_data.append((aug_utils.flip_image(img), 1))\r\n#         # \u955c\u50cf\u4e00\u534a\r\n#         augmented_data.append((aug_utils.mirror_half_image(img), 1))\r\n#         # \u5d4c\u5165\u76f8\u540c\r\n#         img_id = random.randint(0, len(positive_images)-1)\r\n#         aaa = Image.open(positive_images[img_id]).convert('RGB')\r\n#         augmented_data.append((aug_utils.embed_same(aaa, img), 1))\r\n        \r\n    \r\n#     # \u589e\u5f3a\u8d1f\u6837\u672c\r\n#     for i, neg_img in enumerate(negative_images):\r\n#         img = Image.open(neg_img).convert('RGB')\r\n#         # \u539f\u56fe\r\n#         augmented_data.append((img, 0))\r\n#         # \u989c\u8272\u906e\u7f69\r\n#         augmented_data.append((aug_utils.add_color_mask(img, False), 0))\r\n#         # \u955c\u50cf\u4e00\u534a\r\n#         augmented_data.append((aug_utils.mirror_half_image(img), 0))\r\n#         # \u5d4c\u5165\u6b63\u6837\u672c\r\n#         pos_img = Image.open(positive_images[random.randint(0, len(positive_images)-1)]).convert('RGB')\r\n#         augmented_data.append((aug_utils.embed_positive_in_negative(pos_img, img), 1))\r\n#         # \u5d4c\u5165\u76f8\u540c\r\n#         img_id = random.randint(0, len(negative_images)-1)\r\n#         aaa = Image.open(negative_images[img_id]).convert('RGB')\r\n#         augmented_data.append((aug_utils.embed_same(aaa, img), 0))\r\n        \r\n\r\n        \r\n#     # # \u663e\u793a\u5e76\u4fdd\u5b58\r\n#     # for i, (img, label) in enumerate(augmented_data):\r\n#     #     # img.show()\r\n#     #     os.makedirs('aug_images', exist_ok=True)\r\n#     #     img.save(f'aug_images/aug_{i}.jpg')\r\n    \r\n#     # \u7edf\u8ba1\r\n#     print(f'Positive: {len([x for x, y in augmented_data if y == 1])}, Negative: {len([x for x, y in augmented_data if y == 0])}')\r\n#     return augmented_data\r\n\r\n\r\nclass LinearWarmUpCosineAnnealingLR(LambdaLR):\r\n    def __init__(self, optimizer, *, warmup_iters, max_learning_rate, min_lr, lr_decay_iters, **kwargs):\r\n        self.warmup_iters = warmup_iters\r\n        self.max_learning_rate = max_learning_rate\r\n        self.lr_decay_iters = lr_decay_iters\r\n        self.min_lr = min_lr\r\n        kwargs['optimizer'] = optimizer\r\n        kwargs['lr_lambda'] = self._step_inner\r\n        super().__init__(**kwargs)\r\n\r\n    def _step_inner(self, steps):\r\n        if steps < self.warmup_iters:\r\n            return self.max_learning_rate * steps / self.warmup_iters\r\n        elif steps < self.lr_decay_iters:\r\n            return self.min_lr + 0.5 * (1.0 + np.cos((steps - self.warmup_iters) / (self.lr_decay_iters - self.warmup_iters)*np.pi)) * (self.max_learning_rate - self.min_lr)\r\n        else:\r\n            return self.min_lr\r\n\r\n\r\ndef transform_img(img):\r\n    # \u5904\u7406\u56fe\u7247\r\n    img_np = np.array(img)\r\n    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1)  # C, H, W\r\n    img_tensor = torch.nn.functional.interpolate(img_tensor.unsqueeze(0), size=(image_size, image_size), mode='bilinear', align_corners=False).squeeze(0)\r\n    # normalize\r\n    normalized_img = img_tensor.float() / 255.0\r\n    return normalized_img\r\n\r\n\r\ntransform = transforms.Compose([\r\n    transforms.Resize((image_size, image_size)),\r\n    transforms.ToTensor(),\r\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n])\r\n\r\n\r\ndef transform_img_torchvision(data):\r\n    data['x'] = [transform(img.convert('RGB')) for img in data['image']]\r\n    return data\r\n\r\n\r\nlabel_mapping = {\r\n    'nailong': 0,\r\n    'emoji': 1,\r\n    'anime': 2,\r\n    'others': 3,\r\n    'long': 4\r\n}\r\n\r\ndef extract_datasets():\r\n    ds = load_dataset('refoundd/NailongClassification', cache_dir='data', split='train')\r\n    ds = ds.map(lambda x: {'label': label_mapping[x['label']]})\r\n    ds = ds.map(transform_img_torchvision, remove_columns=['image'], batched=True)\r\n    dataset = ds.train_test_split(test_size=0.2)\r\n    return dataset\r\n\r\ndataset = extract_datasets()\r\n\r\n\r\nclass NaiLongDataset(Dataset):\r\n    def __init__(self, mode='train'):\r\n        assert mode in ['train', 'test']\r\n        self.dataset = dataset[mode]\r\n\r\n    def __len__(self):\r\n        return len(self.dataset)\r\n\r\n    def __getitem__(self, idx):\r\n        item = self.dataset[idx]['x']\r\n        label = self.dataset[idx]['label']\r\n        return torch.tensor(item), torch.tensor(label)\r\n\r\n\r\n\r\nclass NaiLongTrainer(Trainer):\r\n    def __init__(self, config):\r\n        super().__init__(config)\r\n\r\n    def build_model(self):\r\n        # model = resnet18()\r\n        # model.fc = torch.nn.Linear(model.fc.in_features, 2)\r\n        # return model\r\n        return convnext_base(pretrained=False, num_classes=5)\r\n    \r\n    def build_criterion(self):\r\n        return torch.nn.CrossEntropyLoss()\r\n    \r\n    def build_scheduler(self):\r\n        return LinearWarmUpCosineAnnealingLR(self.optimizer, warmup_iters=self.config['warmup_iters'], max_learning_rate=self.config['max_learning_rate'], min_lr=self.config['min_lr'], lr_decay_iters=self.config['lr_decay_iters'])\r\n    \r\n    def build_dataloader(self, mode='train'):\r\n        dataset = NaiLongDataset(mode='train')\r\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\r\n    \r\n    def train_step(self, batch):\r\n        x, y = batch\r\n        x, y = x.to(device), y.to(device)\r\n        return self.criterion(self.model(x), y)\r\n    \r\n    def validate(self):\r\n        self.logger.info('Validating...')\r\n        self.model.eval()\r\n        dataloader = self.build_dataloader(mode='test')\r\n        acc = []\r\n        f1 = [[], []]\r\n        with torch.no_grad(): \r\n            for i, (x, y) in enumerate(dataloader):\r\n                x, y = x.to(device), y.to(device)\r\n                # print(f'Validation: {i}, {y}')\r\n                y_hat = self.model(x)\r\n                acc.append(torch.sum(torch.argmax(y_hat, dim=1) == y).item() / len(y))\r\n                f1[0].extend(y.cpu().tolist())\r\n                f1[1].extend(torch.argmax(y_hat, dim=1).cpu().tolist())\r\n            f1_scores = f1_score(f1[0], f1[1], average='macro')\r\n        return {'acc': sum(acc) / len(acc), 'f1': f1_scores}\r\n\r\n\r\ndef main():\r\n    config = {  # test\r\n        'model': 'convnext_tiny',\r\n        'checkpoint_dir': './checkpoints',\r\n        'tensorboard_dir': './tensorboard',\r\n        'device': 'cuda',\r\n        'enable_cudnn_benchmark': True,\r\n        'enable_amp': False,\r\n        'learning_rate': 1,  # \u542f\u52a8lr_scheduler \u8fd9\u91cc\u5fc5\u987b\u662f1\r\n        'betas': [0.9, 0.999],\r\n        'eps': 1e-8,\r\n        'enable_compile': False,\r\n        'weight_decay': 0.0,\r\n        'max_steps': 5000,\r\n        'max_grad_norm': 1.0,\r\n        'save_every': 500,\r\n        'gradient_accumulation_steps': 1,\r\n        'warmup_iters': 500,\r\n        'max_learning_rate': 1e-3,\r\n        'min_lr': 1e-4,\r\n        'lr_decay_iters': 1000\r\n    }\r\n    os.makedirs(config['checkpoint_dir'], exist_ok=True)\r\n    os.makedirs(config['tensorboard_dir'], exist_ok=True)\r\n    trainer = NaiLongTrainer(config)\r\n    trainer.train()\r\n\r\nif __name__ == '__main__':\r\n    # \u5220\u9664tensorboard\u4e0b\u7684\u6587\u4ef6, \u4f46\u4e0d\u5220\u9664\u6587\u4ef6\u5939\r\n    for i in os.listdir('./tensorboard'):\r\n        os.remove(os.path.join('./tensorboard', i))\r\n    # \u5220\u9664checkpoints\u4e0b\u7684\u6587\u4ef6\r\n    for i in os.listdir('./checkpoints'):\r\n        os.remove(os.path.join('./checkpoints', i))\r\n    try:\r\n        main()\r\n    except KeyboardInterrupt:\r\n        print('KeyboardInterrupt')\r\n        \r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n### \u6570\u636e\u589e\u5e7f\r\n\r\n\u539f\u59cb\u6570\u636e\u96c6\u53ea\u6709\u4e24\u767e\u591a\u5f20\u56fe\u7247, \u8fd9\u4e2a\u65f6\u5019\u65e0\u6cd5\u907f\u514d\u7684\u8981\u505a\u6570\u636e\u589e\u5e7f, \u6269\u5c55 nailong \u6807\u7b7e\u7684\u6570\u636e, \u8fd9\u91cc\u56e0\u4e3a\u662f\u521d\u7248\u65b9\u6848, \u4e5f\u6ca1\u6709\u975e\u5e38\u7cbe\u7ec6\u7684\u589e\u5e7f\u65b9\u6848, \u8fd9\u91cc\u4f7f\u7528\u4e86\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f(\u4ee3\u7801\u5728\u5982\u4e0atrain.py\u4e2d):\r\n\r\n- \u7ed9\u56fe\u7247\u6dfb\u52a0\u989c\u8272\u906e\u7f69\r\n    \u8ba9\u6a21\u578b\u4e0d\u8981\u5c06\u9047\u5230\u9ec4\u8272\u7684\u5c31\u5224\u5b9a\u4e3a\u5976\u9f99\r\n- \u5728\u8d1f\u6837\u672c\u4e2d\u5d4c\u5165\u6b63\u6837\u672c\r\n    \u5f88\u7ecf\u5178\u7684\u589e\u5e7f\u6570\u636e\u7684\u624b\u6cd5\r\n- \u56fe\u7247\u8f74\u5bf9\u79f0\r\n- \u53d6\u56fe\u50cf\u7684\u4e00\u534a\u955c\u50cf\u7ffb\u8f6c\r\n\r\n### \u8bad\u7ec3\r\n\r\n#### \u53c2\u6570\u641c\u7d22\r\n\r\n\u867d\u7136\u662f\u4e2a\u4eba\u5c0f\u9879\u76ee, \u7b80\u5355\u7684\u53c2\u6570\u641c\u7d22\u4e0d\u80fd\u5c11, \u7ee7\u7eed\u4e0a\u9762\u5199\u7684 `trainer.py`, \u6211\u4e5f\u5199\u4e86\u4e00\u4e2a\u7b80\u5355\u7684 `hyperparameter_seacher.py` \u6765\u641c\u7d22\u8d85\u53c2\r\n\r\n<details><summary>hyperparameter_seacher.py</summary>\r\n<p>\r\n\r\n```python\r\nfrom trainer import Trainer\r\nimport optuna\r\n\r\n\r\nexample_config = {\r\n    'model': 'convnext_tiny',\r\n    'checkpoint_dir': './checkpoints',\r\n    'tensorboard_dir': './tensorboard',\r\n    'device': 'cuda',\r\n    'enable_cudnn_benchmark': True,\r\n    'enable_amp': False,\r\n    'learning_rate': 1e-4,\r\n    'betas': [0.9, 0.999],\r\n    'eps': 1e-8,\r\n    'enable_compile': False,\r\n    'weight_decay': 0.05,\r\n    'max_steps': 100,\r\n    'max_grad_norm': 1.0,\r\n    'save_every': 1000000,  # \u4e0d\u4fdd\u5b58\r\n    'gradient_accumulation_steps': 4\r\n}\r\n\r\nexample_search_config = {\r\n    'params': {\r\n        'learning_rate': {\r\n            'type': 'float',\r\n            'range': [1e-5, 1e-2],\r\n            'log': True\r\n        },\r\n        'gradient_accumulation_steps': {\r\n            'type': 'int',\r\n            'range': [1, 8],\r\n            'log': False\r\n        }\r\n    },\r\n    'if_save_info': False,\r\n    'n_trials': 10\r\n}\r\n\r\nclass HyperparameterSearcher:\r\n    def __init__(self, config, trainer):\r\n        assert isinstance(trainer, Trainer), 'trainer must be an instance of Trainer'\r\n        self.config = config\r\n        self.trainer = trainer\r\n        \r\n    def objective(self, trial):\r\n        search_params = self.config['params']\r\n        \r\n        for param_name, param_config in search_params.items():\r\n            if param_config['type'] == 'float':\r\n                self.trainer.config[param_name] = trial.suggest_float(\r\n                    param_name,\r\n                    param_config['range'][0],\r\n                    param_config['range'][1],\r\n                    log=param_config.get('log', False)\r\n                )\r\n            elif param_config['type'] == 'int':\r\n                self.trainer.config[param_name] = trial.suggest_int(\r\n                    param_name,\r\n                    param_config['range'][0],\r\n                    param_config['range'][1]\r\n                )\r\n            elif param_config['type'] == 'list':\r\n                self.trainer.config[param_name] = trial.suggest_categorical(\r\n                    param_name,\r\n                    param_config['range']\r\n                )\r\n            else:\r\n                raise ValueError(f'Unsupported parameter type: {param_config['type']}, only support float and int')\r\n        \r\n        self.trainer.setup_training()\r\n        self.trainer.train()\r\n        metric = self.trainer.validate()\r\n        if 'acc' not in metric:\r\n            raise ValueError('metric must contain 'acc'')\r\n        return -metric['acc']  # only support maximizing acc\r\n    \r\n    def search(self):\r\n        study = optuna.create_study(direction='maximize')\r\n        study.optimize(self.objective, n_trials=self.config['n_trials'])\r\n        print('Best params:', study.best_params)\r\n        print('Best value:', -study.best_value)\r\n        if self.config['if_save_info']:\r\n            study.trials_dataframe().to_csv('./output/optuna_results.csv')\r\n        return study.best_params\r\n    \r\ndef main():\r\n    \r\n    pass\r\n\r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except KeyboardInterrupt:\r\n        pass\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\u8d85\u53c2\u641c\u7d22\u9700\u8981 trainer \u7684\u914d\u5408, \u4f7f\u7528\u4e86\u4e0e\u6a21\u578b\u65e0\u5173\u7684 optuna \u6765\u8dd1\u7ed9\u5b9a\u8303\u56f4\u7684\u8d85\u53c2\u503c, \u8fd9\u4e2a\u65f6\u5019\u53ef\u4ee5\u7ed9trainer\u4e00\u4e2a\u6bd4\u8f83\u5bb9\u6613\u8bad\u7ec3\u7684\u8d85\u53c2\u8bbe\u7f6e(\u77ed\u7684epoch\u7b49), \u540c\u65f6\u5173\u95ed\u4fdd\u5b58\u6a21\u5f0f\r\n\r\n\u6211\u4e5f\u5199\u4e86\u4e2a\u7b80\u5355\u7684\u8d85\u53c2\u641c\u7d22\u7684\u4f8b\u5b50\r\n\r\n<details><summary>hyperparameter_seacher\u4f7f\u7528\u6848\u4f8b</summary>\r\n<p>\r\n\r\nfrom example_trainer import Cifer10Trainer\r\nfrom hyperparameter_seacher import HyperparameterSearcher\r\n\r\nclass Cifer10HyperparameterSearcher(HyperparameterSearcher):\r\n    def __init__(self, config, trainer):\r\n        super().__init__(config, trainer)\r\n\r\n\r\ndef main():\r\n    search_config = {\r\n        'params': {\r\n            'learning_rate': {\r\n                'type': 'float',\r\n                'range': [1e-5, 1e-2],\r\n                'log': True\r\n            },\r\n            'gradient_accumulation_steps': {\r\n                'type': 'int',\r\n                'range': [1, 8],\r\n                'log': False\r\n            }\r\n        },\r\n        'if_save_info': True,\r\n        'n_trials': 10\r\n    }\r\n\r\n    trainer_config = {\r\n        'model': 'resnet18',\r\n        'checkpoint_dir': './checkpoints',\r\n        'tensorboard_dir': './tensorboard',\r\n        'device': 'cuda',\r\n        'enable_cudnn_benchmark': True,\r\n        'enable_amp': False,\r\n        'learning_rate': 1e-3,\r\n        'betas': [0.9, 0.999],\r\n        'eps': 1e-8,\r\n        'enable_compile': False,\r\n        'weight_decay': 0.05,\r\n        'max_steps': 500,\r\n        'max_grad_norm': 1.0,\r\n        'save_every': 10000,  # large than max_steps, no save\r\n        'gradient_accumulation_steps': 4,\r\n        'batch_size': 32\r\n    }\r\n    trainer = Cifer10Trainer(trainer_config)\r\n    searcher = Cifer10HyperparameterSearcher(search_config, trainer)\r\n    best_params = searcher.search()\r\n    print(best_params)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n</p>\r\n</details> \r\n\r\n> \u641c\u7d22\u4e0a\u9762\u90a3\u4e2a\u4f8b\u5b50\u4e2d\u7684\u5408\u9002\u7684\u8d85\u53c2\u6570\r\n\r\n\u5728\u51c6\u5907\u597d\u8fd9\u4e9b\u540e, \u7f16\u5199\u6211\u4eec\u9879\u76ee\u7684\u8d85\u53c2\u641c\u7d22\u5668\r\n\r\n<details><summary>\u4e4b\u540e\u8865\u5145</summary>\r\n<p>\r\n\r\n\r\n\r\n</p>\r\n</details> \r\n\r\n> \u641c\u7d22\u51fa\u6765\u7684\u6700\u4f73\u8d85\u53c2\u662f\u4e00\u4e2a\u5f88\u957f\u7684\u5c0f\u6570, \u56db\u820d\u4e94\u5165\u5408\u9002\u7684\u4f4d\u6570\u5373\u53ef\r\n\r\n#### \u7b2c\u4e00\u6b21\u8bad\u7ec3\r\n\r\n\u5728\u51c6\u5907\u597d\u540e, \u5f00\u59cb\u7b2c\u4e00\u6b21\u8bad\u7ec3\r\n\r\n\u5728\u8f83\u65b0\u7684GPU\u4e0b, \u8bad\u7ec3\u4ee5\u524d\u8f83\u5c0f\u7684\u6a21\u578b\u53ef\u8c13\u964d\u7ef4\u6253\u51fb, \u4e0d\u5230\u4e00\u4e2a\u5c0f\u65f6\u8bad\u7ec3\u5b8c\u6bd5\r\n\r\n\u7136\u800c, \u7b2c\u4e00\u4e2a\u95ee\u9898\u51fa\u6765\u4e86\r\n\r\nacc\u5f88\u9ad8, f1\u5f88\u4f4e\r\n\r\n\u7f16\u5199\u6d4b\u8bd5\u4ee3\u7801:\r\n\r\n<details><summary>test.py(\u975e\u521d\u7248\u4ee3\u7801, \u4ec5\u4f9b\u53c2\u8003)</summary>\r\n<p>\r\n\r\n```python\r\nfrom sklearn.metrics import f1_score\r\nimport torch\r\n\r\nfrom model import convnext_base\r\nfrom PIL import Image\r\nimport numpy as np\r\nfrom glob import glob\r\nfrom torchvision import transforms\r\n\r\ndevice = 'cuda'\r\nimage_size = 224\r\n\r\nmodel = convnext_base(pretrained=False, num_classes=5).to(device)\r\n# model = resnet18()\r\n# model.fc = torch.nn.Linear(model.fc.in_features, 2)\r\ncheckpoint = torch.load('./checkpoints/best.pt', map_location=device)\r\nmodel.load_state_dict(checkpoint['model'])\r\n\r\ntransform = transforms.Compose([\r\n    transforms.Resize((image_size, image_size)),\r\n    transforms.ToTensor(),\r\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n])\r\n\r\ndef transform_img(img):\r\n    # \u5904\u7406\u56fe\u7247\r\n    img_np = np.array(img)\r\n    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1)  # C, H, W\r\n    img_tensor = torch.nn.functional.interpolate(img_tensor.unsqueeze(0), size=(image_size, image_size), mode='bilinear', align_corners=False).squeeze(0)\r\n    # normalize\r\n    normalized_img = img_tensor.float() / 255.0\r\n    return normalized_img\r\n\r\n\r\ndef get_input_images(image_path):\r\n    img = Image.open(image_path).convert('RGB')\r\n    img = transform(img)\r\n    return torch.tensor(img).to(device).unsqueeze(0)\r\n\r\nmodel.eval()\r\n\r\n# \u5bfc\u51faonnx\r\ninput_names = ['input']\r\noutput_names = ['output']\r\ndynamic_axes = {\r\n    'input': {0: 'batch_size'},  # \u8f93\u5165\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f\u52a8\u6001\u7684\r\n    'output': {0: 'batch_size'}  # \u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f\u52a8\u6001\u7684\r\n}\r\ntorch.onnx.export(model, torch.randn(1, 3, 224, 224).to(device), 'model.onnx', input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, opset_version=11)\r\n\r\nwith torch.no_grad():\r\n    # image = torch.randn(1, 3, 256, 256)\r\n    print(torch.softmax(model(get_input_images('1.jpg')), dim=1))\r\n    input()\r\n    print(torch.softmax(model(get_input_images('3.jpg')), dim=1))\r\n    input()\r\n    acc = []\r\n    f1 = [[], []]\r\n    \r\n    \r\n    for file in glob('./datasets/nailong/*'):\r\n        y_hat, y = model(get_input_images(file)), torch.tensor([0]).to(device)\r\n        acc.append(torch.sum(torch.argmax(y_hat, dim=1) == y).item() / len(y))\r\n        f1[0].append(y.cpu().tolist()[0])\r\n        f1[1].append(torch.argmax(y_hat, dim=1).cpu().tolist()[0])\r\n        \r\n\r\n    # for file in glob('./datasets/cifer10/*'):\r\n    #     y_hat, y = model(get_input_images(file)), torch.tensor([3]).to(device)\r\n    #     acc.append(torch.sum(torch.argmax(y_hat, dim=1) == y).item() / len(y))\r\n    #     f1[0].append(y.cpu().tolist()[0])\r\n    #     f1[1].append(torch.argmax(y_hat, dim=1).cpu().tolist()[0])\r\n\r\nprint(sum(acc) / len(acc))\r\nf1_scores = f1_score(f1[0], f1[1], average='macro')\r\nprint(f1_scores)\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\r\n\u53d1\u73b0 acc \u4e0e f1 \u7684\u503c\u975e\u5e38\u4f4e(\u767e\u5206\u4e4b10\u5230\u767e\u5206\u4e4b20\u9644\u8fd1)\r\n\r\n\u8fd9\u4e2a\u65f6\u5019\u67e5\u770b\u6a21\u578b\u7684\u8f93\u51fa, \u53d1\u73b0\u6a21\u578b\u7684\u8f93\u51fa\u63a5\u8fd1\u521d\u59cb\u5316\u7684\u8f93\u51fa(softmax\u540e), \u6a21\u578b\u6ca1\u6709\u600e\u4e48\u88ab\u8bad\u7ec3\r\n\r\n\u8fd9\u4e2a\u65f6\u5019\u6000\u7591\u662f\u8bad\u7ec3\u4ee3\u7801\u51fa\u4e86\u95ee\u9898, \u7136\u800c cifer10 \u7684 \u8bad\u7ec3\u5e76\u6ca1\u6709\u4ec0\u4e48\u95ee\u9898\r\n\u68c0\u67e5\u6570\u636e\u589e\u5e7f\u4ee3\u7801, \u67e5\u770b\u589e\u5e7f\u540e\u7684\u56fe\u7247, \u53d1\u73b0\u589e\u5e7f\u505a\u7684\u4e0d\u662f\u5f88\u597d, \u6b63\u6837\u672c\u5185\u5d4c\u8d1f\u6837\u672c\u6ca1\u5d4c\u597d\r\n\r\n\u5728\u7ecf\u8fc7\u4fee\u6539\u540e, \u91cd\u542f\u8bad\u7ec3\r\n\u7136\u800c, \u95ee\u9898\u53d8\u6210\u4e86, \u6a21\u578b\u7684\u8f93\u51fa\u63a5\u8fd1(0.5, 0.5)(\u4e8c\u5206\u7c7b\u4efb\u52a1)\r\n\r\n\u8ddf\u4eba\u8ba8\u8bba\u540e, \u8ba4\u4e3a\u662f\u6570\u636e\u96c6\u96be\u5ea6\u592a\u5927, \u68c0\u67e5\u8868\u60c5\u5305\u6570\u636e\u96c6, \u90fd\u662f\u4e00\u4e9b\u5206\u5e03\u4e0e nailong \u6570\u636e\u5dee\u5f02\u5f88\u5927\u7684\u56fe\u7247. \r\n\r\n> \u975e\u4e25\u683c\u63a8\u7406, \u7eaf\u8111\u6d4b\r\n\u6a21\u578b\u53d1\u73b0, \u7ed9\u4e00\u5f20\u65b0\u7684\u56fe\u7247\u9884\u6d4b nailong \u7c7b, \u8fd8\u662f\u5176\u4ed6\u7c7b, \u90fd\u4f1a\u5bfc\u81f4loss\u4e0a\u5347, \u4e8e\u662f\u5e72\u8106\u6446\u70c2\u4e71\u731c,  \u6700\u7ec8\u7684\u6982\u7387\u5206\u5e03\u4f1a\u8f93\u51fa\u6570\u636e\u5206\u5e03, \u7ecf\u8fc7\u6570\u636e\u589e\u5e7f\u540e\u7684\u6570\u636e\u6070\u597d\u662f\u4e24\u7c7b 1:1, \u6a21\u578b\u9000\u5316\u6210\u7edf\u8ba1\u6570\u636e\u96c6\u4e86\r\n\r\n\u5bfc\u81f4\u8fd9\u4e2a\u7684\u6700\u76f4\u63a5\u539f\u56e0\u662f\u8f93\u5165\u7279\u5f81\u4e0d\u591f, \u5230\u56fe\u50cf\u5206\u7c7b\u5c31\u662f\u6a21\u578b\u627e\u4e0d\u5230\u51b3\u5b9a\u56fe\u7247\u5206\u7c7b\u7684\u6a21\u5f0f\r\n\r\n\u4e8e\u662f, \u7b2c\u4e00\u9636\u6bb5\u7684\u8bad\u7ec3\u7ed3\u675f\u4e86\r\n\r\n#### \u7b2c\u4e8c\u6b21\u8bad\u7ec3\r\n\r\n\u5728\u6570\u636e\u96c6\u4f5c\u8005\u4e0d\u65ad\u7684\u52aa\u529b\u4e0b, nailong \u6570\u636e\u96c6\u6709\u4e86\u4e00\u4e9b\u5b8c\u5584, \u4e3b\u8981\u7684\u5b8c\u5584\u70b9\u5728\u4e8e: \r\n1. \u65b0\u6dfb\u66f4\u591a nailong\r\n2. \u4e0d\u662f\u4e8c\u5206\u7c7b\u4e86, \u65b0\u589e\u4e86\u8868\u60c5\u5305\u5206\u7c7b, \u52a8\u753b\u5206\u7c7b\u7b49\u4e94\u5206\u7c7b, \u4e0d\u8fc7\u4e0d\u540c\u7c7b\u522b\u7684\u6570\u636e\u6570\u91cf\u5dee\u5f02\u5f88\u5927(\u4e24\u4e2a\u6570\u91cf\u7ea7)\r\n3. \u52a0\u5165\u4e86\u4e00\u4e9b corner case, \u6bd4\u5982 \u85e4\u7530\u7434\u97f3\u7b49\u5176\u4ed6\u989c\u8272\u4e3a\u9ec4\u8272\u7684\u56fe\u50cf\r\n\r\n\u56e0\u4e3a\u7b2c\u4e00\u6b21\u8bad\u7ec3\u4ee3\u7801\u5df2\u7ecf\u5199\u597d\u4e86, \u6539\u8d77\u6765\u4e5f\u4e0d\u662f\u5f88\u9ebb\u70e6, \u53ea\u9700\u8981\u6362\u4e2a\u6570\u636e\u96c6\u5b9a\u4e49\u4e0e\u8bfb\u53d6. \u4f5c\u8005\u7684\u6570\u636e\u96c6\u653e\u5728 huggingface \u4e0a, \u4e8e\u662f\u6211\u4eec\u4f7f\u7528 datasets \u8fdb\u884c\u8bfb\u53d6.\r\n\r\n> \u6211\u4e5f\u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u6211\u5199\u7684\u95ee\u9898, datasets\u8bfb\u8d77\u6765\u5f88\u6162, dataloader \u540e, \u4f1a\u628a label \u81ea\u52a8\u53d8\u6210torch.tensor\u683c\u5f0f, \u4f46\u662f n, c, h, w \u683c\u5f0f\u7684\u56fe\u7247\u53ea\u4f1a\u628a w \u7ef4\u5ea6\u53d8\u6210 torch.tensor \u683c\u5f0f, \u5176\u4ed6\u7ef4\u5ea6\u8fd8\u662f List, \u9700\u8981\u5728 dataset \u7c7b\u5b9a\u4e49\u7684\u65f6\u5019\u4f7f\u7528 __getitem__() \u5c06\u6570\u636e\u63d0\u524d\u53d8\u4e3a torch.tensor\r\n> \u7136\u540e\u4e0d\u652f\u6301\u591a\u7ebf\u7a0b\u8bfb\u53d6(\u4f1a\u5361\u4f4f), \u5355\u7ebf\u7a0b\u8bfb\u53d6\u8bfb\u8d77\u6765\u5f88\u6162, gpu \u7684 cuda \u5448\u73b0\u5c16\u523a\u72b6\r\n> \u7136\u540e, dataset \u7684\u8bfb\u53d6**\u8981\u5148**\u8bfb\u53d6 id \u518d\u8bfb\u53d6 x \u8ddf label\r\n> \u6ca1\u600e\u4e48\u7528\u8fc7 dataset, \u8fd9\u6b21\u5c5e\u5b9e\u662f\u5b66\u5230\u4e86\r\n\r\n\u4fee\u6539\u597d\u540e\u6570\u636e\u52a0\u8f7d\u7684\u4ee3\u7801\u540e\u5e76\u6ce8\u91ca\u6389\u5148\u524d\u7684\u6570\u636e\u589e\u5e7f\u4ee3\u7801\u540e(\u540e\u7eed\u7814\u7a76), \u7b2c\u4e8c\u6b21\u8bad\u7ec3\u5f00\u59cb\u4e86\r\n\r\n\u8fd9\u6b21\u7ed3\u679c\u597d\u8fc7\u5934\u4e86\r\n\u6a21\u578b\u7684 loss \u6536\u655b\u5230\u4e86 $1e^{-5}$, acc\u8ddff1\u66f4\u662f\u5230\u8fbe\u4e86 $100\\%$\r\n\r\n\u4f7f\u7528\u6d4b\u8bd5\u4ee3\u7801\u7b80\u5355\u6d4b\u8bd5, \u53d1\u73b0\u5728\u6570\u636e\u96c6\u7684\u6570\u636e\u90fd\u80fd\u5b8c\u7f8e\u5206\u7c7b, \u4e0d\u5728\u6570\u636e\u96c6\u7684\u5206\u7c7b\u53ea\u8981\u5206\u4e0d\u51fa\u662f\u5976\u9f99\u5373\u53ef. \u68c0\u67e5\u6a21\u578b\u8f93\u51fa\u6743\u91cd, \u4e5f\u6ca1\u5565\u95ee\u9898, \u770b\u8d77\u6765\u662f\u5b8c\u7f8e\u4e86?\r\n\r\n\u7136\u800c \u8fd9\u5f20\u56fe\u8fd8\u662f\u7ed9\u4e86\u6a21\u578b\u4e00\u62f3\r\n\r\n<details><summary>\u56fe</summary>\r\n<p>\r\n\r\n![22](https://github.com/user-attachments/assets/3cb2b111-e01f-44dd-8e71-0509ab2bb6c0)\r\n\r\n</p>\r\n</details> \r\n\r\n\r\n\u4ed6\u4f1a\u8bc6\u522b\u6210 nailong, \u4e0d\u8fc7\u6211\u89c9\u5f97\u95ee\u9898\u4e0d\u5927(\u786e\u5b9e\u6709\u4eba\u628a\u4ed6\u62bd\u8c61\u7684\u8ba4\u6210 nailong)\r\n\r\n### \u90e8\u7f72\r\n\r\n\u4e0a\u9762\u7684 `test.py` \u4e2d \u5199\u4e86onnx\u5bfc\u51fa\u7684\u4ee3\u7801, \u652f\u6301\u4efb\u610f batch \u7684\u8f93\u5165(\u89e3\u9501\u4e86 n, c, h, w \u7684 n \u7ef4\u5ea6)\r\n\r\n\u7b80\u5355\u7f16\u5199onnx\u63a8\u7406\u4ee3\u7801\r\n\r\n<details><summary>onnx_inference.py</summary>\r\n<p>\r\n\r\n```python\r\n# from torchvision import transforms\r\nimport onnxruntime as ort\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\nimg_size = 224\r\n\r\n# transform = transforms.Compose([\r\n#     transforms.Resize((img_size, img_size)),\r\n#     transforms.ToTensor(),\r\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n# ])\r\n\r\ndef transform_img(img: Image, image_size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\r\n    img = img.convert('RGB').resize((image_size, image_size), Image.Resampling.LANCZOS)\r\n    img = np.array(img)\r\n    img = (img / 255 - mean) / std\r\n    img = img.transpose((2, 0, 1))\r\n    img = np.expand_dims(img, axis=0)\r\n    return img.astype(np.float32)\r\n\r\n\r\nlabel_mapping = {\r\n    'nailong': 0,\r\n    'emoji': 1,\r\n    'anime': 2,\r\n    'others': 3,\r\n    'long': 4\r\n}\r\n\r\nreverse_label_mapping = {v: k for k, v in label_mapping.items()}\r\n\r\nmodel_path = 'model.onnx'\r\nsession = ort.InferenceSession(model_path)\r\n\r\nimage_path = '3.jpg'\r\nimage = Image.open(image_path).convert('RGB')\r\n# image = transform(image).unsqueeze(0).numpy()\r\nimage = transform_img(image)\r\n\r\n# \u8fd0\u884c\u63a8\u7406\r\ninput_name = session.get_inputs()[0].name\r\noutput_name = session.get_outputs()[0].name\r\noutputs = session.run([output_name], {input_name: image})\r\n\r\n# \u83b7\u53d6\u5206\u7c7b\u7ed3\u679c\r\noutput = outputs[0]\r\npredicted_class = np.argmax(output, axis=1)\r\npredicted_label = reverse_label_mapping[predicted_class[0]]\r\n\r\nprint(f'Predicted class: {predicted_label}')\r\n\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n> \u8bad\u7ec3\u7684\u65f6\u5019\u5f15\u5165\u4e86 torchvision \u7684 transforms, \u8fd9\u91cc\u4e3a\u4e86\u51cf\u5c11\u4f9d\u8d56, \u9009\u62e9\u624b\u52a8\u5b9e\u73b0, \u6709\u9700\u8981\u4e5f\u53ef\u4ee5\u81ea\u884c\u53d6\u6d88\u6ce8\u91ca\u5e76\u4fee\u6539\r\n\u3002", "top": 0, "createdAt": 1732625582, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-26", "dateLabelColor": "#bc4c00"}, "P5": {"htmlDir": "docs/post/shi-yong-k3s-da-jian-de-k8s-ji-qun-da-jian-yi-xie-jian-dan-de-ying-yong.html", "labels": ["blog"], "postTitle": "\u4f7f\u7528k3s\u642d\u5efa\u7684k8s\u96c6\u7fa4\u642d\u5efa\u4e00\u4e9b\u7b80\u5355\u7684\u5e94\u7528", "postUrl": "post/shi-yong-k3s-da-jian-de-k8s-ji-qun-da-jian-yi-xie-jian-dan-de-ying-yong.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/5", "commentNum": 0, "wordCount": 8386, "description": "> \u53ef\u80fd\u5e76\u975e\u6700\u4f73\u5b9e\u73b0, \u6ca1\u6709\u8fdb\u884c\u7cfb\u7edf\u6027\u5b66\u4e60, \u6b22\u8fce\u4ea4\u6d41\r\n\r\n## \u955c\u50cf\r\n\r\n### \u955c\u50cf\u7ba1\u7406\r\n\r\n\u5b89\u88c5\u955c\u50cf\u7ba1\u7406\u5e73\u53f0 Harbor, \u6765\u4e3a\u96c6\u7fa4\u63d0\u4f9b\u955c\u50cf\u6e90\r\n\r\n\u5728[\u4e0a\u4e00\u7bc7](https://fairyowo.github.io/post/shi-yong-%20k3s%20-da-jian-%20k8s%20-ji-qun-%28-shi-yong-guo-nei-jing-xiang-%29.html), \u4ecb\u7ecd\u4e86\u96c6\u7fa4\u7684\u642d\u5efa, \u5728\u90a3\u4e2a\u65f6\u5019\u914d\u7f6e\u4e86\u96c6\u7fa4\u7684\u955c\u50cf\u6e90, \u4e5f\u5c31\u662f\u8bf4, \u8fd9\u4e2a\u96c6\u7fa4\u6709\u7b80\u5355\u7684\u62c9\u955c\u50cf\u80fd\u529b, \u5176\u6b21, \u5b89\u88c5\u4e86 helm, \u53ef\u4ee5\u6839\u636e helm \u4ed3\u5e93\u62c9\u53d6\u5e94\u7528\r\n\r\n\u8fd9\u91cc\u4ecb\u7ecd\u62c9\u53d6\u539f\u59cbchart\u4ed3\u5e93\u7684\u76f8\u5173\u6587\u4ef6\u7684\u65b9\u6cd5\u5b89\u88c5\r\n\r\n1. \u83b7\u53d6chart\u4ed3\u5e93\u7684\u6587\u4ef6\r\n  \u524d\u5f80 [harbor-helm](harbor-helm) \u7684 github \u4ed3\u5e93\r\n  \u524d\u5f80 release, \u4e0b\u8f7d\u6e90\u4ee3\u7801, \u89e3\u538b\u4e4b\u540e\u62ff\u5230\u5176\u4e2d\u7684 `templates` \u6587\u4ef6\u5939, `Chart.yaml` \u6587\u4ef6, `values.yaml` \u6587\u4ef6\r\n2. \u4fee\u6539 `values.yaml` \u6587\u4ef6\r\n  \u8be6\u89c1 \u9644\u5f55\u4e00\r\n    > \u6211\u4eec\u7684\u5c0f\u96c6\u7fa4\u65e2\u6ca1\u6709https, \u53c8\u6ca1\u6709\u6301\u4e45\u5316\u5b58\u50a8, \u6240\u4ee5\u8fd9\u4e9b\u90fd\u4e0d\u9700\u8981\u5199\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d, \u76f4\u63a5\u5173\u6389\u8fd9\u4e9b\u529f\u80fd\u5373\u53ef\r\n    > admin \u7684\u521d\u59cb\u5316\u5bc6\u7801\u5728\u7f51\u9875\u767b\u9646\u540e\u4e5f\u80fd\u6539\r\n3. \u521b\u5efa harbor \u4e13\u5c5e\u7684 namespace\r\n  ```sh\r\n  kubectl create namespace harbor\r\n  ```\r\n4. \u542f\u52a8\r\n  ```sh\r\n  cd /path/to/harbor\r\n  helm --namespace harbor install harbor .\r\n  ```\r\n  \u5982\u679c\u5bf9\u914d\u7f6e\u9879\u540e\u6094, \u4f7f\u7528 \u4ee5\u4e0b\u547d\u4ee4\u66f4\u65b0\r\n  ```sh\r\n  helm --namespace harbor upgrade harbor .\r\n  ```\r\n\r\n\u5230 kubepi \u4e2d, \u5373\u53ef\u770b\u5230 harbor \u7684\u76f8\u5173\u955c\u50cf\u5728\u62c9\u53d6\u4e86, \u5982\u679c\u955c\u50cf\u914d\u7f6e\u6b63\u786e\u7684\u8bdd, \u8fc7\u4e00\u6bb5\u65f6\u95f4\u5c31\u4f1a\u62c9\u53d6\u6210\u529f\r\n> \u5728 kubepi \u4e2d\u4ed6\u4f1a\u4e0d\u65ad\u91cd\u8bd5\u62c9\u53d6, \u5b9e\u9645\u4e0a\u4f1a\u7f13\u6162\u62c9\u53d6\u6210\u529f\r\n> \u6211\u662f2M\u5c0f\u670d\u52a1\u5668\u62c9\u4e86\u534a\u4e2a\u5c0f\u65f6+\r\n\r\n\u5728\u62c9\u53d6\u6210\u529f\u4e4b\u540e, \u7b2c\u4e00\u65f6\u95f4\u5728\u521a\u521a `values.yaml` \u4e2d\u914d\u7f6e\u7684url\u4e2d\u767b\u5f55, \u4fee\u6539admin\u5bc6\u7801(\u5982\u679c\u6ca1\u6709\u4fee\u6539\u9ed8\u8ba4\u5bc6\u7801)\r\n\r\n### \u5411 Harbor \u4e0a\u4f20\u955c\u50cf\r\n\r\n\u9700\u8981\u4e00\u53f0\u4f7f\u7528 docker \u7684\u673a\u5668, \u5411 Harbor \u4e0a\u4f20\u955c\u50cf `docker pull`\r\n> \u8fd9\u91cc\u6211\u5728\u5b89\u88c5\u597d\u540e\u624d\u610f\u8bc6\u5230, \u6211\u7684\u96c6\u7fa4\u4f7f\u7528\u7684\u5bb9\u5668\u8fd0\u884c\u65f6 containerd, \u597d\u50cf\u6ca1\u6709\u80fd\u529b\u5bf9\u955c\u50cf\u8fdb\u884c\u4fee\u6539, \u53ea\u80fd\u5bf9\u955c\u50cf\u8fdb\u884c\u90e8\u7f72, \u6240\u4ee5\u4ee4\u8d77\u4e86\u4e00\u53f0\u673a\u5b50, \u5b89\u88c5 docker, \u914d\u7f6e\u955c\u50cf\u6e90(TODO)\r\n> \u53e6\u4e00\u79cd\u65b9\u6848\u662f\u91cd\u88c5\u96c6\u7fa4, \u4f7f\u7528 docker \u4f5c\u4e3a \u5bb9\u5668\u8fd0\u884c\u65f6, \u4f46\u6211\u6ca1\u6709\u9009\u62e9\u8fd9\u4e2a\u65b9\u6848\r\n\r\n\u505a\u597d\u51c6\u5907\u540e \u9700\u8981\u5bf9 harbor \u8fdb\u884c\u4fe1\u4efb\r\n> \u6ca1\u6709 https \u5bfc\u81f4\u7684, \u6709 https \u53ef\u4ee5\u8df3\u8fc7\u8fd9\u4e00\u6b65\r\n\r\n\u5411 `/etc/docker/daemon.json` \u5199\u5165\r\n```text\r\n'insecure-registries': ['harbor_ip:port']\r\n```\r\n\r\n> \u4f60\u9700\u8981\u81ea\u884c\u5904\u7406\u4ed6\u7684json\u8bed\u6cd5\r\n\r\n\u540e, \u4f7f\u7528\r\n\r\n```sh\r\nsystemctl daemon-reload\r\nsystemctl restart docker\r\n```\r\n\r\n\u91cd\u542f docker\r\n\r\n\u5728\u914d\u7f6e\u597d\u540e, \u53ef\u4ee5\u63a8\u4e00\u4e2a\u7b80\u5355\u7684 helloworld\u955c\u50cf\r\n\r\n```sh\r\ndocker login harbor_ip:port\r\n# \u8fd9\u91cc\u586b\u5165\u4f60\u7684\u8d26\u53f7\u4e0e\u5bc6\u7801. \u6211\u8fd9\u91cc\u662f admin \u4e0e\u76f8\u5bf9\u4e8e\u7684\u5bc6\u7801\r\n\r\ndocker run hello-world:latest\r\n# \u4fee\u6539tag\r\ndocker tag hello-world:latest harbor_ip:port/library/hello-world:latest\r\ndocker push harbor_ip:port/library/hello-world:latest\r\n```\r\n\r\n\u767b\u5f55\u5230 harbor \u63a7\u5236\u53f0, \u5373\u53ef\u770b\u5230\u521a\u521a\u63a8\u9001\u4e0a\u6765\u7684\u955c\u50cf\r\n\r\n## \u96c6\u7fa4\u62c9\u53d6\u955c\u50cf\r\n\r\n> \u5982\u679c\u4f60\u6ca1\u6709 https, \u5219\u9700\u8981\u4ee5\u4e0b\u989d\u5916\u4e00\u6b65, \u5982\u679c\u6709, \u5219\u4fdd\u8bc1\u96c6\u7fa4\u53ef\u4ee5\u8fde\u63a5\u5230 harbor \u5373\u53ef\r\n\r\n\u6839\u636e\u4e0d\u540c\u7684\u96c6\u7fa4\u642d\u5efa\u65b9\u6cd5(\u8fd9\u91cc\u662fk3s), \u5c06 harbor \u6dfb\u52a0\u8fdb\u96c6\u7fa4\u53ef\u4ee5\u62c9\u53d6\u7684\u955c\u50cf\u6e90\r\n\r\n\u4e0e\u666e\u901a\u6dfb\u52a0\u955c\u50cf\u4e00\u81f4, \u9996\u5148\u9700\u8981\u5230 `/etc/rancher/k3s` \u76ee\u5f55\u4e0b\r\n\r\n\u5411\u5176\u4e2d\u7684 `registries.yaml` \u6dfb\u52a0\u5185\u5bb9\r\n\r\n```yaml\r\nmirrors:\r\n  harbor_ip:port:\r\n    endpoint:\r\n     - http://harbor_ip:port\r\n\r\nconfigs:\r\n  harbor_ip:port:\r\n    auth:\r\n      username: \u4f60\u7684 harbor \u8d26\u53f7\r\n      password: \u4f60\u7684 harbor \u5bc6\u7801\r\n```\r\n\r\n> \u8fd9\u91cc\u53ef\u80fd `registries.yaml` \u5df2\u7ecf\u6709\u5185\u5bb9\u4e86(\u914d\u7f6e\u8fc7\u955c\u50cf\u6e90), \u4f60\u9700\u8981\u6839\u636e yaml \u7684\u8bed\u6cd5\u81ea\u884c\u5904\u7406\u4ed6\u4eec\u7684\u5173\u7cfb\r\n> \u6bcf\u4e00\u53f0\u96c6\u7fa4\u90fd\u8981\u8fd9\u4e48\u505a\r\n\r\n\u4e4b\u540e, \u91cd\u542f\u5373\u53ef\r\n```sh\r\nsystemctl restart k3s  # systemctl restart k3s-agent if agent\r\n```\r\n\r\n\u5728\u7f16\u5199\u597d kubectl \u4f7f\u7528\u7684 yaml \u540e, \u5373\u53ef\u4ece harbor \u62c9\u53d6\u955c\u50cf\r\n> \u611f\u8c22 claude-sonnet \u5e2e\u6211\u5199yaml\r\n\r\n## \u5b9e\u6218\r\n\r\n\u8fd9\u91cc\u642d\u5efa\u4e86\u4e00\u4e2a\u6c42\u751f\u4e4b\u8def2\u7684\u670d\u52a1\u5668\r\n\r\n> \u8fd9\u91cc\u5e94\u8be5\u6709\u4e00\u4e2a\u6c42\u751f\u4e4b\u8def2\u7684\u7b80\u5355\u4ecb\u7ecd\r\n\r\n### docker\u673a\u5b50\u62c9\u53d6\u955c\u50cf\r\n\r\n\u8fd9\u91cc\u4f7f\u7528\u7684\u662f [HoshinoRei/l4d2server-docker](https://github.com/HoshinoRei/l4d2server-docker)\r\n\r\n```sh\r\ndocker pull hoshinorei/l4d2server:edge\r\n```\r\n\r\n### \u63d0\u4ea4\u955c\u50cf\r\n\r\n```sh\r\ndocker tag hoshinorei/l4d2server:edge harbor_ip:port/library/hoshinorei/l4d2server:edge\r\ndocker push harbor_ip:port/library/hoshinorei/l4d2server:edge\r\n```\r\n\r\n### \u7f16\u5199 kubectl \u4f7f\u7528\u7684 yaml\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```yaml\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: l4d2server\r\nspec:\r\n  replicas: 1\r\n  selector:\r\n    matchLabels:\r\n      app: l4d2server\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: l4d2server\r\n    spec:\r\n      containers:\r\n      - name: l4d2server\r\n        image: harbor_ip:port/library/hoshinorei/l4d2server:edge\r\n        command: ['/home/steam/l4d2server/srcds_run', '-game left4dead2', '-secure', '+exec', 'server.cfg', '+map', 'c1m1_hotel', '-port', '27015', '-tickrate 60', '+sv_setmax 31']\r\n        ports:\r\n        - containerPort: 27015\r\n          name: tcp-game\r\n        - containerPort: 27015\r\n          protocol: UDP\r\n          name: udp-game\r\n        volumeMounts:\r\n        - name: addons\r\n          mountPath: /home/steam/l4d2server/left4dead2/addons/\r\n        - name: server-config\r\n          mountPath: /home/steam/l4d2server/left4dead2/cfg/server.cfg\r\n          subPath: server.cfg\r\n        - name: host-file\r\n          mountPath: /home/steam/l4d2server/left4dead2/host.txt\r\n          subPath: host.txt\r\n        - name: motd-file\r\n          mountPath: /home/steam/l4d2server/left4dead2/motd.txt\r\n          subPath: motd.txt\r\n        - name: cfg\r\n          mountPath: /home/steam/l4d2server/left4dead2/cfg/\r\n        \r\n      volumes:\r\n        - name: addons\r\n          hostPath:\r\n            path: /root/l4d2/addons/\r\n            type: Directory\r\n        - name: server-config\r\n          hostPath:\r\n            path: /root/l4d2/cfg/\r\n        - name: host-file\r\n          configMap:\r\n            name: l4d2server-host\r\n        - name: motd-file\r\n          configMap:\r\n            name: l4d2server-motd\r\n        - name: cfg\r\n          hostPath:\r\n            path: /root/l4d2/cfg/\r\n            type: Directory\r\n\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: l4d2server\r\nspec:\r\n  type: NodePort\r\n  ports:\r\n  - name: tcp-game\r\n    port: 27015\r\n    targetPort: 27015\r\n    protocol: TCP\r\n    nodePort: 30015\r\n  - name: udp-game\r\n    port: 27015\r\n    targetPort: 27015\r\n    protocol: UDP\r\n    nodePort: 30016\r\n  selector:\r\n    app: l4d2server\r\n\r\n---\r\napiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: l4d2server-host\r\ndata:\r\n  host.txt: |\r\n    # \u8fd9\u91cc\u653e\u7f6e host.txt \u7684\u5185\u5bb9\r\n\r\n---\r\napiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: l4d2server-motd\r\ndata:\r\n  motd.txt: |\r\n    # \u8fd9\u91cc\u653e\u7f6e motd.txt \u7684\u5185\u5bb9\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n> \u5177\u4f53\u7684\u53c2\u6570\u7ec6\u8282\u53c2\u8003 [\u8fd9\u91cc](https://www.bilibili.com/opus/736922474423255104)\r\n> \u9700\u8981\u5728\u5f53\u524d\u76ee\u5f55\u521b\u5efa `host.txt` \u4e0e `motd.txt`, \u5e76\u5728\u91cc\u9762\u8f93\u5165\u5185\u5bb9, \u5728\u670d\u52a1\u5668\u8fdb\u5165\u7684\u65f6\u5019\u4f1a\u663e\u793a\u8fd9\u4e9b\u5185\u5bb9\r\n\r\n\u6267\u884c\r\n\r\n```sh\r\nkubectl apply -f l4d2server.yaml\r\n```\r\n\r\n### \u5176\u4ed6\r\n\r\n> \u6302\u8f7d\u4e86\u5bbf\u4e3b\u673a\u7684\u76ee\u5f55\u6765\u653e\u7f6e l4d2 mod\r\n\r\n\u8fdb\u5165 kubepi \u4e2d, \u67e5\u770b\u5177\u4f53\u88ab\u5206\u914d\u5230\u4e86\u54ea\u53f0\u673a\u5b50\u4e0a, \u7136\u540e\u53bb\u90a3\u53f0\u673a\u5b50\u7684 ~/cfg \u4e2d, \u653e\u7f6e \u539f\u59cb l4d2 \u670d\u52a1\u5668\u7684 cfg (\u53ef\u4ee5\u901a\u8fc7\u521a\u5f00\u59cb\u7684 docker \u673a\u5b50, \u8fdb\u5165 docke \u5bb9\u5668\u53d6\u5f97), \u4e4b\u540e\u5728 kubepi \u91cd\u542f\u5373\u53ef\r\n\r\n\u5982\u679c\u9700\u8981\u6dfb\u52a0 mods, \u5219\u5c06 mod \u79fb\u52a8\u5230 addons \u8ddf cfg \u4e2d\u5373\u53ef(\u6ce8\u610f linux \u517c\u5bb9\u6027), \u7136\u540e\u91cd\u542f, \u5982\u679c\u9700\u8981\u66f4\u6539\u542f\u52a8\u547d\u4ee4\u5219\u9700\u8981\u4fee\u6539\u539f yaml\r\n\r\n## \u9644\u5f55\r\n\r\n### \u4e00\r\n\u8fd9\u91cc\u7ed9\u51fa\u5e38\u7528\u7684 harbor \u7684 values.yaml \u7684\u9009\u9879, \u590d\u5236\u81ea [(https://blog.starry-s.moe/posts/2023/harbor-helm-chart/)](https://blog.starry-s.moe/posts/2023/harbor-helm-chart/)\r\n\r\n<details><summary>\u4fee\u6539\u7684\u9009\u9879</summary>\r\n<p>\r\n\r\n```yaml\r\nexpose:\r\n# expose type, \u53ef\u4ee5\u8bbe\u7f6e\u4e3a ingress, clusterIP, nodePort, nodeBalancer\uff0c\u533a\u5206\u5927\u5c0f\u5199\r\n# \u9ed8\u8ba4\u4e3a ingress\uff08\u5982\u679c\u4e0d\u60f3\u4f7f\u7528 80/443 \u6807\u51c6\u7aef\u53e3\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u4e3a nodePort\uff0c\u7aef\u53e3\u4e3a\u9ad8\u4f4d 3000X\uff09\r\ntype: ingress\r\ntls:\r\n  # \u662f\u5426\u542f\u7528 TLS (HTTPS)\uff0c\u5efa\u8bae\u542f\u7528\r\n  enabled: true\r\n  # TLS Certificate \u7684\u6765\u6e90\uff0c\u53ef\u4ee5\u4e3a auto, secret \u6216 none\r\n  # \u5982\u679c\u4e3a secret\uff0c\u9700\u8981\u5728\u5b89\u88c5 Chart \u4e4b\u524d\u5148\u521b\u5efa TLS Secret\r\n  # 1) auto: generate the tls certificate automatically\r\n  # 2) secret: read the tls certificate from the specified secret.\r\n  # The tls certificate can be generated manually or by cert manager\r\n  # 3) none: configure no tls certificate for the ingress. If the default\r\n  # tls certificate is configured in the ingress controller, choose this option\r\n  certSource: secret\r\n  secret:\r\n    # The name of secret which contains keys named:\r\n    # 'tls.crt' - the certificate\r\n    # 'tls.key' - the private key\r\n    secretName: 'harbor-tls'\r\n    # Only needed when the 'expose.type' is 'ingress'.\r\n    notarySecretName: 'harbor-tls'\r\ningress:\r\n  hosts:\r\n    # Ingress Host\uff0c\u5982\u679c\u9700\u8981\u5141\u8bb8\u4efb\u610f\u57df\u540d/IP \u90fd\u80fd\u8bbf\u95ee\uff0c\u5c06\u5176\u8bbe\u7f6e\u4e3a\u7a7a\u5b57\u7b26\u4e32\uff08\u4e0d\u5efa\u8bae\uff09\r\n    # \u8fd9\u91cc\u586b\u5199\u7684\u57df\u540d\u52a1\u5fc5\u80fd\u89e3\u6790\u5230\u5f53\u524d\u96c6\u7fa4\r\n    core: harbor.example.com\r\n    notary: notary.example.com\r\n\r\n# Harbor external URL\r\n# \u4e0e Ingress Host \u76f8\u5bf9\u5e94\uff0c\u5982\u679c\u542f\u7528\u4e86 TLS\uff0c\u90a3\u5c31\u662f https://<domain>\r\n# \u5982\u679c\u6ca1\u542f\u7528 TLS\uff0c\u90a3\u5c31\u662f http://<domain>\r\n# \u5982\u679c expose type \u4e3a nodePort\uff0c\u5219\u586b\u5199 http(s)://<IP_ADDRESS>:3000X (\u7aef\u53e3\u53f7\u4e0d\u80fd\u4e22)\r\nexternalURL: https://harbor.example.com\r\n\r\n# \u6301\u4e45\u5377\u914d\u7f6e\uff0c\u9ed8\u8ba4\u4e3a true\uff0c\u5982\u679c\u662f\u6d4b\u8bd5\u73af\u5883\u53ef\u4ee5\u8bbe\u7f6e\u4e3a enabled: false (\u91cd\u65b0\u5b89\u88c5 Chart \u65f6\u4ed3\u5e93\u91cc\u6240\u6709\u7684\u6570\u636e\u90fd\u4f1a\u4e22\u5931\uff0c\u4e0d\u5efa\u8bae\uff01)\r\n# \u5982\u679c\u9700\u8981\u542f\u7528\u6301\u4e45\u5377\uff0c\u53ef\u4ee5\u5728\u5b89\u88c5 Chart \u4e4b\u524d\u63d0\u524d\u521b\u5efa\u597d PVC\uff0c\u5e76\u914d\u7f6e subPath\r\npersistence:\r\nenabled: true\r\nresourcePolicy: 'keep'\r\npersistentVolumeClaim:\r\n  registry:\r\n    # \u586b\u5199\u5df2\u7ecf\u521b\u5efa\u597d\u7684 PVC\r\n    existingClaim: 'harbor-pvc'\r\n    storageClass: ''\r\n    # \u5982\u679c\u5171\u7528\u4e00\u4e2a PVC\uff0c\u9700\u8981\u8bbe\u7f6e\u5b50\u76ee\u5f55\r\n    subPath: 'registry'\r\n    accessMode: ReadWriteOnce\r\n    size: 5Gi\r\n    annotations: {}\r\n  jobservice:\r\n    jobLog:\r\n      existingClaim: 'harbor-pvc'\r\n      storageClass: ''\r\n      subPath: 'jobservice'\r\n      accessMode: ReadWriteOnce\r\n      size: 1Gi\r\n      annotations: {}\r\n  database:\r\n    existingClaim: 'harbor-pvc'\r\n    storageClass: ''\r\n    subPath: 'database'\r\n    accessMode: ReadWriteOnce\r\n    size: 1Gi\r\n    annotations: {}\r\n  redis:\r\n    existingClaim: 'harbor-pvc'\r\n    storageClass: ''\r\n    subPath: 'redis'\r\n    accessMode: ReadWriteOnce\r\n    size: 1Gi\r\n    annotations: {}\r\n  trivy:\r\n    existingClaim: 'harbor-pvc'\r\n    storageClass: ''\r\n    subPath: 'trivy'\r\n    accessMode: ReadWriteOnce\r\n    size: 5Gi\r\n    annotations: {}\r\n\r\n# Admin \u521d\u59cb\u5bc6\u7801\r\nharborAdminPassword: 'Harbor12345'\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\u3002", "top": 0, "createdAt": 1733123581, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-02", "dateLabelColor": "#bc4c00"}, "P6": {"htmlDir": "docs/post/2024 Advent of Code -fu-pan-yu-da-an- (-yi-) 1-8-ti.html", "labels": ["blog"], "postTitle": "2024 Advent of Code \u590d\u76d8\u4e0e\u7b54\u6848 (\u4e00) 1-8\u9898", "postUrl": "post/2024%20Advent%20of%20Code%20-fu-pan-yu-da-an-%20%28-yi-%29%201-8-ti.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/6", "commentNum": 0, "wordCount": 16860, "description": "[Advent of Code](https://adventofcode.com/)\r\n\r\n\u4f7f\u7528 python \u7f16\u5199, \u6ca1\u6709\u6574\u7406\u4ee3\u7801, \u6240\u4ee5\u975e\u5e38\u4e71(\u53d8\u91cf\u4e71\u53d6\u540d, \u6ca1\u6709\u6ce8\u91ca, \u903b\u8f91\u5947\u602a, \u5e76\u975e\u6700\u4f73\u5b9e\u73b0)\r\n\u53ef\u4ee5\u4f7f\u7528 gpt \u76f8\u5173\u5de5\u5177\u8f85\u52a9\u67e5\u770b\r\n\r\n> \u5982\u679c\u6ca1\u6709\u7279\u610f\u8bf4\u660e, \u53d8\u91cf a \u7edf\u4e00\u5b58\u653e\u6240\u6709\u539f\u59cb\u5b57\u7b26\u4e32\r\n\r\n## \u7b2c\u4e00\u9898\r\n\r\n[https://adventofcode.com/2024/day/1](https://adventofcode.com/2024/day/1)\r\n\r\n### 1\u9898\r\n\r\n\u8bf7\u5c06\u6570\u5b57\u914d\u5bf9\u5e76\u6d4b\u91cf\u5b83\u4eec\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002", "top": 0, "createdAt": 1733123787, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-02", "dateLabelColor": "#bc4c00"}, "P7": {"htmlDir": "docs/post/mian-xun-lian-de-RAG pipeline.html", "labels": ["blog"], "postTitle": "\u514d\u8bad\u7ec3\u7684RAG pipeline", "postUrl": "post/mian-xun-lian-de-RAG%20pipeline.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/7", "commentNum": 0, "wordCount": 1620, "description": "> \u672c\u6587\u7684\u6846\u67b6\u662f `llama_index`\r\n\r\n> \u6574\u7406\u53c2\u8003\u81ea\r\n> [EasyRAG](https://github.com/BUAADreamer/EasyRAG)\r\n> [RAG \u6700\u4f73\u5b9e\u8df5](https://zhuanlan.zhihu.com/p/8861103446)\r\n\r\n## \u6570\u636e\u8bfb\u53d6\u4e0e\u5904\u7406\r\n\r\n\u5c06\u5176\u4ed6\u7c7b\u578b\u8f6c\u6362\u4e3a\u51e0\u79cd\u57fa\u7840\u7c7b\u578b, \u518d\u5c06\u5bf9\u57fa\u7840\u7c7b\u578b\u8fdb\u884c\u89e3\u6790\r\n\r\n\u4f7f\u7528\u5230\u7684\u57fa\u7840\u7c7b\u578b\u4e3a: `markdown`, `html`, `pdf`\r\n\r\n\u4f7f\u7528\u5230\u7684\u5e93\u4e3a: [dify_rag](https://github.com/hustyichi/dify-rag)\r\n\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u57fa\u7840\u7c7b\u578b\u89e3\u6790\u65b9\u6848, \u89e3\u6790\u6210 `langchain` \u7684 `Document` \u5f62\u5f0f\r\n> \u5c3d\u7ba1\u4ed6\u662f\u7ed9 `dify` \u8bbe\u8ba1, \u4f46\u4ed6\u662f\u901a\u7528\u5f0f\u8bbe\u8ba1, \u53ef\u4ee5\u7528\u5728\u5176\u4ed6\u5730\u65b9\r\n\r\n```sh\r\npip install dify_rag\r\n```\r\n\r\n```python\r\nfrom dify_rag.extractor.html_extractor import HtmlExtractor\r\nfrom dify_rag.extractor.markdown_extractor import MarkdownExtractor\r\n\r\ndocuments = HtmlExtractor(r'path/to/data.html').extract()  # MarkdownExtractor(r'path/to/data.md').extract()\r\n\r\n# \u8f6c\u6362\u6210 llama_index \u7684 Document \u683c\u5f0f\r\ndocs = []\r\nfor i in documents:\r\n    i.metadata['titles'] = str(i.metadata['titles'])  # \u517c\u5bb9\u6027\u95ee\u9898, llama_index \u4e0d\u652f\u6301 titles \u91cc\u7528list[str]\r\n    docs.append(Document(text=i.page_content, metadata=i.metadata))\r\n\r\n```\r\n\r\n## \u5207\u5206\u6587\u6863\r\n\r\n`chunk_size` \u5728 256 512 1024 \u4e2d\u9009\u62e9, \u8fd9\u91cc\u9009\u62e9\u7684\u662f 512\r\n`chunk_overlap` \u89c6\u5b58\u50a8\u6210\u672c, \u8fd9\u91cc\u9009\u62e9\u662f 40\r\n\r\n### \u7236\u5b50\u5207\u5206\r\n\r\n> \u5c06\u4e00\u4efd Document \u4e2d\u7684\u6587\u6863, \u5207\u5206\u6210\u7236\u5b50\u7684\u5f62\u5f0f, \u68c0\u7d22\u5230\u5b50\u8282\u70b9\u7684\u65f6\u5019, \u4f7f\u7528\u7236\u8282\u70b9\u8fd4\u56de, \u6765\u62d3\u5c55\u4e0a\u4e0b\u6587\r\n\r\n```python\r\nnode_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[512 * 4, 512], chunk_overlap=40)\r\nnodes = node_parser.get_nodes_from_documents(docs)\r\n```\r\n\r\n### \u666e\u901a\u5207\u5206\r\n\r\n```python\r\nnode_parser = SentenceSplitter(chunk_size=512, chunk_overlap=40)\r\nnodes = node_parser.get_nodes_from_documents(docs)\r\n```\r\n\r\n### embedding\r\n\r\n\u6700\u597d\u7684\u4ecd\u7136\u662f\u4f7f\u7528 `llm` \u8c03\u6574\u6210\u7684 `embedding`, \u4e0d\u8fc7\u8fd9\u91cc\u8003\u8651\u5230\u63a8\u7406\u6210\u672c, \u8fd9\u91cc\u4f7f\u7528\u7684\u662f[BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)\r\n\r\n```python\r\nembed_model = HuggingFaceEmbedding(model_name='BAAI/bge-m3', cache_folder='cache')\r\n```\r\n\r\nTODO\u3002", "top": 0, "createdAt": 1734083575, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-13", "dateLabelColor": "#bc4c00"}, "P8": {"htmlDir": "docs/post/2024 Advent of Code -fu-pan-yu-da-an- (-er-) (9-16-ti-).html", "labels": ["blog"], "postTitle": "2024 Advent of Code \u590d\u76d8\u4e0e\u7b54\u6848 (\u4e8c) (9-16\u9898)", "postUrl": "post/2024%20Advent%20of%20Code%20-fu-pan-yu-da-an-%20%28-er-%29%20%289-16-ti-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/8", "commentNum": 0, "wordCount": 26029, "description": "[Advent of Code](https://adventofcode.com/)\n\n\u4f7f\u7528 python \u7f16\u5199, \u6ca1\u6709\u6574\u7406\u4ee3\u7801, \u6240\u4ee5\u975e\u5e38\u4e71(\u53d8\u91cf\u4e71\u53d6\u540d, \u6ca1\u6709\u6ce8\u91ca, \u903b\u8f91\u5947\u602a, \u5e76\u975e\u6700\u4f73\u5b9e\u73b0)\n\u53ef\u4ee5\u4f7f\u7528 gpt \u76f8\u5173\u5de5\u5177\u8f85\u52a9\u67e5\u770b\n\n> \u5982\u679c\u6ca1\u6709\u7279\u610f\u8bf4\u660e, \u53d8\u91cf a \u7edf\u4e00\u5b58\u653e\u6240\u6709\u539f\u59cb\u5b57\u7b26\u4e32\n\n## \u7b2c\u4e5d\u9898\n\n[https://adventofcode.com/2024/day/9](https://adventofcode.com/2024/day/9)\n\n### 1\u9898\n\n\u4e00\u4e2a\u78c1\u76d8\u4e2d\u7684\u6587\u4ef6\u8868\u793a\u65b9\u6cd5, \u6bcf\u4e24\u4f4d\u6570\u5b57\u5404\u8868\u793a, x\u5757\u6587\u4ef6, x\u5757\u7a7a\u7684\u533a\u57df\n\u4f8b\u5982\n`12345`\n\u8868\u793a \u4e00\u5757\u6587\u4ef6 \u4e24\u5757\u7a7a\u6587\u4ef6 \u4e09\u5757\u6587\u4ef6 \u56db\u5757\u7a7a\u6587\u4ef6 \u4e94\u5757\u6587\u4ef6\n\u6bcf\u4e2a\u6587\u4ef6\u4ece\u524d\u5f80\u540e\u7684id\u4e3a\u4ed6\u4eec\u5728\u78c1\u76d8\u4e2d\u7684\u987a\u5e8f, \u4f8b\u5982\u4e0a\u8ff0\u53ef\u4ee5\u8868\u793a\u4e3a\n`0..111....22222`\n\n\u5e0c\u671b\u4ece\u540e\u5f80\u524d\u7684\u5c06\u6587\u4ef6\u585e\u5165\u4ece\u524d\u5f80\u540e\u4e2d\u7a7a\u7684\u5730\u65b9\n\n\u4f8b\u5982\n```text\n0..111....22222\n02.111....2222.\n022111....222..\n0221112...22...\n02211122..2....\n022111222......\n```\n\n\u6700\u540e\u8f93\u51fa\u6bcf\u4e2a\u5757\u4f4d\u7f6e*id\u53f7\u4e4b\u548c\n\n<details><summary>Details</summary>\n<p>\n\n```python\n# \u6784\u5efa\nt = []\nflag = True\nfile_id = 0\nfor i in list(a):\n    if flag:\n        for _ in range(int(i)):\n            t.append(file_id)\n        flag = False\n        file_id += 1\n    else:\n        for _ in range(int(i)):\n            t.append('.')\n        flag = True\n\ni = 0\nj = len(t) - 1\n\nwhile i < j:\n    if t[i] == '.':\n        if t[j] != '.':\n            t[i], t[j] = t[j], t[i]\n        else:\n            i -= 1\n        j -= 1\n    i += 1\n\nans = 0\nfor i, j in enumerate(t):\n    if j != '.':\n        ans += i * j\nprint(ans)\n\n```\n\n</p>\n</details> \n\n### 2\u9898\n\n\u5728\u4e00\u9898\u7684\u57fa\u7840\u4e0a, \u4fee\u6539\u4ece\u540e\u5f80\u524d\u653e\u5165\u4ece\u524d\u5f80\u540e\u7a7a\u533a\u57df\u7684\u65b9\u6cd5, \u4ece\u5355\u4e2a\u5757\u79fb\u52a8\u8f6c\u6362\u4e3a\u6574\u4e2a\u6587\u4ef6\u79fb\u52a8, \u4f8b\u5982\n```text\n00...111...2...333.44.5555.6666.777.888899\n0099.111...2...333.44.5555.6666.777.8888..\n0099.1117772...333.44.5555.6666.....8888..\n0099.111777244.333....5555.6666.....8888..\n00992111777.44.333....5555.6666.....8888..\n```\n\n\u6700\u540e\u8f93\u51fa\u6bcf\u4e2a\u5757\u4f4d\u7f6e*id\u53f7\u4e4b\u548c\n\n<details><summary>Details</summary>\n<p>\n\n```python\n# \u6784\u5efa\nt = []\nflag = True\nfile_id = 0\nfor i in list(a):\n    if flag:\n        for _ in range(int(i)):\n            t.append(file_id)\n        flag = False\n        file_id += 1\n    else:\n        for _ in range(int(i)):\n            t.append('.')\n        flag = True\n\n\ndef get_file_size(file_id):\n    return t.count(file_id)\n\nfor i in range(file_id - 1, -1, -1):\n    file_size = get_file_size(i)\n    file_index = t.index(i)\n    flag = False\n    size = 0\n    for id, j in enumerate(t):\n        if j == '.':\n            flag = True\n        else:\n            flag = False\n            size = 0\n        \n        if flag:\n            size += 1\n            if size == file_size:\n                # change\u4f4d\u7f6e\n                for k in range(id, id - file_size, -1):\n                    t[k], t[file_index] = t[file_index], t[k]\n                    file_index += 1\n\n                break\n        if id >= file_index:\n            break\n\nans = 0\nfor i, j in enumerate(t):\n    if j != '.':\n        ans += i * j\nprint(ans)\n\n```\n\n</p>\n</details> \n\n## \u7b2c\u5341\u9898\n\n[https://adventofcode.com/2024/day/10](https://adventofcode.com/2024/day/10)\n\n### 1\u9898\n\n\u7ed9\u5b9a\u4e00\u5e45\u7531\u6570\u5b57\u7ec4\u6210\u7684\u5730\u56fe, \u4ece 0 \u5f00\u59cb, \u4e00\u6b65\u4e00\u6b65\u4e0a\u4e0b\u5de6\u53f3\u79fb\u52a8\u5230 9\n\u6c42\u4e00\u526f\u56fe\u4e2d, \u6bcf\u4e00\u4e2a 0 \u80fd\u5230\u8fbe\u7684 9 \u6709\u591a\u5c11\u4e2a, \u8f93\u51fa\u4ed6\u4eec\u7684\u548c\n\n<details><summary>Details</summary>\n<p>\n\n```python\naaa = []\nfor i in a.splitlines():\n    aaa.append(list(map(int, list(i))))\n\n# print(aaa)\n\n# \u83b7\u53d6\u6240\u6709 0 \u8ddf 9 \u7684\u4f4d\u7f6e\npos_0 = []\npos_9 = []\nfor i in range(len(aaa)):\n    for j in range(len(aaa[i])):\n        if aaa[i][j] == 0:\n            pos_0.append((i, j))\n        elif aaa[i][j] == 9:\n            pos_9.append((i, j))\n\ndef get_allow_pos(pos):\n    for i in [(0, 1), (1, 0), (-1, 0), (0, -1)]:\n        next_step = (pos[0] + i[0], pos[1] + i[1])\n        if len(aaa) > next_step[0] >= 0 and len(aaa[0]) > next_step[1] >= 0:\n            if aaa[next_step[0]][next_step[1]] == aaa[pos[0]][pos[1]] + 1:\n                yield (pos[0] + i[0], pos[1] + i[1])\n\n\ndef dfs(pos, pos_9):\n    if pos == pos_9:\n        return 1\n    aa = 0\n    for p in get_allow_pos(pos):\n        aa = dfs(p, pos_9)\n        if aa > 0:\n            return aa\n    return aa\n\nans = 0\nfor i in pos_0:\n    for j in pos_9:\n        ans += dfs(i, j)\n\nprint(ans)\n\n``` \n\n</p>\n</details> \n\n### 2\u9898\n\n\u6c42 0 \u5230\u6bcf\u4e00\u4e2a 9 \u6709\u591a\u5c11\u79cd\u4e0d\u540c\u7684\u8d70\u6cd5 (\u6ce8\u610f\u4e0e\u7b2c\u4e00\u9898\u7684\u533a\u522b, \u7b2c\u4e00\u9898\u53ea\u8981\u6c42\u5230\u8fbe, \u7b2c\u4e8c\u9898\u9700\u8981\u627e\u5230\u6240\u6709\u8def\u7ebf)\n\n<details><summary>Details</summary>\n<p>\n\n```python\naaa = []\nfor i in a.splitlines():\n    aaa.append(list(map(int, list(i))))\n\n# print(aaa)\n\n# \u83b7\u53d6\u6240\u6709 0 \u8ddf 9 \u7684\u4f4d\u7f6e\npos_0 = []\npos_9 = []\nfor i in range(len(aaa)):\n    for j in range(len(aaa[i])):\n        if aaa[i][j] == 0:\n            pos_0.append((i, j))\n        elif aaa[i][j] == 9:\n            pos_9.append((i, j))\n\ndef get_allow_pos(pos):\n    for i in [(0, 1), (1, 0), (-1, 0), (0, -1)]:\n        next_step = (pos[0] + i[0], pos[1] + i[1])\n        if len(aaa) > next_step[0] >= 0 and len(aaa[0]) > next_step[1] >= 0:\n            if aaa[next_step[0]][next_step[1]] == aaa[pos[0]][pos[1]] + 1:\n                yield (pos[0] + i[0], pos[1] + i[1])\n\n\ndef dfs(pos, pos_9):\n    if pos == pos_9:\n        return 1\n    aa = 0\n    for p in get_allow_pos(pos):\n        aa = dfs(p, pos_9)\n        if aa > 0:\n            return aa\n    return aa\n\nans = 0\nfor i in pos_0:\n    for j in pos_9:\n        ans += dfs(i, j)\n\nprint(ans)\n\n```\n\n</p>\n</details> \n\n> \u5728\u4e00\u9898\u7684\u57fa\u7840\u4e0a, dfs\u56fa\u5b9a\u8fd4\u56de1 \u53d8\u6210 dfs \u8fd4\u56de\u4e0a\u4e00\u6b21dfs + 1\n\n## \u7b2c\u5341\u4e00\u9898\n\n[https://adventofcode.com/2024/day/11](https://adventofcode.com/2024/day/11)\n\n### 1\u9898\n\n\u7ed9\u5b9a\u4e00\u4e32\u6570\u5b57, \u6839\u636e\u4ee5\u4e0b\u89c4\u5219\u53d8\u6362\n\n1. \u5982\u679c\u6570\u5b57\u662f0, \u5219\u6570\u5b57\u662f1\n2. \u5982\u679c\u6570\u5b57\u662f\u5076\u6570\u4f4d, \u5219\u6570\u5b57\u53d8\u6210\u4e24\u4e2a\u6570\u5b57, \u5de6\u534a\u8ddf\u53f3\u534a, \u4f8b\u5982 1000 \u53d8\u6210 10 \u8ddf 00, \u4e0d\u4fdd\u7559\u524d\u5bfc0, 00\u53d8\u62100\n3. \u5982\u679c\u6ca1\u6709\u78b0\u5230\u524d\u4e24\u6761\u89c4\u5219, \u5219\u6570\u5b57=\u6570\u5b57*2024\n\n\u987a\u5e8f\u90fd\u4f1a\u88ab\u4fdd\u7559 (\u4f46\u662f\u8fd9\u9898\u6ca1\u6709\u7528\u5230, \u800c\u4e14\u4f1a\u8bef\u5bfc\u7b2c\u4e8c\u9898)\n\u6a21\u62df\u4e0a\u8ff0\u89c4\u521925\u6b21\n\n<details><summary>Details</summary>\n<p>\n\n```python\naa = a.split(' ')\n\nfor _ in range(25):\n    i = 0\n    while i < len(aa):\n        if aa[i] == '0':\n            aa[i] = '1'\n        elif len(aa[i]) % 2 == 0:\n            left = aa[i][:len(aa[i]) // 2]\n            left = str(int(left))\n            right = aa[i][len(aa[i]) // 2:]\n            right = str(int(right))\n            aa.insert(i+1, right)\n            aa[i] = left\n            i += 1\n        else:\n            aa[i] = str(int(aa[i]) * 2024)\n        \n        i += 1\n\nprint(len(aa))\n```\n\n</p>\n</details> \n\n> \u6a21\u62df\u5373\u53ef, 25\u6b21\u86ee\u5c11\u7684\u53ef\u4ee5\u76f4\u63a5\u51fa\u6765\n\n### 2\u9898\n\n\u57281\u9898\u7684\u57fa\u7840\u4e0a, \u6a21\u62df75\u6b21\n\n<details><summary>Details</summary>\n<p>\n\n```python\nfrom collections import defaultdict\nfrom tqdm import tqdm\naa = list(map(int, a.split(' ')))\n\ndef get_length(num):\n    i = 0\n    while num > 0:\n        num //= 10\n        i += 1\n    return i\n\nt = defaultdict(int)\n\nfor i in aa:\n    t[i] += 1\n\nfor _ in tqdm(range(75)):\n    tt = defaultdict(int)\n    for i, j in t.items():\n        length = get_length(i)\n        if i == 0:\n            tt[1] += j\n        elif length % 2 == 0:\n            tt[i // 10 ** (length // 2)] += j\n            tt[i % 10 ** (length // 2)] += j\n        else:\n            tt[i * 2024] += j\n        \n        t = tt\n\nprint(sum(t.values()))\n```\n\n</p>\n</details> \n\n> `tqdm` \u662f\u4e3a\u4e86\u76d1\u63a7\u901f\u5ea6, \u975e\u5fc5\u8981\u5f15\u5165\n> \u4e0e\u7b2c\u4e00\u9898\u4e0d\u540c, \u8fd9\u9898\u6307\u6570\u7206\u70b8, 75\u6b21\u4f1a\u8d85\u65f6, \u56e0\u4e3a\u7b54\u6848\u4e0d\u8981\u6c42\u987a\u5e8f, \u6240\u4ee5\u53ef\u4ee5\u7528\u7f13\u5b58\n\n## \u7b2c\u5341\u4e8c\u9898\n\n[https://adventofcode.com/2024/day/12](https://adventofcode.com/2024/day/12)\n\n### 1\u9898\n\n\u5212\u5206\u533a\u57df\n\n```text\nAAAA\nBBCD\nBBCC\nEEEC\n```\n\n\u5212\u5206\u6210\n\n```text\n+-+-+-+-+\n|A A A A|\n+-+-+-+-+     +-+\n              |D|\n+-+-+   +-+   +-+\n|B B|   |C|\n+   +   + +-+\n|B B|   |C C|\n+-+-+   +-+ +\n          |C|\n+-+-+-+   +-+\n|E E E|\n+-+-+-+\n```\n\n\u5206\u4e3a\u4e94\u4e2a\u533a\u57df, \n\u8ba1\u7b97\u6bcf\u4e2a\u533a\u57df\u7684\u5468\u957f*\u9762\u79ef\u4e4b\u548c\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = []\nfor i in a.splitlines():\n    aa.append(list(i))\n\ndef get_perimeter(arr):\n    perimeter = 0\n    for i in range(len(arr)):\n        for j in range(len(arr[0])):\n            if arr[i][j] == 1:\n                perimeter += 4\n                if i > 0 and arr[i - 1][j] == 1:\n                    perimeter -= 1\n                if j > 0 and arr[i][j - 1] == 1:\n                    perimeter -= 1\n                if i < len(arr) - 1 and arr[i + 1][j] == 1:\n                    perimeter -= 1\n                if j < len(arr[0]) - 1 and arr[i][j + 1] == 1:\n                    perimeter -= 1\n    \n    return perimeter\n\ndef get_area(arr):\n    area = 0\n    for i in range(len(arr)):\n        for j in range(len(arr[0])):\n            if arr[i][j] == 1:\n                area += 1\n    return area\n\ndef get_allow_pos(pos):\n    allow_pos = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n    char = aa[pos[0]][pos[1]]\n    for i in allow_pos:\n        next_pos = (pos[0] + i[0], pos[1] + i[1])\n        if len(aa) > next_pos[0] >= 0 and len(aa[0]) > next_pos[1] >= 0:\n            if aa[next_pos[0]][next_pos[1]] == char:\n                yield next_pos\n\n\nans = 0\n\nalready_visited = np.zeros((len(aa), len(aa[0])))\nfor i in range(len(aa)):\n    for j in range(len(aa[i])):\n        if already_visited[i][j] == 0:\n            # print(aa[i][j])\n            array_ = np.zeros((len(aa), len(aa[0])))\n            already_visited[i][j] = 1\n            array_[i][j] = 1\n            def dfs(pos):\n                for next_pos in get_allow_pos(pos):\n                    if already_visited[next_pos[0]][next_pos[1]] == 0:\n                        already_visited[next_pos[0]][next_pos[1]] = 1\n                        array_[next_pos[0]][next_pos[1]] = 1\n                        dfs(next_pos)\n            \n            dfs((i, j))\n            area = get_area(array_)\n            perimeter = get_perimeter(array_)\n            ans += area * perimeter\n        \nprint(ans)\n\n```\n\n</p>\n</details> \n\n> \u52a0\u4e00\u4e2a\u6b63\u65b9\u5f62\u8fb9\u957f+4, \u5982\u679c\u65c1\u8fb9\u6bcf\u6709\u4e00\u4e2a\u6b63\u65b9\u5f62\u5c31-1\u7684\u8fb9\u957f\n\n### 2\u9898\n\n1\u9898\u7684\u8fb9\u957f\u53d8\u6210\u8fb9\u7684\u6570\u91cf\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = []\nfor i in a.splitlines():\n    aa.append(list(i))\n\n\n\ndef get_area(arr):\n    area = 0\n    for i in range(len(arr)):\n        for j in range(len(arr[0])):\n            if arr[i][j] == 1:\n                area += 1\n    return area\n\ndef get_perimeter(region):\n        \n    max_x = len(region) - 1\n    max_y = len(region[0]) - 1\n    min_x = min_y = 0\n    \n    def state(x, y):\n        if x < 0 or x > max_x or y < 0 or y > max_y:\n            return False\n        return region[x][y]\n    \n    perimeter = 0\n    \n    # \u5782\u76f4\u65b9\u5411\u626b\u63cf\n    for i in range(max_x + 1):\n        st = state(i, -1)\n        for j in range(max_y + 2):\n            if st != state(i, j):\n                if st != state(i-1, j-1) or st == state(i-1, j):\n                    perimeter += 1\n                if st != state(i+1, j-1) or st == state(i+1, j):\n                    perimeter += 1\n                st = not st\n    \n    # \u6c34\u5e73\u65b9\u5411\u626b\u63cf\n    for j in range(max_y + 1):\n        st = state(-1, j)\n        for i in range(max_x + 2):\n            if st != state(i, j):\n                if st != state(i-1, j-1) or st == state(i, j-1):\n                    perimeter += 1\n                if st != state(i-1, j+1) or st == state(i, j+1):\n                    perimeter += 1\n                st = not st\n    \n    return perimeter // 2\n\ndef get_allow_pos(pos):\n    allow_pos = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n    char = aa[pos[0]][pos[1]]\n    for i in allow_pos:\n        next_pos = (pos[0] + i[0], pos[1] + i[1])\n        if len(aa) > next_pos[0] >= 0 and len(aa[0]) > next_pos[1] >= 0:\n            if aa[next_pos[0]][next_pos[1]] == char:\n                yield next_pos\n\nans = 0\n\nalready_visited = np.zeros((len(aa), len(aa[0])))\nfor i in range(len(aa)):\n    for j in range(len(aa[i])):\n        if already_visited[i][j] == 0:\n            # print(aa[i][j])\n            array_ = np.zeros((len(aa), len(aa[0])))\n            already_visited[i][j] = 1\n            array_[i][j] = 1\n            def dfs(pos):\n                for next_pos in get_allow_pos(pos):\n                    if already_visited[next_pos[0]][next_pos[1]] == 0:\n                        already_visited[next_pos[0]][next_pos[1]] = 1\n                        array_[next_pos[0]][next_pos[1]] = 1\n                        \n                        dfs(next_pos)\n            \n            dfs((i, j))\n            area = get_area(array_)\n            perimeter = get_perimeter(array_)\n            # print(perimeter)\n            ans += area * perimeter\n        \nprint(ans)\n\n```\n\n</p>\n</details> \n\n> \u4e00\u6761\u8fb9\u6709\u4e24\u4e2a\u89d2, \u627e\u5230\u6240\u6709\u89d2\u4e4b\u540e\u6574\u96642\u5373\u53ef\n\n## \u7b2c\u5341\u4e09\u9898\n\n[https://adventofcode.com/2024/day/13](https://adventofcode.com/2024/day/13)\n\n### 1\u9898\n\n\u6309\u4e0b\u6309\u94aeA\u6216B, \u79fb\u52a8\u8001\u864e\u722a, \u8ba9\u8001\u864e\u722a\u79fb\u52a8\u5230\u6307\u5b9a\u7684\u4f4d\u7f6e, \u6309\u4e0bA\u9700\u8981\u4e09\u5757\u94b1, B\u9700\u8981\u4e00\u5757\u94b1\n\u6709\u53ef\u80fd\u65e0\u89e3(\u65e0\u6cd5\u79fb\u52a8\u5230\u6307\u5b9a\u4f4d\u7f6e)\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = a.split('\\n\\n')\nfrom sympy import *\n\nans = 0\nfor i in aa:\n    inputs = i.split('\\n')\n    # \u63d0\u53d6\u8f93\u5165\n    ax, ay = inputs[0].split(': ')[1].split(', ')\n    bx, by = inputs[1].split(': ')[1].split(', ')\n    t1, t2 = inputs[2].split(': ')[1].split(', ')\n    ax, ay = int(ax[2:]), int(ay[2:])\n    bx, by = int(bx[2:]), int(by[2:])\n    t1, t2 = int(t1[2:]), int(t2[2:])\n    m = Symbol('m')\n    n = Symbol('n')\n    temp = solve([m * ax + n * bx - t1, m * ay + n * by - t2], [m, n])\n    # print(temp)\n    if temp[m].is_Integer and temp[n].is_Integer:\n        ans += int(temp[m]) * 3 + int(temp[n])\n\nprint(ans)\n\n```\n\n</p>\n</details> \n> \u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b\u7ec4\u7684\u6574\u6570\u89e3\n\n### 2\u9898\n\n\u5728\u4e00\u9898\u7684\u57fa\u7840\u4e0a, X\u8f74\u548cY\u8f74\u4e0a\u90fd\u9ad8\u51fa10000000000000(\u5927\u6570)\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = a.split('\\n\\n')\nfrom sympy import *\n\nans = 0\nfor i in aa:\n    inputs = i.split('\\n')\n    # \u63d0\u53d6\u8f93\u5165\n    ax, ay = inputs[0].split(': ')[1].split(', ')\n    bx, by = inputs[1].split(': ')[1].split(', ')\n    t1, t2 = inputs[2].split(': ')[1].split(', ')\n    ax, ay = int(ax[2:]), int(ay[2:])\n    bx, by = int(bx[2:]), int(by[2:])\n    t1, t2 = int(t1[2:]) + 10000000000000, int(t2[2:]) + 10000000000000\n    m = Symbol('m')\n    n = Symbol('n')\n    temp = solve([m * ax + n * bx - t1, m * ay + n * by - t2], [m, n])\n    # print(temp)\n    if temp[m].is_Integer and temp[n].is_Integer:\n        ans += int(temp[m]) * 3 + int(temp[n])\n\nprint(ans)\n```\n\n</p>\n</details> \n\n> python\u65e0\u9650\u7cbe\u5ea6\u6574\u6570, \u4e0d\u9700\u8981\u989d\u5916\u5904\u7406\n\n## \u7b2c\u5341\u56db\u9898\n\n[https://adventofcode.com/2024/day/14](https://adventofcode.com/2024/day/14)\n\n### 1\u9898\n\n\u7ed9\u5b9a\u70b9\u5750\u6807, \u70b9\u7684\u79fb\u52a8\u901f\u5ea6, \u5927\u5c0f\u56fa\u5b9a\u7684\u56fe\n\n\u6c42 \u56db\u4e2a\u8c61\u9650\u5185\u70b9\u7684\u6570\u91cf \u4e4b\u79ef\n\u8c61\u9650\u662f\u53bb\u6389\u6700\u4e2d\u95f4\u4e00\u5217\u4e0e\u4e00\u884c\u4f7f\u5f97\u56fe\u5206\u6210\u56db\u4e2a\u533a\u57df\n\u70b9\u5230\u8fb9\u754c\u4f1a\u4f20\u9001\u5230\u53e6\u4e00\u4fa7 (mod)\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\ndef main():\n    lines = a.splitlines()\n\n    robots = []\n    for line in lines:\n        p_part, v_part = line.strip().split()\n        p_x, p_y = map(int, p_part[2:].split(','))\n        v_x, v_y = map(int, v_part[2:].split(','))\n        robots.append({'p': (p_x, p_y), 'v': (v_x, v_y)})\n\n    positions = {}\n    for robot in robots:\n        x = (robot['p'][0] + robot['v'][0] * 100) % 101\n        y = (robot['p'][1] + robot['v'][1] * 100) % 103\n        positions[(x, y)] = positions.get((x, y), 0) + 1\n\n    q1 = q2 = q3 = q4 = 0\n    for (x, y), count in positions.items():\n        if x < 50 and y < 51:\n            q1 += count\n        elif x > 50 and y < 51:\n            q2 += count\n        elif x > 50 and y > 51:\n            q3 += count\n        elif x < 50 and y > 51:\n            q4 += count\n\n    safety_factor = q1 * q2 * q3 * q4\n    print(safety_factor)\n\nif __name__ == '__main__':\n    main()\n\n```\n\n</p>\n</details> \n\n### 2\u9898\n\n\u76f4\u63a5\u8d34\u539f\u9898, \u56e0\u4e3a\u539f\u9898\u662f\u9605\u8bfb\u7406\u89e3\n\nDuring the bathroom break, someone notices that these robots seem awfully similar to ones built and used at the North Pole. If they're the same type of robots, they should have a hard-coded Easter egg: very rarely, most of the robots should arrange themselves into a picture of a Christmas tree.\n> \u5728\u4e0a\u5395\u6240\u7684\u65f6\u5019\uff0c\u6709\u4eba\u6ce8\u610f\u5230\u8fd9\u4e9b\u673a\u5668\u4eba\u770b\u8d77\u6765\u4e0e\u5728\u5317\u6781\u5efa\u9020\u548c\u4f7f\u7528\u7684\u673a\u5668\u4eba\u975e\u5e38\u76f8\u4f3c\u3002", "top": 0, "createdAt": 1734487384, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-18", "dateLabelColor": "#bc4c00"}, "P9": {"htmlDir": "docs/post/huan-shou-pa-lu-fan-zhi-shu-sou-suo-, -yong-yu-sou-suo-cong-A-pa-lu-dao-B-pa-lu-de-suo-you-zui-duan-lu-jing.html", "labels": ["blog", "game"], "postTitle": "\u5e7b\u517d\u5e15\u9c81\u7e41\u6b96\u6811\u641c\u7d22, \u7528\u4e8e\u641c\u7d22\u4eceA\u5e15\u9c81\u5230B\u5e15\u9c81\u7684\u6240\u6709\u6700\u77ed\u8def\u5f84", "postUrl": "post/huan-shou-pa-lu-fan-zhi-shu-sou-suo-%2C%20-yong-yu-sou-suo-cong-A-pa-lu-dao-B-pa-lu-de-suo-you-zui-duan-lu-jing.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/9", "commentNum": 0, "wordCount": 5608, "description": "## \u76f8\u5173\u539f\u7406\n\n\u8be6\u89c1[\u8fd9\u91cc](https://paldb.cc/cn/Breeding_Farm#BreedingFarm)\n\n\u7b80\u5355\u6765\u8bf4, \u5b50\u5e15\u9c81\u662f\u4e24\u4e2a\u7236\u5e15\u9c81\u7e41\u6b96\u529b\u4e0e1\u7684\u548c\u6574\u96642, \u7279\u6b8a\u914d\u65b9\u9700\u8981\u6309\u7167\u4e13\u6709\u914d\u65b9\u624d\u53ef\u4ee5\u7e41\u6b96\n\n\u526a\u679d\u7684 bfs \u5373\u53ef\u5b8c\u6210\n\n## \u51c6\u5907\u6570\u636e\n\n\u4f60\u9700\u8981\u4ece[\u5e15\u9c81\u7f16\u5e74\u53f2](https://paldb.cc)\u4e2d, \u81ea\u884c\u6574\u7406 `a.tsv` (\u6240\u6709\u5e15\u9c81\u7684CombiRank \u7e41\u6b96\u529b IndexOrder \u7d22\u5f15), `b.tsv` (\u7279\u6b8a\u7e41\u6b96\u914d\u65b9)\n> \u6b64\u7d22\u5f15\u4e0e\u5e15\u9c81id\u4e0d\u540c\n<details><summary>\u4e24\u4e2a\u8868\u7684\u683c\u5f0f\u793a\u4f8b</summary>\n<p>\n\n## a.tsv\n\n[\u5e15\u9c81\u7f16\u5e74\u53f2 Breed Combi](https://paldb.cc/cn/Breeding_Farm)\n\n```tsv\nname\tCombiRank\tIndexOrder\n\u76ae\u76ae\u9e21\t1500\t66\n\u58f6\u5c0f\u8c61\t1490\t17\n\u55b5\u4e1d\u7279\t1480\t7\n```\n\n> \u6ce8\u610f\u4e2d\u95f4\u662f `\\t` \u5236\u8868\u7b26\n\n## b.tsv\n\n[\u5e15\u9c81\u7f16\u5e74\u53f2 Breed Unique](https://paldb.cc/cn/Breeding_Farm#BreedUnique)\n[\u5e15\u9c81\u7f16\u5e74\u53f2 Breed Self](https://paldb.cc/cn/Breeding_Farm#BreedSelf)\n\n\n```tsv\nparent\t\u5b75\u5316\u5b8c\u6210\n\u4f69\u514b\u9f99  \u4f0f\u7279\u55b5\t\u6d3e\u514b\u9f99\n\u708e\u9b54\u7f8a  \u566c\u9b42\u517d\t\u6697\u9b54\u7f8a\n\u55b5\u4e1d\u7279  \u4f01\u4e38\u4e38\t\u51b0\u4e1d\u7279\n```\n> \u6ce8\u610f\u4e2d\u95f4\u662f `\\t` \u5236\u8868\u7b26, parent\u4e2d\u95f4\u662f\u4e24\u4e2a\u7a7a\u683c\n\n</p>\n</details> \n\n> \u6ce8\u610f\u8bed\u8a00\n\n## \u4ee3\u7801\n\n<details><summary>\u672a\u6574\u7406\u4ee3\u7801</summary>\n<p>\n\n```python\nfrom collections import deque\nimport csv\n\ndef load_data():\n    data = {}\n    with open(r'a.tsv', 'r', newline='', encoding='utf-8') as f:\n        reader = csv.reader(f, delimiter='\\t')\n        next(reader)\n        for row in reader:\n            data[row[0]] = {'fertility': int(row[1]), 'index_order': int(row[2])}\n\n    data2 = {}\n    exclusive = set()\n\n    with open(r'b.tsv', 'r', newline='', encoding='utf-8') as f:\n        reader = csv.reader(f, delimiter='\\t')\n        next(reader)\n        for row in reader:\n            parents = tuple(sorted(row[0].split('  ')))\n            child = row[1]\n            data2[parents] = child\n            exclusive.add(child)\n\n    return data, data2, exclusive\n\npal_data, special_breeding, exclusive_pals = load_data()\n\ndef breed(parent1, parent2):\n    key = tuple(sorted([parent1, parent2]))\n    if key in special_breeding:\n        return special_breeding[key]\n    \n    # \u5854\u4e3b\u5904\u7406\n    p1_fertility = pal_data[parent1]['fertility']\n    p2_fertility = pal_data[parent2]['fertility']\n    if p1_fertility == 9999 or p2_fertility == 9999:\n        return '\u76ae\u76ae\u9e21'\n    \n    value = (p1_fertility + p2_fertility + 1) // 2\n    \n    valid_pals = [\n        (name, info) for name, info in pal_data.items() \n        if name not in exclusive_pals\n    ]\n    \n    closest_pal = min(\n        valid_pals,\n        key=lambda x: (abs(x[1]['fertility'] - value), x[1]['index_order'])\n    )\n    return closest_pal[0]\n\ndef find_breeding_path(start, end):\n    if start not in pal_data or end not in pal_data:\n        return []\n    \n    target_fertility = pal_data[end]['fertility']\n    visited = {}\n    queue = deque([(start, [start])])\n    results = []\n    min_steps = None\n\n    while queue:\n        level_size = len(queue)\n        found = False\n        \n        for _ in range(level_size):\n            current_pal, path = queue.popleft()\n            \n            if min_steps and len(path) > min_steps:\n                continue\n                \n            if current_pal == end:\n                if not min_steps:\n                    min_steps = len(path)\n                if len(path) == min_steps:\n                    results.append(path)\n                found = True\n                continue\n                \n            # \u83b7\u53d6\u5f53\u524d\u5e15\u9c81\u7e41\u6b96\u529b\n            current_fertility = pal_data[current_pal]['fertility']\n            \n            for mate in pal_data:\n                if mate == current_pal:\n                    continue\n                \n                key = tuple(sorted([current_pal, mate]))\n                \n                # \u7279\u6b8a\u7e41\u6b96\u76f4\u63a5\u5904\u7406\n                if key in special_breeding:\n                    child = special_breeding[key]\n                    new_path = path + [mate, child]\n                    if child not in visited or len(new_path) < visited.get(child, float('inf')):\n                        visited[child] = len(new_path)\n                        queue.append((child, new_path))\n                    continue\n                \n                mate_fertility = pal_data[mate]['fertility']\n                \n                # \u5854\u4e3b\u7279\u6b8a\u5904\u7406\n                if current_fertility == 9999 or mate_fertility == 9999:\n                    child = '\u76ae\u76ae\u9e21'\n                else:\n                    if current_fertility < target_fertility and mate_fertility < current_fertility:\n                        continue  # \u914d\u5076\u751f\u80b2\u529b\u66f4\u4f4e\uff0c\u5b50\u4ee3\u53ea\u4f1a\u66f4\u5c0f\n                    if current_fertility > target_fertility and mate_fertility > current_fertility:\n                        continue  # \u914d\u5076\u751f\u80b2\u529b\u66f4\u9ad8\uff0c\u5b50\u4ee3\u53ea\u4f1a\u66f4\u5927\n                    \n                    child = breed(current_pal, mate)\n                \n                new_path = path + [mate, child]\n                \n                # \u5982\u679c\u5b50\u4ee3\u751f\u80b2\u529b\u504f\u79bb\u76ee\u6807\u65b9\u5411\n                child_fertility = pal_data[child]['fertility']\n                if (target_fertility > current_fertility and child_fertility < current_fertility) or \\\n                   (target_fertility < current_fertility and child_fertility > current_fertility):\n                    continue\n                \n                if child not in visited or len(new_path) < visited[child]:\n                    visited[child] = len(new_path)\n                    queue.append((child, new_path))\n                elif len(new_path) == visited[child]:\n                    queue.append((child, new_path))\n        \n        if found:\n            break\n\n    final_results = [p for p in results if len(p) == min_steps]\n    return final_results if final_results else []\n\nstart_pal = '\u6df7\u6c8c\u9a91\u58eb'\nend_pal = '\u516b\u4e91\u72ac'\npaths = find_breeding_path(start_pal, end_pal)\n\nif paths:\n    print(f'\u627e\u5230{len(paths)}\u6761\u6700\u77ed\u7e41\u6b96\u8def\u5f84\uff08\u6b65\u6570\uff1a{(len(paths[0])-1)//2}\uff09:')\n    for i, path in enumerate(paths, 1):\n        print(f'\\n\u8def\u5f84{i}:')\n        for j in range(0, len(path)-1, 2):\n            print(f'{path[j]} + {path[j+1]} \u2192 {path[j+2]}')\nelse:\n    print('\u65e0\u53ef\u884c\u7e41\u6b96\u8def\u5f84')\n\n```\n\n</p>\n</details> \n\n> \u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48, \u76f8\u5bf9\u4e8e\u5e15\u9c81\u7f16\u5e74\u53f2\u7684\u5b9e\u73b0, \u6211\u7684\u5b9e\u73b0\u6162\u4e00\u70b9, \u4f30\u8ba1\u662f\u4ed6\u9884\u8ba1\u7b97\u597d\u4e86\u3002", "top": 0, "createdAt": 1738724591, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2025-02-05", "dateLabelColor": "#0969da"}, "P10": {"htmlDir": "docs/post/ji-yu- deepseek -de- r1 -fu-xian-, -dui-chuan-tong-qiang-hua-xue-xi-de-si-kao- (-wa-keng-).html", "labels": ["idea"], "postTitle": "\u57fa\u4e8e deepseek \u7684 r1 \u590d\u73b0, \u5bf9\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7684\u601d\u8003 (\u6316\u5751)", "postUrl": "post/ji-yu-%20deepseek%20-de-%20r1%20-fu-xian-%2C%20-dui-chuan-tong-qiang-hua-xue-xi-de-si-kao-%20%28-wa-keng-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/10", "commentNum": 0, "wordCount": 1321, "description": "> \u672c\u6587\u5b58\u5728\u5927\u91cf\u53e3\u9f7f\u4e0d\u6e05\n\ndeepseek-r1\u6301\u7eed\u706b\u70ed, \u5df2\u6709\u5927\u91cf\u7684\u590d\u73b0\u8bad\u7ec3\u8fc7\u7a0b\n\n1. [open-r1](https://github.com/huggingface/open-r1)\n2. [mini-deepseek-r1](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/mini-deepseek-r1-aha-grpo.ipynb)\n3. [open-r1-multimodal](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal)\n4. [open-thoughts](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal)\n5. [TinyZero](https://github.com/Jiayi-Pan/TinyZero)\n6. [simpleRL-reason](https://github.com/hkust-nlp/simpleRL-reason)\n7. [RAGEN](https://github.com/ZihanWang314/RAGEN)\n8. [unsloth r1-reasoning](https://unsloth.ai/blog/r1-reasoning)\n9. [oat-zero](https://github.com/sail-sg/oat-zero)\n10. [Logic-RL](https://github.com/Unakar/Logic-RL)\n11. [deepseek-r1-gsm8k](https://github.com/Mryangkaitong/deepseek-r1-gsm8k)\n\n\u5177\u4f53\u6548\u679c\u53ef\u4ee5\u770b\u5177\u4f53\u7684\u4ed3\u5e93\u4e0e\u5176\u4e2d\u7684\u8bba\u6587\u6216\u8005\u535a\u5ba2, \u8fd9\u91cc\u4e3b\u8981\u60f3\u6cd5\u662f, \u662f\u5426\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e00\u8bad\u7ec3\u8303\u5f0f, \u6765\u4e3a\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1, \u5e26\u6765\u53ef\u5bf9\u4eba\u5e26\u6765\u53c2\u8003\u7684\u601d\u7ef4\u8fc7\u7a0b\n\n\u4f8b\u5982, \u5e0c\u671b\u7ed9\u56f4\u68cb\u4f7f\u7528\u6b64\u8303\u5f0f, \u4e00\u4e2a\u53ef\u80fd\u7684 pipeline \u662f:\n1. sft, \u4e3a\u6a21\u578b\u5e26\u5165\u56f4\u68cb\u77e5\u8bc6\n    > \u6211\u8ba4\u4e3a\u662f\u5fc5\u8981\u7684, \u56e0\u4e3a\u901a\u7528\u578b\u5927\u6a21\u578b\u6b64\u7c7b\u77e5\u8bc6\u8f83\u5c11, \u5982\u679c\u6ca1\u6709\u7684\u8bdd, \u641c\u7d22\u89e3\u7a7a\u95f4\u592a\u5927, \u4e0d\u5bb9\u6613\u641c\u7d22\u5230\u6b63\u786e\u7684 token, \u53ef\u4ee5\u4f7f\u7528\u5176\u4ed6\u5f3a\u529b\u6a21\u578b\u6216\u8005\u7a0b\u5e8f\u8fdb\u884c\u8f85\u52a9\u6784\u5efa\n2. \u8bbe\u5b9a\u4e00\u4e2a\u901a\u7528\u683c\u5f0f, \u7ee7\u7eedsft, \u8ba9\u6a21\u578b\u8f93\u51fa\u6b63\u786e\u683c\u5f0f(\u975e\u5fc5\u8981, \u5728\u4e0a\u8ff0\u590d\u73b0\u4e2d, \u65e0\u9700\u7279\u610fsft\u4e5f\u53ef\u4ee5\u8ba9\u6a21\u578b\u8f93\u51fa\u6b63\u786e\u683c\u5f0f)\n3. rule based RL\n    > \u8003\u8651\u5230\u56f4\u68cb\u4e2d\u95f4\u7684reward\u975e\u5e38\u96be\u91cf\u5316, \u53ef\u4ee5\u4f7f\u7528\u4e13\u4e1a\u56f4\u68cb\u6a21\u578b\u8fdb\u884c\u53cd\u9988\n    > \u8ba9\u5927\u6a21\u578b\u8fdb\u884c\u4e00\u5b9a\u7684\u601d\u8003, \u8f93\u51fa\u4e00\u4e2a\u7b54\u6848, \u4e4b\u540e\u4e0e\u56f4\u68cb\u6a21\u578b\u8fdb\u884c\u6bd4\u5bf9, \u524d\u51e0\u9009 reward +1, \u5176\u4ed6 reward -1, \u6216\u8005\u66f4\u8fdb\u4e00\u6b65\u7684, \u4f7f\u7528\u56f4\u68cb\u6a21\u578b\u7684 logits\n    > \u5982\u679c\u662f\u7b80\u5355\u7684\u4efb\u52a1, \u5219\u53ef\u4ee5\u901a\u8fc7env\u53cd\u9988\u5956\u52b1(\u4e0er1\u76f8\u540c), \u53c2\u8003 [RAGEN](https://github.com/ZihanWang314/RAGEN)\n\n\n\u3002", "top": 0, "createdAt": 1739260046, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2025-02-11", "dateLabelColor": "#0969da"}, "P11": {"htmlDir": "docs/post/2024 Advent of Code -fu-pan-yu-da-an- (-san-) (17-25-ti-).html", "labels": ["blog"], "postTitle": "2024 Advent of Code \u590d\u76d8\u4e0e\u7b54\u6848 (\u4e09) (17-25\u9898)", "postUrl": "post/2024%20Advent%20of%20Code%20-fu-pan-yu-da-an-%20%28-san-%29%20%2817-25-ti-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/11", "commentNum": 0, "wordCount": 21765, "description": "[Advent of Code](https://adventofcode.com/)\n\n\u4f7f\u7528 python \u7f16\u5199, \u6ca1\u6709\u6574\u7406\u4ee3\u7801, \u6240\u4ee5\u975e\u5e38\u4e71(\u53d8\u91cf\u4e71\u53d6\u540d, \u6ca1\u6709\u6ce8\u91ca, \u903b\u8f91\u5947\u602a, \u5e76\u975e\u6700\u4f73\u5b9e\u73b0)\n\u53ef\u4ee5\u4f7f\u7528 gpt \u76f8\u5173\u5de5\u5177\u8f85\u52a9\u67e5\u770b\n\n> \u5982\u679c\u6ca1\u6709\u7279\u610f\u8bf4\u660e, \u53d8\u91cf a \u7edf\u4e00\u5b58\u653e\u6240\u6709\u539f\u59cb\u5b57\u7b26\u4e32\n\n## \u7b2c\u5341\u4e03\u9898\n\n[https://adventofcode.com/2024/day/17](https://adventofcode.com/2024/day/17)\n\n### 1\u9898\n\n\u5c1d\u8bd5\u6a21\u62df\u8ba1\u7b97\u673a, \u5bc4\u5b58\u5668+\u7279\u5b9a\u64cd\u4f5c\u7801\n\n> \u9898\u975e\u5e38\u9ebb\u70e6, \u5efa\u8bae\u770b\u539f\u6587\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\ndef main():\n    input_data = a.splitlines()\n    \n    # Parse initial register values\n    registers = {\n        'A': int(input_data[0].split(': ')[1]),\n        'B': int(input_data[1].split(': ')[1]),\n        'C': int(input_data[2].split(': ')[1]),\n    }\n    \n    # Parse program\n    program = list(map(int, input_data[4].split(': ')[1].split(',')))\n    \n    output = []\n    ip = 0\n    program_length = len(program)\n    \n    def get_combo_value(operand):\n        if operand == 4:\n            return registers['A']\n        elif operand == 5:\n            return registers['B']\n        elif operand == 6:\n            return registers['C']\n        else:\n            return operand  # 0-3\n    \n    while ip < program_length:\n        if ip + 1 >= program_length:\n            break  # Invalid instruction, halt\n        opcode = program[ip]\n        operand = program[ip + 1]\n        \n        if opcode == 0:  # adv\n            denominator = 2 ** get_combo_value(operand)\n            registers['A'] = registers['A'] // denominator\n            ip += 2\n        elif opcode == 1:  # bxl\n            registers['B'] ^= operand\n            ip += 2\n        elif opcode == 2:  # bst\n            registers['B'] = get_combo_value(operand) % 8\n            ip += 2\n        elif opcode == 3:  # jnz\n            if registers['A'] != 0:\n                ip = operand\n            else:\n                ip += 2\n        elif opcode == 4:  # bxc\n            registers['B'] ^= registers['C']\n            ip += 2\n        elif opcode == 5:  # out\n            output_value = get_combo_value(operand) % 8\n            output.append(str(output_value))\n            ip += 2\n        elif opcode == 6:  # bdv\n            denominator = 2 ** get_combo_value(operand)\n            registers['B'] = registers['A'] // denominator\n            ip += 2\n        elif opcode == 7:  # cdv\n            denominator = 2 ** get_combo_value(operand)\n            registers['C'] = registers['A'] // denominator\n            ip += 2\n        else:\n            ip += 2  # Invalid opcode, skip\n        \n    print(','.join(output))\n\nif __name__ == '__main__':\n    main()\n``` \n\n</p>\n</details> \n\n### 2\u9898\n\n\u5728\u7ed9\u5b9a\u64cd\u4f5c\u7801\u4e0b, \u63a8\u65ad\u6700\u5c0f\u7684\u5bc4\u5b58\u5668\u4e2d\u7684\u6ee1\u8db3\u6761\u4ef6\u7684\u503c(\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u7b49\u4e8e\u8f93\u51fa\u7684\u503c)\n\n<details><summary>Details</summary>\n<p>\n\n```python\nprogram = list(map(int, a.splitlines()[4].split(': ')[1].split(',')))\nn = len(program)\nprogram = program[::-1]\n\nchoices = next_choices = [0]\nfor oo in program:\n    choices = next_choices\n    next_choices = []\n    while choices:\n        a = choices.pop()\n        for i in range(8):\n            aa = (a << 3) | i\n            bb = i ^ 1\n            cc = aa >> bb\n            bb = (bb ^ cc ^ 4) % 8\n            if bb == oo:\n                next_choices.append(aa)\n    # print(next_choices)\n    \nprint(min(next_choices))\n\n# z = (A % 8) ^ 1\n# out = z ^ (A >> z) ^ 4\n``` \n\n</p>\n</details> \n\n## \u7b2c\u5341\u516b\u9898\n\n[https://adventofcode.com/2024/day/18](https://adventofcode.com/2024/day/18)\n\n### 1\u9898\n\n\u8d70\u4e8c\u7ef4\u8ff7\u5bab\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\nimport heapq\nfrom collections import defaultdict\n\n# print(all_map)\n\nstart = (0, 0)\nend = (70, 70)\n\n\n\n\nflag = False\ntemp = a.splitlines()\ntemp = temp[:1024]\n# while not flag:\nall_map = [['.' for _ in range(71)] for _ in range(71)]\nfor i in temp:\n    x, y = map(int, i.split(','))\n    all_map[x][y] = '#'\n\n\ndef get_allow_pos(pos):\n    for i in [(0, 1), (1, 0), (-1, 0), (0, -1)]:\n        next_step = (pos[0] + i[0], pos[1] + i[1])\n        if len(all_map) > next_step[0] >= 0 and len(all_map[0]) > next_step[1] >= 0:\n            if all_map[next_step[0]][next_step[1]] == '.':\n                yield (pos[0] + i[0], pos[1] + i[1])\n\nnode = []\nheapq.heappush(node, (0, start))\nvisited = defaultdict(int)\nvisited[start] = 0\n\nwhile node:\n    step, (x, y) = heapq.heappop(node)\n    if (x, y) == end:\n        flag = True\n        print(step)\n        break\n    if visited[(x, y)] < step:\n        continue\n    for next in get_allow_pos((x, y)):\n        if next not in visited or step + 1 < visited[(next[0], next[1])]:\n            visited[(next[0], next[1])] = step + 1\n            heapq.heappush(node, (step + 1, next))\n``` \n\n</p>\n</details> \n\n### 2\u9898\n\n\u8ba9\u8ff7\u5bab\u65e0\u89e3\u7684\u6700\u65b0\u7684\u5750\u6807\u662f\u591a\u5c11\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\nimport heapq\nfrom collections import defaultdict\n\n# print(all_map)\n\nstart = (0, 0)\nend = (70, 70)\n\nflag = False\ntemp = a.splitlines()\ntemp.append('')\nwhile not flag:\n    all_map = [['.' for _ in range(71)] for _ in range(71)]\n    print(temp.pop())\n    for i in temp:\n        x, y = map(int, i.split(','))\n        all_map[x][y] = '#'\n\n    def get_allow_pos(pos):\n        for i in [(0, 1), (1, 0), (-1, 0), (0, -1)]:\n            next_step = (pos[0] + i[0], pos[1] + i[1])\n            if len(all_map) > next_step[0] >= 0 and len(all_map[0]) > next_step[1] >= 0:\n                if all_map[next_step[0]][next_step[1]] == '.':\n                    yield (pos[0] + i[0], pos[1] + i[1])\n\n    node = []\n    heapq.heappush(node, (0, start))\n    visited = defaultdict(int)\n    visited[start] = 0\n\n    while node:\n        step, (x, y) = heapq.heappop(node)\n        if (x, y) == end:\n            flag = True\n            print(step)\n            break\n        if visited[(x, y)] < step:\n            continue\n        for next in get_allow_pos((x, y)):\n            if next not in visited or step + 1 < visited[(next[0], next[1])]:\n                visited[(next[0], next[1])] = step + 1\n                heapq.heappush(node, (step + 1, next))\n``` \n\n</p>\n</details> \n\n## \u7b2c\u5341\u4e5d\u9898\n\n[https://adventofcode.com/2024/day/19](https://adventofcode.com/2024/day/19)\n\n### 1\u9898\n\n\u7ed9\u5b9a\u51e0\u4e2a\u56fe\u6848\u7247\u6bb5, \u4e0e\u51e0\u79cd\u56fe\u6848(\u5305\u62ec\u4e0d\u53ef\u5b8c\u6210\u56fe\u6848), \u627e\u51fa\u6709\u591a\u5c11\u79cd\u8bbe\u8ba1\u65b9\u6848\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = a.splitlines()\nhas = aa[0]\nhas = has.split(', ')\nall_possible = aa[2:]\n\n\ndef dp(s):\n    n = len(s)\n    dp_state = [0] * (n + 1)\n    dp_state[0] = 1\n    for i in range(n):\n        if dp_state[i]:\n            for j in has:\n                l = len(j)\n                if i + l <= n and s[i:i+l] == j:\n                    dp_state[i+l] = 1\n    return dp_state[n]\n\nprint(dp('abaa'))\n\nans = 0\nfor i in all_possible:\n    ans += dp(i)\n\nprint(ans)\n\n``` \n\n</p>\n</details> \n\n### 2\u9898\n\n\u518d\u5c06\u6bcf\u4e2a\u8bbe\u8ba1\u7684\u4e0d\u540c\u65b9\u6cd5\u7684\u6570\u91cf\u52a0\u8d77\u6765\n\n<details><summary>Details</summary>\n<p>\n\n```python\naa = a.splitlines()\nhas = aa[0]\nhas = has.split(', ')\nall_possible = aa[2:]\n\ndef dp(s):\n    n = len(s)\n    dp_state = [0] * (n + 1)\n    dp_state[0] = 1\n    for i in range(n):\n        if dp_state[i]:\n            for j in has:\n                l = len(j)\n                if i + l <= n and s[i:i+l] == j:\n                    dp_state[i+l] += dp_state[i]\n    return dp_state[n]\n\n\nans = 0\nfor i in all_possible:\n    ans += dp(i)\n\nprint(ans)\n\n``` \n\n</p>\n</details> \n\n## \u7b2c\u4e8c\u5341\u9898\n\n[https://adventofcode.com/2024/day/20](https://adventofcode.com/2024/day/20)\n\n### 1\u9898\n\n\u8d70\u8ff7\u5bab, \u4f46\u5141\u8bb8\u7a7f\u5899 \u8d70\u4e00\u6b651ps, \u5141\u8bb8\u7a7f\u5899\u4e00\u6b21 \u6700\u591a2 \u76ae\u79d2\u5185\u7981\u6b62\u78b0\u649e\u4e00\u6b21\n\u6c42\u6709\u591a\u5c11\u79cd\u80fd\u7701100ps\u7684\u7a7f\u5899\u65b9\u5f0f\n\n<details><summary>Details</summary>\n<p>\n\n```python\n\naa = [list(i) for i in a.splitlines()]\nwalls = [(-1, -1)]\n# \u5f00\u59cb\u7ed3\u675f\nfor i in range(len(aa)):\n    for j in range(len(aa[i])):\n        if aa[i][j] == 'S':\n            start = (i, j)\n            aa[i][j] = '.'\n        elif aa[i][j] == 'E':\n            end = (i, j)\n            aa[i][j] = '.'\n        elif aa[i][j] == '#':\n            walls.append((i, j))\n\nnew_walls = []\nfor i in range(len(walls)):\n    if i == 0:\n        continue\n    if walls[i][0] == 0 or walls[i][0] == len(aa) - 1 or walls[i][1] == 0 or walls[i][1] == len(aa[0]) - 1:\n        continue\n    # \u5982\u679cwall\u7684\u4e0a\u4e0b\u6216\u8005\u5de6\u53f3\u65e0\u5899, \u5219\u52a0\u5165new_walls, \u6ce8\u610f\u8fb9\u754c\n    if walls[i][0] - 1 >= 0 and aa[walls[i][0] - 1][walls[i][1]] != '#' and walls[i][0] + 1 < len(aa) and aa[walls[i][0] + 1][walls[i][1]] != '#':\n        new_walls.append((walls[i][0], walls[i][1]))\n    if walls[i][1] - 1 >= 0 and aa[walls[i][0]][walls[i][1] - 1] != '#' and walls[i][1] + 1 < len(aa[0]) and aa[walls[i][0]][walls[i][1] + 1] != '#':\n        new_walls.append((walls[i][0], walls[i][1]))\n\n# print(new_walls)\nwalls = new_walls\n\nprint(start, end)\n\nfrom copy import deepcopy\nimport heapq\nfrom collections import defaultdict\n\nans = []\naaa = 0\nflag = True\nfor i in walls:\n    all_map = deepcopy(aa)\n    if not flag:\n        all_map[i[0]][i[1]] = '.'\n\n    def get_allow_pos(pos):\n        for i in [(0, 1), (1, 0), (-1, 0), (0, -1)]:\n            next_step = (pos[0] + i[0], pos[1] + i[1])\n            if len(all_map) > next_step[0] >= 0 and len(all_map[0]) > next_step[1] >= 0:\n                if all_map[next_step[0]][next_step[1]] == '.':\n                    yield (pos[0] + i[0], pos[1] + i[1])\n\n\n    node = []\n    heapq.heappush(node, (0, start))\n    visited = defaultdict(int)\n    visited[start] = 0\n    while node:\n        step, (x, y) = heapq.heappop(node)\n        if (x, y) == end:\n            if flag:\n                aaa = step\n                flag = False\n            else:\n                if aaa - step >= 100:\n                    ans.append(aaa - step)\n            break\n        if visited[(x, y)] < step:\n            continue\n        for next in get_allow_pos((x, y)):\n            if next not in visited or step + 1 < visited[(next[0], next[1])]:\n                visited[(next[0], next[1])] = step + 1\n                heapq.heappush(node, (step + 1, next))\nprint(len(ans))\n\n``` \n\n</p>\n</details> \n\n### 2\u9898\n\n\u7a7f\u5899\u5141\u8bb820ps, \u4f5c\u5f0a\u4e0d\u9700\u8981\u4f7f\u7528\u5168\u90e8 20 \u76ae\u79d2\uff1b\u4f5c\u5f0a\u53ef\u4ee5\u6301\u7eed\u4efb\u610f\u65f6\u95f4\uff0c\u6700\u957f\u53ef\u8fbe 20 \u76ae\u79d2, \u4f46\u8fd8\u662f\u53ea\u80fd\u7528\u4e00\u6b21, \u4efb\u4f55\u672a\u4f7f\u7528\u7684\u4f5c\u5f0a\u65f6\u95f4\u90fd\u4f1a\u4e22\u5931\uff1b\u5b83\u4e0d\u80fd\u88ab\u4fdd\u5b58\u4ee5\u4f9b\u4ee5\u540e\u518d\u6b21\u4f5c\u5f0a\u3002", "top": 0, "createdAt": 1746513679, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2025-05-06", "dateLabelColor": "#0969da"}, "P12": {"htmlDir": "docs/post/sui-ji-(-yi-) -ying-yong-shang-de-sui-ji.html", "labels": ["blog"], "postTitle": "\u968f\u673a(\u4e00) \u5e94\u7528\u4e0a\u7684\u968f\u673a", "postUrl": "post/sui-ji-%28-yi-%29%20-ying-yong-shang-de-sui-ji.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/12", "commentNum": 0, "wordCount": 2878, "description": "> \u5199\u5728\u524d\u9762: \u672c\u6587\u63a2\u8ba8\u7684\u771f\u968f\u673a\u4e0e\u4f2a\u968f\u673a\u7684\u5b9a\u4e49: \u53ea\u8981\u6ee1\u8db3\u968f\u673a\u6027\u68c0\u6d4b\u7684, \u5373\u4e3a\u771f\u968f\u673a. \u5176\u4f59\u7686\u4e3a\u4f2a\u968f\u673a\n> \u533a\u522b\u4e8e\u901a\u8fc7\u7269\u7406\u73b0\u8c61\u6216\u4e0d\u53ef\u9884\u6d4b\u7684\u4e8b\u4ef6\u4ea7\u751f\u7684\u771f\u968f\u673a\u6570, \u4e0e\u7a0b\u5e8f\u751f\u6210\u7684\u4f2a\u968f\u673a\u6570, \u4e24\u8005\u5c06\u5728\u4e0b\u4e00\u7bc7\u4ecb\u7ecd\n> \u5e38\u89c1\u7684\u4f2a\u968f\u673a\u6709: \u62bd\u5361\u4f4e\u4fdd\u7b97\u6cd5\u7b49\n\n## \u5f15\u8a00\n\n\u5927\u591a\u6570\u4eba\u77e5\u9053'\u968f\u673a', \u4f46\u5728\u5b9e\u9645\u751f\u6d3b\u4e2d, \u7f3a\u6df7\u6dc6\u76f8\u5173\u6982\u5ff5, \u8fd9\u91cc\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u4ecb\u7ecd, \u672c\u6587\u5e0c\u671b\u4ece\u7edf\u8ba1\u6d4b\u8bd5\u548c\u751f\u6210\u673a\u5236\u4e24\u4e2a\u89c6\u89d2\u5398\u6e05\u4e8c\u8005\u7684\u754c\u9650.\n\n\u5728\u5e94\u7528\u7bc7\u89c6\u89d2\u4e0b\uff0c\u6211\u4eec\u5173\u6ce8\u7684\u662f\u4e00\u4e2a\u6570\u5b57\u5e8f\u5217\u5728\u7279\u5b9a\u573a\u666f\u4e2d\u201c\u8868\u73b0\u201d\u5f97\u5982\u4f55\uff0c\u800c\u975e\u5176\u201c\u51fa\u8eab\u201d\u5982\u4f55\u3002", "top": 0, "createdAt": 1748935205, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2025-06-03", "dateLabelColor": "#0969da"}}, "singeListJson": {}, "labelColorDict": {"blog": "#f9d0c4", "game": "#7B3EB2", "help wanted": "#008672", "idea": "#fef2c0", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "FairyOwO \u7684 Blog", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "homeUrl": "https://FairyOwO.github.io", "prevUrl": "disabled", "nextUrl": "disabled"}