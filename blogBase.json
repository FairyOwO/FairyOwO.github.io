{"singlePage": [], "startSite": "11/22/2024", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark_colorblind", "urlMode": "pinyin", "script": "", "style": "", "head": "", "indexScript": "", "indexStyle": "", "bottomText": "\u8f6c\u8f7d\u65e0\u9700\u6ce8\u660e\u51fa\u5904", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 1, "allHead": "", "title": "FairyOwO \u7684 Blog", "subTitle": "\u8bb0\u5f55\u4e00\u4e9b\u7410\u4e8b", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "email": "740614599@qq.com", "postListJson": {"P1": {"htmlDir": "docs/post/Test.html", "labels": ["blog"], "postTitle": "Test", "postUrl": "post/Test.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/1", "commentNum": 2, "wordCount": 24, "description": "\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5!\r\nThis is a test!\u3002", "top": 0, "createdAt": 1732245994, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P2": {"htmlDir": "docs/post/dai-yue-du.html", "labels": ["idea"], "postTitle": "\u5f85\u9605\u8bfb", "postUrl": "post/dai-yue-du.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/2", "commentNum": 0, "wordCount": 315, "description": "## \u5bf9\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u5b66\u4e60\r\n> \u6b64\u524d\u56e0\u4e3a\u5bf9\u4e00\u4e9b\u5f3a\u5316\u5b66\u4e60\u9879\u76ee\u611f\u5174\u8da3, \u800c\u8349\u8349\u5b66\u4e60\u4e86\u4e00\u90e8\u5206(\u611f\u8c22 ai, \u89e3\u91ca\u4e86\u5927\u90e8\u5206\u5185\u5bb9), \u8fd9\u91cc\u51c6\u5907\u7cfb\u7edf\u6027\u5b66\u4e60\u4e00\u4efd\r\n1. [Reinforcement Learning: An Introduction](https://rl.qiwihui.com/zh-cn/latest/) \u5f3a\u5316\u5b66\u4e60\u5bfc\u8bba\r\n2. [Openai Spinning Up](https://spinningup.qiwihui.com/zh-cn/latest/) OpenAI \u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\r\n\r\n## \u77e5\u4e4e \u5927\u6a21\u578b\u76f8\u5173\r\n\r\n## \u82cf\u5251\u6797\u535a\u5ba2\r\n\r\n## \u56fe\u50cf\u751f\u6210, llm\u5bf9prompt\u4f18\u5316\r\n> demo\u9700\u8981\u3002", "top": 0, "createdAt": 1732265067, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P3": {"htmlDir": "docs/post/shi-yong- k3s -da-jian- k8s -ji-qun-(-shi-yong-guo-nei-jing-xiang-).html", "labels": ["blog"], "postTitle": "\u4f7f\u7528 k3s \u642d\u5efa k8s \u96c6\u7fa4(\u4f7f\u7528\u56fd\u5185\u955c\u50cf)", "postUrl": "post/shi-yong-%20k3s%20-da-jian-%20k8s%20-ji-qun-%28-shi-yong-guo-nei-jing-xiang-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/3", "commentNum": 0, "wordCount": 8564, "description": "> \u5386\u53f2\u6587\u7ae0\u642c\u8fd0\r\n\r\n> \u6ce8: \u6b64\u5904k3s\u4e3a\u5177\u4f53\u7684 Kubernetes \u53d1\u884c\u7248, \u540e\u9762\u7684k8s\u4e3a Kubernetes \u7684\u7f29\u5199, Kubernetes \u662f\u5f00\u6e90\u5bb9\u5668\u7f16\u6392\u5e73\u53f0\r\n\r\n\u9700\u6c42\u4e4b\u521d\u662f\u60f3\u5bf9\u5e74\u629b\u673a, \u6708\u629b\u673a\u8fdb\u884c\u7edf\u4e00\u7684\u7ba1\u7406, \u65b9\u4fbf\u90e8\u7f72\u76f8\u5173\u955c\u50cf, \u7c7b\u4f3c\u4e8e\u53f2\u83b1\u59c6\u7684\u7ed3\u6784(\u62ff\u5230\u65b0\u7684\u673a\u5668, \u52a0\u5165\u96c6\u7fa4, \u673a\u5668\u65f6\u95f4\u8fc7\u671f, \u81ea\u52a8\u79bb\u7ebf, \u4f38\u7f29\u91cd\u542f\u5206\u914d\u5168\u7531\u96c6\u7fa4\u672c\u8eab\u7ba1\u7406)\r\n\r\n\u4f7f\u7528\u7cfb\u7edf\u4e3a Debian\r\n\r\n## \u670d\u52a1\u5668\u642d\u5efa\r\n\r\n### \u642d\u5efa\u96c6\u7fa4\r\n\r\n\u4e3b server sh\u811a\u672c\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  sh -s - server \\\r\n  --cluster-init \\\r\n  --system-default-registry=registry.cn-hangzhou.aliyuncs.com\r\n\r\ncat /var/lib/rancher/k3s/server/token\r\n\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\u526f server sh\u811a\u672c\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  sh -s - server \\\r\n  --cluster-init \\\r\n  --system-default-registry=registry.cn-hangzhou.aliyuncs.com\r\n\r\ncat /var/lib/rancher/k3s/server/token\r\n\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\nclient sh\u811a\u672c\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```sh\r\necho 'deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\r\n\r\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\r\n\r\n# \u4ee5\u4e0b\u5b89\u5168\u66f4\u65b0\u8f6f\u4ef6\u6e90\u5305\u542b\u4e86\u5b98\u65b9\u6e90\u4e0e\u955c\u50cf\u7ad9\u914d\u7f6e\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u4fee\u6539\u6ce8\u91ca\u5207\u6362\r\ndeb https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\r\ndeb-src https://security.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware' > /etc/apt/sources.list\r\n\r\napt update\r\n\r\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\\r\n  INSTALL_K3S_MIRROR=cn \\\r\n  K3S_URL=https://ip:6443 \\\r\n  K3S_TOKEN=your_token \\\r\n  sh -\r\n\r\nmkdir -p /etc/rancher/k3s\r\ncat >> /etc/rancher/k3s/registries.yaml << EOF\r\nmirrors:\r\n  docker.io:\r\n    endpoint:\r\n      - 'https://dockerproxy.net'\r\n      - 'https://registry.cn-hangzhou.aliyuncs.com/'\r\n      - 'https://mirror.ccs.tencentyun.com'\r\n  k8s.gcr.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/google_containers'\r\n  ghcr.io:\r\n    endpoint:\r\n      - 'https://ghcr.dockerproxy.net'\r\n      - 'https://ghcr.m.daocloud.io/'\r\n  gcr.io:\r\n    endpoint:\r\n      - 'https://gcr.dockerproxy.net'\r\n      - 'https://gcr.m.daocloud.io/'\r\n  quay.io:\r\n    endpoint:\r\n      - 'https://quay.dockerproxy.net'\r\n      - 'https://quay.tencentcloudcr.com/'\r\n  registry.k8s.io:\r\n    endpoint:\r\n      - 'https://k8s.dockerproxy.net'\r\n      - 'https://registry.aliyuncs.com/v2/google_containers'\r\nEOF\r\nsystemctl restart k3s-agent\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n> \u6ce8: k3s \u642d\u5efa\u96c6\u7fa4\u7684\u65b9\u6848\u9700\u8981\u4fdd\u8bc1\u4e3b\u670d\u52a1\u5668\u4e0d\u79bb\u7ebf, \u5426\u5219\u6574\u4e2a\u96c6\u7fa4\u4f1a\u79bb\u7ebf, \u8003\u8651\u5230k3s\u5360\u7528\u4f4e, \u673a\u5668\u4e00\u822c\u662f\u6027\u80fd\u4e0d\u9ad8\u7684\u7c7b\u578b, \u6211\u4e5f\u6709\u957f\u671f\u7eed\u8d39\u7684\u670d\u52a1\u5668, \u6545\u4f7f\u7528\u8fd9\u4e2a\u65b9\u6848\r\n\r\n\u5728\u4e3bserver\u670d\u52a1\u5668\u4f7f\u7528\r\n\r\n```sh\r\nkubectl get nodes -A\r\n```\r\n\u51fa\u73b0\u6bcf\u53f0\u673a\u5b50\u7684\u4fe1\u606f, \u4ee3\u8868\u96c6\u7fa4\u5185\u90e8\u7f51\u7edc\u901a\u4fe1\u6ca1\u95ee\u9898\r\n\r\n\u5728\u4e3bserver\u670d\u52a1\u5668\u4f7f\u7528\r\n```sh\r\nkubectl get pods --all-namespaces\r\n```\r\n\u5728\u6240\u6709\u670d\u52a1\u5728 `RUNNING` \u72b6\u6001\u65f6, \u4e3a\u5b89\u88c5\u6210\u529f (\u8fd9\u4e9b\u670d\u52a1\u90fd\u662f\u5185\u90e8\u901a\u4fe1\u4e0e\u5747\u8861\u8d1f\u8f7d\u7684\u955c\u50cf), \u5982\u679c\u662f\u5361\u5728 `container creating`, \u5219\u5b89\u88c5\u5931\u8d25, \u539f\u56e0\u662f\u955c\u50cf\u6ca1\u6b63\u786e\u914d\u7f6e\r\n\r\n### \u5b89\u88c5helm (\u867d\u7136\u4e0d\u77e5\u9053\u5e72\u4ec0\u4e48\u7528, \u96c6\u7fa4\u5185\u4e5f\u81ea\u5e26\u4e00\u4e2ahelm)\r\n\r\n1. \u624b\u52a8\u5b89\u88c5\r\n    1. \u4e0b\u8f7d\u9700\u8981\u7684\u7248\u672c [\u4e0b\u8f7d\u5730\u5740](https://github.com/helm/helm/releases)\r\n    2. \u89e3\u538b, \u4e0a\u4f20\u5230\u670d\u52a1\u5668, chmod\u7ed9\u6267\u884c\u6743\u9650\r\n    3. \u79fb\u52a8\u5230\u73af\u5883\u53d8\u91cf\u7684\u76ee\u5f55\u4e2d\r\n        ```sh\r\n        mv helm /usr/local/bin/helm\r\n        ```\r\n2. \u4f7f\u7528\u811a\u672c\u5b89\u88c5\r\n    ```sh\r\n    https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\r\n    ```\r\n\r\n## \u9762\u677f\u5b89\u88c5\r\n\r\n\u4e3a\u4e86\u7b80\u5355, \u9762\u677f\u9009\u62e9\u7684\u662f kubepi\r\n\r\n[\u6587\u6863](https://github.com/1Panel-dev/KubePi/wiki/2%E3%80%81%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2#kubernetes)\r\n\r\n\u8fd9\u91cc\u9009\u62e9\u7684\u662f\u975e\u6301\u4e45\u5316\u90e8\u7f72, \u5728\u76f4\u63a5\u90e8\u7f72\u5728\u521a\u521a\u5efa\u597d\u7684\u96c6\u7fa4\u4e4b\u4e2d\r\n\r\n> \u6301\u4e45\u5316\u90e8\u7f72\u4f1a\u6709\u83ab\u540d\u5176\u5999\u7684\u5206\u914d\u95ee\u9898, \u5e94\u8be5\u662f\u8ddf\u5206\u914d\u672c\u5730\u7a7a\u95f4\u6709\u5173\u7cfb, \u6211\u4e5f\u4e0d\u9700\u8981\u6301\u4e45\u5316\u96c6\u7fa4\u4fe1\u606f(\u56e0\u4e3a\u53ea\u6709\u4e00\u4e2a\u96c6\u7fa4), \u6240\u4ee5\u6ca1\u4ec0\u4e48\u5173\u7cfb\r\n\r\n```sh\r\n# \u5b89\u88c5\r\nsudo kubectl apply -f https://raw.githubusercontent.com/1Panel-dev/KubePi/master/docs/deploy/kubectl/kubepi.yaml\r\n```\r\n\r\n\u5b89\u88c5\u5b8c\u6210\u540e, \u6839\u636e\u5b89\u88c5\u6559\u7a0b, \u83b7\u53d6\u8bbf\u95ee\u5730\u5740\r\n\r\n```sh\r\n# \u83b7\u53d6 NodeIp\r\nexport NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')\r\n# \u83b7\u53d6 NodePort\r\nexport NODE_PORT=$(kubectl -n kube-system get services kubepi -o jsonpath='{.spec.ports[0].nodePort}')\r\n# \u83b7\u53d6 Address\r\necho http://$NODE_IP:$NODE_PORT\r\n```\r\n\r\n> \u6ce8: \u5185\u7f51\u7ec4\u673a\u5b50\u7684\u65f6\u5019\u8fd9\u91cc\u4f1a\u662f\u5185\u7f51\u5730\u5740, \u9700\u8981\u4f7f\u7528\u7aef\u53e3\u8f6c\u53d1\u8f6c\u53d1\u5230 `0.0.0.0` \u4e4b\u540e\u624d\u80fd\u5916\u7f51\u8bbf\u95ee\r\n> ```sh\r\n> kubectl port-forward --address 0.0.0.0 kubepi-d8477f9d8-drthz -n kube-system 2999:80\r\n> ```\r\n> \u6b64\u547d\u4ee4\u4e0d\u4f1a\u4e2d\u65ad, \u4f1a\u6301\u7eed\u8fd0\u884c, \u9700\u8981\u628a\u8fd9\u6761\u547d\u4ee4\u4e2d\u7684 `kubepi-d8477f9d8-drthz` \u6362\u6210\u5b9e\u9645\u540d\u5b57\r\n\r\n\u767b\u9646\u7cfb\u7edf\r\n\r\n```text\r\n\u5730\u5740: http://$NODE_IP:$NODE_PORT\r\n\u7528\u6237\u540d: admin\r\n\u5bc6\u7801: kubepi\r\n```\r\n\r\n\u767b\u9646\u540e\u8bb0\u5f97\u4fee\u6539\u5bc6\u7801\r\n\r\n\u5bfc\u5165\u96c6\u7fa4\r\n\r\n\u5728\u4e3b\u670d\u52a1\u5668, \u83b7\u53d6\r\n\r\n```sh\r\ncd /etc/rancher/k3s\r\ncat k3s.yaml\r\n```\r\n\u5728 kubepi \u5bfc\u5165\u96c6\u7fa4, \u8ba4\u8bc1\u6a21\u5f0f\u9009\u62e9 kubeconfig\u6587\u4ef6, \u628a\u8fd9\u4e2a\u6587\u4ef6\u590d\u5236\u8fdb\u53bb\r\n\r\n\u5728\u96c6\u7fa4\u914d\u7f6e\u4e2d, \u914d\u7f6e\u4e00\u4e0b\u7f51\u7edc, \u4f7f\u4e4b\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u5916\u7f51\u7aef\u53e3\u8bbf\u95ee\r\n\r\n\u5177\u4f53\u914d\u7f6e\u6d41\u7a0b\u5fd8\u4e86, \u6b64\u65b9\u6cd5\u7531\u540c\u4e8b\u6307\u70b9\r\n\r\n## \u90e8\u7f72\u9879\u76ee\r\n\r\n\u5728 kubepi \u4e2d \u9009\u62e9\u96c6\u7fa4, \u5e94\u7528\u5e02\u573a, chart \u4ed3\u5e93, \u586b\u5165\u76f8\u5173\u4fe1\u606f, \u8fd9\u91cc\u6211\u4f7f\u7528\u7684\u662f:\r\n```text\r\n\u5f00\u6e90\u793e: http://mirror.kaiyuanshe.cn/kubernetes/charts/\r\n\u5f00\u6e90\u5e94\u7528\u5e02\u573a: https://charts.grapps.cn\r\n```\r\n\r\n\u70b9\u5f00\u5e94\u7528\u5c31\u6709\u5f88\u591a\u9879\u76ee\u8df3\u51fa\u6765\u53ef\u4ee5\u90e8\u7f72\u3002", "top": 0, "createdAt": 1732268091, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-22", "dateLabelColor": "#bc4c00"}, "P4": {"htmlDir": "docs/post/nailong-shu-ju-ji-, -jian-ce-nailong-de-mo-xing-, -xun-lian-yu-tui-li- (-yi-).html", "labels": ["blog"], "postTitle": "nailong\u6570\u636e\u96c6, \u68c0\u6d4bnailong\u7684\u6a21\u578b, \u8bad\u7ec3\u4e0e\u63a8\u7406 (\u4e00)", "postUrl": "post/nailong-shu-ju-ji-%2C%20-jian-ce-nailong-de-mo-xing-%2C%20-xun-lian-yu-tui-li-%20%28-yi-%29.html", "postSourceUrl": "https://github.com/FairyOwO/FairyOwO.github.io/issues/4", "commentNum": 0, "wordCount": 20509, "description": "> \u56de\u5f52 \u8001\u672c\u884c\r\n\r\n\u5076\u7136\u5f97\u5230 nailong \u6570\u636e\u96c6, \u5206\u4e3a\u4e24\u5757, \u4e00\u79cd\u662f\u7ed9[\u5206\u7c7b\u6a21\u578b\u4f7f\u7528\u7684\u6570\u636e\u96c6](https://huggingface.co/datasets/refoundd/NailongClassification), \u53e6\u4e00\u79cd\u662f\u7ed9[\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u4f7f\u7528\u7684\u6570\u636e\u96c6](https://huggingface.co/datasets/refoundd/NailongDetection)\r\n\r\n> \u540e\u8005\u7684\u6570\u636e\u91cf\u4e0d\u662f\u975e\u5e38\u591a(6\u5f20), \u7b49\u5230\u6709\u8db3\u591f\u591a\u7684\u6570\u636e\u6216\u8005\u6211\u4e00\u65f6\u5174\u8d77\u624b\u52a8\u6807\u6ce8\u5728\u8fdb\u884c\u7814\u7a76\r\n\r\n## \u521d\u7248\u65b9\u6848\r\n\r\n### \u6570\u636e\u96c6\u9009\u62e9\r\n\r\n\u5728\u6211\u521a\u63a5\u89e6\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u65f6\u5019, \u6570\u636e\u96c6\u662f\u53ea\u6709\u5976\u9f99\u7684(\u65e0\u5176\u4ed6\u6807\u7b7e\u7684\u6570\u636e), \u8fd9\u4e2a\u65f6\u5019\u7b2c\u4e00\u4e2a\u60f3\u6cd5\u5c31\u662f\u5f15\u5165\u5176\u4ed6\u5206\u7c7b, \u8fd9\u91cc\u91c7\u7528cifer10\u6570\u636e\u96c6\u7684\u6570\u636e, \u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u589e\u5e7f\r\n\r\n\u7136\u800c, cifer10 \u7684\u6570\u636e\u5206\u5e03\u6bd5\u7adf\u4e0e\u5e38\u89c1\u7fa4\u804a\u5185\u53d1\u9001\u7684\u56fe\u7247\u4e0d\u540c, \u6211\u89c9\u5f97\u4f1a\u5f71\u54cd\u6700\u7ec8\u80fd\u529b, \u5e94\u8be5\u6709\u9009\u62e9\u6027\u800c\u4e0d\u662f\u968f\u610f\u6dfb\u52a0\u5176\u4ed6\u7c7b\u578b\u7684\u56fe\u7247, \u5728\u4e00\u756a\u641c\u7d22\u4e4b\u540e, \u9009\u4e2d\u4e86 [\u8868\u60c5\u5305\u6570\u636e\u96c6](https://github.com/LLM-Red-Team/emo-visual-data)\r\n\r\n\u867d\u7136\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u539f\u8ba1\u5212\u662f\u7528\u6765\u68c0\u6d4b VLLM \u7684\u80fd\u529b, \u4f46\u6211\u8ba4\u4e3a\u5728\u6211\u4eec\u8fd9\u4e2a\u4efb\u52a1\u4e2d\u4e5f\u53ef\u4ee5\u4f7f\u7528\r\n\r\n### \u6a21\u578b\r\n\r\n\u5728\u6572\u5b9a\u6570\u636e\u96c6\u4e4b\u540e, \u5c31\u5f00\u59cb\u6311\u9009\u6a21\u578b\u4e86, \u56e0\u4e3a\u662f\u4e2a\u4eba\u5c0f\u9879\u76ee, \u8fd9\u91cc\u91c7\u7528\u6211\u4e2a\u4eba\u559c\u597d\u7684\u6a21\u578b\u9009\u62e9, \u4f7f\u7528\u4e86 [convnext \u7cfb\u6a21\u578b](https://github.com/facebookresearch/ConvNeXt)\r\n\r\n\u8fd9\u4e2a\u6a21\u578b\u7684\u8bba\u6587\u662f\u4e00\u7bc7\u975e\u5e38\u7ecf\u5178\u7684\u5b9e\u9a8c\u6587, \u91cc\u9762\u5927\u91cf\u63a2\u7d22\u4e86\u4e00\u4e9b\u6280\u5de7\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd (\u5404\u7c7b\u6d88\u878d\u5b9e\u9a8c), \u867d\u7136\u4ed6\u662f 2020 \u5e74\u63a8\u51fa, \u4f46\u4ed6\u5bf9\u73b0\u5728\u7684\u5377\u79ef\u7f51\u7edc\u7684\u8bad\u7ec3\u6280\u5de7\u7684\u6307\u5f15\u5f88\u5927\r\n\r\n\u5177\u4f53\u7ec6\u8282\u53ef\u4ee5\u641c\u7d22\u76f8\u5173\u7684\u6a21\u578b\u89e3\u6790, \u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\r\n\r\n<details><summary>model.py</summary>\r\n<p>\r\n\r\n```python\r\n# copy from facebook/ConvNeXt\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom timm.models.layers import trunc_normal_, DropPath\r\nfrom timm.models.registry import register_model\r\n\r\nclass Block(nn.Module):\r\n    r''' ConvNeXt Block. There are two equivalent implementations:\r\n    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\r\n    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\r\n    We use (2) as we find it slightly faster in PyTorch\r\n    \r\n    Args:\r\n        dim (int): Number of input channels.\r\n        drop_path (float): Stochastic depth rate. Default: 0.0\r\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\r\n    '''\r\n    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\r\n        super().__init__()\r\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\r\n        self.norm = LayerNorm(dim, eps=1e-6)\r\n        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\r\n        self.act = nn.GELU()\r\n        self.pwconv2 = nn.Linear(4 * dim, dim)\r\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \r\n                                    requires_grad=True) if layer_scale_init_value > 0 else None\r\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\r\n\r\n    def forward(self, x):\r\n        input = x\r\n        x = self.dwconv(x)\r\n        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\r\n        x = self.norm(x)\r\n        x = self.pwconv1(x)\r\n        x = self.act(x)\r\n        x = self.pwconv2(x)\r\n        if self.gamma is not None:\r\n            x = self.gamma * x\r\n        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\r\n\r\n        x = input + self.drop_path(x)\r\n        return x\r\n\r\nclass ConvNeXt(nn.Module):\r\n    r''' ConvNeXt\r\n        A PyTorch impl of : `A ConvNet for the 2020s`  -\r\n          https://arxiv.org/pdf/2201.03545.pdf\r\n\r\n    Args:\r\n        in_chans (int): Number of input image channels. Default: 3\r\n        num_classes (int): Number of classes for classification head. Default: 1000\r\n        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\r\n        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\r\n        drop_path_rate (float): Stochastic depth rate. Default: 0.\r\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\r\n        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\r\n    '''\r\n    def __init__(self, in_chans=3, num_classes=1000, \r\n                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \r\n                 layer_scale_init_value=1e-6, head_init_scale=1.,\r\n                 ):\r\n        super().__init__()\r\n\r\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\r\n        stem = nn.Sequential(\r\n            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\r\n            LayerNorm(dims[0], eps=1e-6, data_format='channels_first')\r\n        )\r\n        self.downsample_layers.append(stem)\r\n        for i in range(3):\r\n            downsample_layer = nn.Sequential(\r\n                    LayerNorm(dims[i], eps=1e-6, data_format='channels_first'),\r\n                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\r\n            )\r\n            self.downsample_layers.append(downsample_layer)\r\n\r\n        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\r\n        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \r\n        cur = 0\r\n        for i in range(4):\r\n            stage = nn.Sequential(\r\n                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \r\n                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\r\n            )\r\n            self.stages.append(stage)\r\n            cur += depths[i]\r\n\r\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\r\n        self.head = nn.Linear(dims[-1], num_classes)\r\n\r\n        self.apply(self._init_weights)\r\n        self.head.weight.data.mul_(head_init_scale)\r\n        self.head.bias.data.mul_(head_init_scale)\r\n\r\n    def _init_weights(self, m):\r\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\r\n            trunc_normal_(m.weight, std=.02)\r\n            nn.init.constant_(m.bias, 0)\r\n\r\n    def forward_features(self, x):\r\n        for i in range(4):\r\n            x = self.downsample_layers[i](x)\r\n            x = self.stages[i](x)\r\n        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\r\n\r\n    def forward(self, x):\r\n        x = self.forward_features(x)\r\n        x = self.head(x)\r\n        return x\r\n\r\nclass LayerNorm(nn.Module):\r\n    r''' LayerNorm that supports two data formats: channels_last (default) or channels_first. \r\n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \r\n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \r\n    with shape (batch_size, channels, height, width).\r\n    '''\r\n    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_last'):\r\n        super().__init__()\r\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\r\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\r\n        self.eps = eps\r\n        self.data_format = data_format\r\n        if self.data_format not in ['channels_last', 'channels_first']:\r\n            raise NotImplementedError \r\n        self.normalized_shape = (normalized_shape, )\r\n    \r\n    def forward(self, x):\r\n        if self.data_format == 'channels_last':\r\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\r\n        elif self.data_format == 'channels_first':\r\n            u = x.mean(1, keepdim=True)\r\n            s = (x - u).pow(2).mean(1, keepdim=True)\r\n            x = (x - u) / torch.sqrt(s + self.eps)\r\n            x = self.weight[:, None, None] * x + self.bias[:, None, None]\r\n            return x\r\n\r\n\r\nmodel_urls = {\r\n    'convnext_tiny_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth',\r\n    'convnext_small_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth',\r\n    'convnext_base_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth',\r\n    'convnext_large_1k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth',\r\n    'convnext_tiny_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth',\r\n    'convnext_small_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth',\r\n    'convnext_base_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth',\r\n    'convnext_large_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',\r\n    'convnext_xlarge_22k': 'https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth',\r\n}\r\n\r\n@register_model\r\ndef convnext_tiny(pretrained=False,in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu', check_hash=True)\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_small(pretrained=False,in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_base(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_large(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\r\n    if pretrained:\r\n        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n\r\n@register_model\r\ndef convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\r\n    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\r\n    if pretrained:\r\n        assert in_22k, 'only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True'\r\n        url = model_urls['convnext_xlarge_22k']\r\n        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location='cpu')\r\n        model.load_state_dict(checkpoint['model'])\r\n    return model\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n\r\n### \u4ee3\u7801\r\n\r\n\u8bad\u7ec3\u4ee3\u7801\u5927\u90e8\u5206\u90fd\u662f\u6a21\u677f, \u4e0d\u8fc7, \u6211\u53d1\u73b0\u6211\u8fd8\u6ca1\u6709\u4e00\u4e2a\u5c5e\u4e8e\u81ea\u5df1\u7684 trainer, \u8d81\u7740\u8fd9\u6b21\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u8865\u5145\u4e00\u4e2a\r\n\r\n\u4f7f\u7528\u522b\u4eba\u7684 trainer \u96be\u514d\u4f1a\u9047\u5230 debug, \u800c\u4ee3\u7801\u4e0d\u719f\u7684\u60c5\u51b5, \u81ea\u5df1\u5199\u7684 trainer \u53ef\u4ee5\u638c\u63e1\u5404\u79cd\u7ec6\u8282\r\n\r\n\u5728\u6574\u7406\u4e86\u4e00\u4e9b\u4ee5\u524d\u4ee3\u7801\u540e, \u603b\u7ed3\u51fa\u4e86\u8986\u76d6\u8bb8\u591a\u8bad\u7ec3\u6a21\u578b\u60c5\u51b5\u7684\u6d41\u7a0b, \u8d81\u7740\u8fd9\u4e2a\u65f6\u5019\u6d4b\u8bd5\u4e00\u4e0b\u73b0\u5728ai\u7f16\u7801\u7684\u80fd\u529b, \u5c06\u6d41\u7a0b\u53d1\u7ed9 claude-sonnet \u540e, \u8f93\u51fa\u4e86\u4e00\u7248\u4ee3\u7801, \u5728\u6211\u7684\u4e00\u4e9b\u5c0f\u4fee\u5c0f\u8865(\u8865\u5145\u65e5\u5fd7)\u540e, \u5c31\u53ef\u4ee5\u8dd1\u8d77\u6765\u4e86\r\n\r\n<details><summary>trainer.py</summary>\r\n<p>\r\n\r\n```python\r\nimport gc\r\nimport json\r\nimport logging\r\nimport os\r\nimport shutil\r\n\r\nimport torch\r\nfrom torch import optim\r\nfrom torch.amp import GradScaler\r\nfrom torch.nn.utils import clip_grad_norm_\r\nfrom torch.utils.tensorboard import SummaryWriter\r\nfrom tqdm import tqdm\r\n\r\nexample_config = {\r\n    'model': 'model_name',\r\n    'checkpoint_dir': './checkpoints',\r\n    'tensorboard_dir': './tensorboard',\r\n    'device': 'cuda',\r\n    'enable_cudnn_benchmark': True,\r\n    'enable_amp': False,\r\n    'learning_rate': 1e-4,\r\n    'betas': [0.9, 0.999],\r\n    'eps': 1e-8,\r\n    'enable_compile': False,\r\n    'weight_decay': 0.05,\r\n    'max_steps': 100000,\r\n    'max_grad_norm': 1.0,\r\n    'save_every': 10000,\r\n    'gradient_accumulation_steps': 4\r\n}\r\n\r\n\r\nclass Trainer:\r\n    def __init__(self, config):\r\n        self.config = config\r\n        self.setup_logging()\r\n        self.setup_device()\r\n        self.setup_model()\r\n        self.setup_training()\r\n        \r\n    def setup_logging(self):\r\n        '''\u8bbe\u7f6e\u65e5\u5fd7'''\r\n        logging.basicConfig(\r\n            level=logging.INFO,\r\n            format='%(asctime)s %(levelname)s %(message)s'\r\n        )\r\n        self.logger = logging.getLogger(__name__)\r\n        self.writer = SummaryWriter(self.config['tensorboard_dir'])\r\n        \r\n    def setup_device(self):\r\n        '''\u8bbe\u7f6e\u8bbe\u5907'''\r\n        self.device = torch.device(self.config['device'])\r\n        torch.backends.cudnn.benchmark = self.config.get('enable_cudnn_benchmark', True)\r\n        if self.device.type == 'cuda':\r\n            self.logger.info(f'Using device: {self.device} ({torch.cuda.get_device_name()})')\r\n        else:\r\n            self.logger.info(f'Using device: {self.device}')\r\n            \r\n    def setup_model(self):\r\n        '''\u8bbe\u7f6e\u6a21\u578b\u3001\u635f\u5931\u51fd\u6570\u7b49'''\r\n        self.model = self.build_model().to(self.device)\r\n        if self.config.get('enable_compile', False):\r\n            self.model.compile()\r\n        self.criterion = self.build_criterion()\r\n        \r\n        # \u6253\u5370\u6a21\u578b\u4fe1\u606f\r\n        n_parameters = sum(p.numel() for p in self.model.parameters())\r\n        self.logger.info(f'Number of parameters: {n_parameters:,}')\r\n        \r\n    def setup_training(self):\r\n        '''\u8bbe\u7f6e\u8bad\u7ec3\u76f8\u5173\u7ec4\u4ef6'''\r\n        # \u4f18\u5316\u5668\r\n        self.optimizer = self.build_optimizer()\r\n        \r\n        # \u5b66\u4e60\u7387\u8c03\u5ea6\u5668\r\n        self.scheduler = self.build_scheduler()\r\n        \r\n        # \u68af\u5ea6\u7f29\u653e\u5668(\u7528\u4e8e\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3)\r\n        self.scaler = GradScaler(\r\n            enabled=self.config.get('enable_amp', False)\r\n        )\r\n        self.gradient_accumulation_steps = self.config.get('gradient_accumulation_steps', 1)\r\n        \r\n        # \u52a0\u8f7d\u68c0\u67e5\u70b9\r\n        self.steps = 0\r\n        self.best_metric = {}\r\n        self.load_checkpoint()\r\n        \r\n    def build_model(self):\r\n        '''\u6784\u5efa\u6a21\u578b(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def build_criterion(self):\r\n        '''\u6784\u5efa\u635f\u5931\u51fd\u6570(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def build_optimizer(self):\r\n        '''\u6784\u5efa\u4f18\u5316\u5668'''\r\n        # \u533a\u5206\u9700\u8981\u548c\u4e0d\u9700\u8981weight decay\u7684\u53c2\u6570\r\n        decay_params = []\r\n        no_decay_params = []\r\n        for name, param in self.model.named_parameters():\r\n            if 'bias' in name or 'norm' in name:\r\n                no_decay_params.append(param)\r\n            else:\r\n                decay_params.append(param)\r\n                \r\n        opt_params = [\r\n            {'params': decay_params, 'weight_decay': self.config['weight_decay']},\r\n            {'params': no_decay_params, 'weight_decay': 0.0}\r\n        ]\r\n        \r\n        return optim.AdamW(\r\n            opt_params,\r\n            lr=self.config['learning_rate'],\r\n            betas=self.config.get('betas', (0.9, 0.999)),\r\n            eps=self.config.get('eps', 1e-8)\r\n        )\r\n        \r\n    def build_scheduler(self):\r\n        '''\u6784\u5efa\u5b66\u4e60\u7387\u8c03\u5ea6\u5668(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        return NotImplementedError\r\n        \r\n    def build_dataloader(self):\r\n        '''\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def train_step(self, batch):\r\n        '''\u5355\u6b65\u8bad\u7ec3(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def validate(self):\r\n        '''\u9a8c\u8bc1(\u9700\u8981\u5b50\u7c7b\u5b9e\u73b0)'''\r\n        raise NotImplementedError\r\n        \r\n    def save_checkpoint(self, is_best=False):\r\n        '''\u4fdd\u5b58\u68c0\u67e5\u70b9'''\r\n        state = {\r\n            'model': self.model.state_dict(),\r\n            'optimizer': self.optimizer.state_dict(),\r\n            'scheduler': self.scheduler.state_dict(),\r\n            'scaler': self.scaler.state_dict(),\r\n            'steps': self.steps,\r\n            'best_metric': self.best_metric,\r\n            'config': self.config\r\n        }\r\n        \r\n        # \u4fdd\u5b58\u6700\u65b0\u68c0\u67e5\u70b9\r\n        torch.save(\r\n            state,\r\n            os.path.join(self.config['checkpoint_dir'], 'latest.pt')\r\n        )\r\n        \r\n        # \u4fdd\u5b58\u6700\u4f73\u68c0\u67e5\u70b9\r\n        if is_best:\r\n            shutil.copy(\r\n                os.path.join(self.config['checkpoint_dir'], 'latest.pt'),\r\n                os.path.join(self.config['checkpoint_dir'], 'best.pt')\r\n            )\r\n            \r\n    def load_checkpoint(self):\r\n        '''\u52a0\u8f7d\u68c0\u67e5\u70b9'''\r\n        checkpoint_path = os.path.join(\r\n            self.config['checkpoint_dir'],\r\n            'latest.pt'\r\n        )\r\n        \r\n        if os.path.exists(checkpoint_path):\r\n            checkpoint = torch.load(\r\n                checkpoint_path,\r\n                map_location=self.device\r\n            )\r\n            \r\n            self.model.load_state_dict(checkpoint['model'])\r\n            self.optimizer.load_state_dict(checkpoint['optimizer'])\r\n            self.scheduler.load_state_dict(checkpoint['scheduler'])\r\n            self.scaler.load_state_dict(checkpoint['scaler'])\r\n            self.steps = checkpoint['steps']\r\n            self.best_metric = checkpoint['best_metric']\r\n            \r\n            self.logger.info(f'Loaded checkpoint from {checkpoint_path}')\r\n            self.logger.info(f'Training will resume from step {self.steps}')\r\n    \r\n    @staticmethod\r\n    def is_better_performance(baseline_dict, compare_dict):\r\n        '''\r\n        \u5224\u65adcompare_dict\u4e2d\u7684\u6307\u6807\u662f\u5426\u5168\u9762\u8d85\u8fc7baseline_dict\r\n        \r\n        Args:\r\n            baseline_dict: \u57fa\u51c6\u5b57\u5178,\u683c\u5f0f\u4e3a {\u6307\u6807\u540d: \u503c}\r\n            compare_dict: \u6bd4\u8f83\u5b57\u5178,\u683c\u5f0f\u4e3a {\u6307\u6807\u540d: \u503c} \r\n        \r\n        Returns:\r\n            bool: \u5982\u679ccompare_dict\u4e2d\u6240\u6709\u6307\u6807\u90fd\u4e25\u683c\u5927\u4e8ebaseline_dict\u5219\u8fd4\u56deTrue,\u5426\u5219\u8fd4\u56deFalse\r\n        '''\r\n        if not baseline_dict:\r\n            return True\r\n        \r\n        # \u68c0\u67e5\u4e24\u4e2a\u5b57\u5178\u7684\u952e\u662f\u5426\u4e00\u81f4\r\n        if set(baseline_dict.keys()) != set(compare_dict.keys()):\r\n            return False\r\n            \r\n        # \u68c0\u67e5\u6bcf\u4e2a\u6307\u6807\u662f\u5426\u90fd\u6709\u63d0\u5347\r\n        for metric in baseline_dict:\r\n            if compare_dict[metric] <= baseline_dict[metric]:\r\n                return False\r\n                \r\n        return True\r\n            \r\n    def train(self):\r\n        '''\u8bad\u7ec3\u6d41\u7a0b'''\r\n        train_loader = self.build_dataloader()\r\n        self.model.train()\r\n        \r\n        self.logger.info('Start training...')\r\n        pbar = tqdm(total=self.config['max_steps'], initial=self.steps)\r\n        \r\n        while self.steps < self.config['max_steps']:\r\n            for batch in train_loader:\r\n                # \u8bad\u7ec3\u4e00\u6b65\r\n                with torch.autocast(device_type=self.config['device'], enabled=self.config.get('enable_amp', False)):\r\n                    loss = self.train_step(batch)\r\n                self.scaler.scale(loss / self.gradient_accumulation_steps).backward()\r\n                \r\n                if (self.steps + 1) % self.gradient_accumulation_steps == 0:\r\n                    # \u68af\u5ea6\u88c1\u526a\r\n                    if self.config.get('max_grad_norm', 0) > 0:\r\n                        self.scaler.unscale_(self.optimizer)\r\n                        clip_grad_norm_(\r\n                            self.model.parameters(),\r\n                            self.config['max_grad_norm']\r\n                        )\r\n\r\n                    # \u4f18\u5316\u5668\u6b65\u8fdb\r\n                    self.scaler.step(self.optimizer)\r\n                    self.scaler.update()\r\n                    self.optimizer.zero_grad(set_to_none=True)\r\n                self.scheduler.step()\r\n                \r\n                # \u8bb0\u5f55\r\n                self.writer.add_scalar('train/loss', loss, self.steps)\r\n                self.writer.add_scalar(\r\n                    'train/lr',\r\n                    self.scheduler.get_last_lr()[0],\r\n                    self.steps\r\n                )\r\n                \r\n                self.steps += 1\r\n                pbar.update(1)\r\n                \r\n                # \u9a8c\u8bc1\u548c\u4fdd\u5b58\r\n                if self.steps % self.config['save_every'] == 0:\r\n                    metric = self.validate()\r\n                    for i in metric:\r\n                        self.logger.info(f'Validation {i}: {metric[i]}')\r\n                        self.writer.add_scalar(f'val/{i}', metric[i], self.steps)\r\n                    \r\n                    is_best = self.is_better_performance(self.best_metric, metric)\r\n                    if is_best:\r\n                        self.best_metric = metric\r\n\r\n                    self.model.train()\r\n                    self.save_checkpoint(is_best)\r\n                    \r\n                if self.steps >= self.config['max_steps']:\r\n                    break\r\n                \r\n            gc.collect()\r\n            torch.cuda.empty_cache()\r\n                    \r\n        pbar.close()\r\n        self.logger.info('Training finished!')\r\n\r\n\r\ndef main():\r\n    '''\u4e3b\u51fd\u6570'''\r\n    # \u52a0\u8f7d\u914d\u7f6e\r\n    with open('config.json') as f:\r\n        config = json.load(f)\r\n        \r\n    # \u521b\u5efa\u8f93\u51fa\u76ee\u5f55\r\n    os.makedirs(config['checkpoint_dir'], exist_ok=True)\r\n    os.makedirs(config['tensorboard_dir'], exist_ok=True)\r\n    \r\n    # \u8bad\u7ec3\r\n    trainer = Trainer(config)\r\n    trainer.train()\r\n    \r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except KeyboardInterrupt:\r\n        pass\r\n``` \r\n\r\n</p>\r\n</details> \r\n\r\n<details><summary>train.py(\u4ee3\u7801\u672a\u6574\u7406\u5b8c\u6bd5)</summary>\r\n<p>\r\n\r\n```python\r\n\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n> TODO \u8865\u5145trainer\u7684\u7528\u4f8b\u4e0e\u7528\u6cd5\r\n> TODO \u8865\u5145\u8d85\u53c2\u641c\u7d22\u76f8\u5173\u5185\u5bb9, \u4ee5\u53ca\u5176\u7528\u4f8b\u4e0e\u7528\u6cd5\r\n\r\n### \u6570\u636e\u589e\u5e7f\r\n\r\n\u539f\u59cb\u6570\u636e\u96c6\u53ea\u6709\u4e24\u767e\u591a\u5f20\u56fe\u7247, \u8fd9\u4e2a\u65f6\u5019\u65e0\u6cd5\u907f\u514d\u7684\u8981\u505a\u6570\u636e\u589e\u5e7f, \u6269\u5c55 nailong \u6807\u7b7e\u7684\u6570\u636e, \u8fd9\u91cc\u56e0\u4e3a\u662f\u521d\u7248\u65b9\u6848, \u4e5f\u6ca1\u6709\u975e\u5e38\u7cbe\u7ec6\u7684\u589e\u5e7f\u65b9\u6848, \u8fd9\u91cc\u4f7f\u7528\u4e86\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f(\u4ee3\u7801\u5728\u5982\u4e0atrain.py\u4e2d):\r\n\r\n- \u7ed9\u56fe\u7247\u6dfb\u52a0\u989c\u8272\u906e\u7f69\r\n    \u8ba9\u6a21\u578b\u4e0d\u8981\u5c06\u9047\u5230\u9ec4\u8272\u7684\u5c31\u5224\u5b9a\u4e3a\u5976\u9f99\r\n- \u5728\u8d1f\u6837\u672c\u4e2d\u5d4c\u5165\u6b63\u6837\u672c\r\n    \u5f88\u7ecf\u5178\u7684\u589e\u5e7f\u6570\u636e\u7684\u624b\u6cd5\r\n- \u56fe\u7247\u8f74\u5bf9\u79f0\r\n- \u7b49\r\n\u3002", "top": 0, "createdAt": 1732625582, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-26", "dateLabelColor": "#bc4c00"}}, "singeListJson": {}, "labelColorDict": {"blog": "#f9d0c4", "game": "#7B3EB2", "help wanted": "#008672", "idea": "#fef2c0", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "FairyOwO \u7684 Blog", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "homeUrl": "https://FairyOwO.github.io", "prevUrl": "disabled", "nextUrl": "disabled"}